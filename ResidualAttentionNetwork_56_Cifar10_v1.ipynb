{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "812e091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os, pickle, sys, time\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "from utils.MyRAN56_v1 import ResidualAttentionModel_56\n",
    "from contextlib import redirect_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be290eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "print(gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "873940db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/ran56_v1 already exists.\n",
      "./models/ran56_v1/history already exists.\n",
      "./models/ran56_v1/saved_models already exists.\n",
      "./models/ran56_v1/graphs already exists.\n"
     ]
    }
   ],
   "source": [
    "path = './models'\n",
    "model_name = '/ran56_v1'\n",
    "model_path = path + model_name\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "    print(model_path)\n",
    "else:\n",
    "    print(model_path + ' already exists.')\n",
    "\n",
    "history_path = model_path + '/history'\n",
    "if not os.path.exists(history_path):\n",
    "    os.makedirs(history_path)\n",
    "    print(history_path)\n",
    "else:\n",
    "    print(history_path + ' already exists.')\n",
    "\n",
    "saved_model_path = model_path + '/saved_models'\n",
    "if not os.path.exists(saved_model_path):\n",
    "    os.makedirs(saved_model_path)\n",
    "    print(saved_model_path)\n",
    "else:\n",
    "    print(saved_model_path + ' already exists.')\n",
    "    \n",
    "checkpoint_path = history_path + \"/checkpoints\"\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    os.makedirs(checkpoint_path)\n",
    "else:\n",
    "    print(checkpoint_path + ' already exists.')\n",
    "    \n",
    "graph_path = model_path + '/graphs'\n",
    "if not os.path.exists(graph_path):\n",
    "    os.makedirs(graph_path)\n",
    "    print(graph_path)\n",
    "else:\n",
    "    print(graph_path + ' already exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bf1a26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0dbaacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=20,\n",
    "                                                          width_shift_range=0.2,\n",
    "                                                          height_shift_range=0.2,\n",
    "                                                          horizontal_flip=True,\n",
    "                                                          validation_split=0.2)\n",
    "\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "X_train = X_train - X_train.mean()\n",
    "X_test = X_test - X_test.mean()\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f78fa58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResUnit_L1_NotAttnModule_1_NoDS\n",
      "ResUnit_L2_NotAttnModule_1_NoDS\n",
      "ResUnit_L3_NotAttnModule_1_NoDS\n",
      "ResUnit_L4_NotAttnModule_1_NoDS\n",
      "ResUnit_L5_NotAttnModule_1_NoDS\n",
      "ResUnit_L6_NotAttnModule_1_NoDS\n",
      "ResUnit_L7_NotAttnModule_1_NoDS\n",
      "ResUnit_L8_NotAttnModule_1_NoDS\n",
      "ResUnit_L9_NotAttnModule_1_NoDS\n",
      "ResUnit_L10_NotAttnModule_1_NoDS\n",
      "ResUnit_L11_NotAttnModule_1_NoDS\n",
      "ResUnit_L1_Input-p-1-1_AttnS1-1\n",
      "ResUnit_L2_Input-p-1-1_AttnS1-1\n",
      "ResUnit_L3_Input-p-1-1_AttnS1-1\n",
      "ResUnit_L4_Input-p-1-1_AttnS1-1\n",
      "ResUnit_L5_Input-p-1-1_AttnS1-1\n",
      "ResUnit_L6_Input-p-1-1_AttnS1-1\n",
      "ResUnit_L7_Input-p-1-1_AttnS1-1\n",
      "ResUnit_L8_Input-p-1-1_AttnS1-1\n",
      "ResUnit_L9_Input-p-1-1_AttnS1-1\n",
      "ResUnit_L10_Input-p-1-1_AttnS1-1\n",
      "ResUnit_L11_Input-p-1-1_AttnS1-1\n",
      "ResUnit_L1_Trunk-t-2-1_AttnS1-1\n",
      "ResUnit_L2_Trunk-t-2-1_AttnS1-1\n",
      "ResUnit_L3_Trunk-t-2-1_AttnS1-1\n",
      "ResUnit_L4_Trunk-t-2-1_AttnS1-1\n",
      "ResUnit_L5_Trunk-t-2-1_AttnS1-1\n",
      "ResUnit_L6_Trunk-t-2-1_AttnS1-1\n",
      "ResUnit_L7_Trunk-t-2-1_AttnS1-1\n",
      "ResUnit_L8_Trunk-t-2-1_AttnS1-1\n",
      "ResUnit_L9_Trunk-t-2-1_AttnS1-1\n",
      "ResUnit_L10_Trunk-t-2-1_AttnS1-1\n",
      "ResUnit_L11_Trunk-t-2-1_AttnS1-1\n",
      "ResUnit_L1_Trunk-t-2-2_AttnS1-1\n",
      "ResUnit_L2_Trunk-t-2-2_AttnS1-1\n",
      "ResUnit_L3_Trunk-t-2-2_AttnS1-1\n",
      "ResUnit_L4_Trunk-t-2-2_AttnS1-1\n",
      "ResUnit_L5_Trunk-t-2-2_AttnS1-1\n",
      "ResUnit_L6_Trunk-t-2-2_AttnS1-1\n",
      "ResUnit_L7_Trunk-t-2-2_AttnS1-1\n",
      "ResUnit_L8_Trunk-t-2-2_AttnS1-1\n",
      "ResUnit_L9_Trunk-t-2-2_AttnS1-1\n",
      "ResUnit_L10_Trunk-t-2-2_AttnS1-1\n",
      "ResUnit_L11_Trunk-t-2-2_AttnS1-1\n",
      "ResUnit_L1_SkipConn-Outer_Mask_AttnS1-1\n",
      "ResUnit_L2_SkipConn-Outer_Mask_AttnS1-1\n",
      "ResUnit_L3_SkipConn-Outer_Mask_AttnS1-1\n",
      "ResUnit_L4_SkipConn-Outer_Mask_AttnS1-1\n",
      "ResUnit_L5_SkipConn-Outer_Mask_AttnS1-1\n",
      "ResUnit_L6_SkipConn-Outer_Mask_AttnS1-1\n",
      "ResUnit_L7_SkipConn-Outer_Mask_AttnS1-1\n",
      "ResUnit_L8_SkipConn-Outer_Mask_AttnS1-1\n",
      "ResUnit_L9_SkipConn-Outer_Mask_AttnS1-1\n",
      "ResUnit_L10_SkipConn-Outer_Mask_AttnS1-1\n",
      "ResUnit_L11_SkipConn-Outer_Mask_AttnS1-1\n",
      "ResUnit_L1_DownSamp-r-1-1_Mask_AttnS1-1\n",
      "ResUnit_L2_DownSamp-r-1-1_Mask_AttnS1-1\n",
      "ResUnit_L3_DownSamp-r-1-1_Mask_AttnS1-1\n",
      "ResUnit_L4_DownSamp-r-1-1_Mask_AttnS1-1\n",
      "ResUnit_L5_DownSamp-r-1-1_Mask_AttnS1-1\n",
      "ResUnit_L6_DownSamp-r-1-1_Mask_AttnS1-1\n",
      "ResUnit_L7_DownSamp-r-1-1_Mask_AttnS1-1\n",
      "ResUnit_L8_DownSamp-r-1-1_Mask_AttnS1-1\n",
      "ResUnit_L9_DownSamp-r-1-1_Mask_AttnS1-1\n",
      "ResUnit_L10_DownSamp-r-1-1_Mask_AttnS1-1\n",
      "ResUnit_L11_DownSamp-r-1-1_Mask_AttnS1-1\n",
      "ResUnit_L1_SkipConn-Inner_Mask_AttnS1-1\n",
      "ResUnit_L2_SkipConn-Inner_Mask_AttnS1-1\n",
      "ResUnit_L3_SkipConn-Inner_Mask_AttnS1-1\n",
      "ResUnit_L4_SkipConn-Inner_Mask_AttnS1-1\n",
      "ResUnit_L5_SkipConn-Inner_Mask_AttnS1-1\n",
      "ResUnit_L6_SkipConn-Inner_Mask_AttnS1-1\n",
      "ResUnit_L7_SkipConn-Inner_Mask_AttnS1-1\n",
      "ResUnit_L8_SkipConn-Inner_Mask_AttnS1-1\n",
      "ResUnit_L9_SkipConn-Inner_Mask_AttnS1-1\n",
      "ResUnit_L10_SkipConn-Inner_Mask_AttnS1-1\n",
      "ResUnit_L11_SkipConn-Inner_Mask_AttnS1-1\n",
      "ResUnit_L1_Mid-2r-2-1_Mask_AttnS1-1\n",
      "ResUnit_L2_Mid-2r-2-1_Mask_AttnS1-1\n",
      "ResUnit_L3_Mid-2r-2-1_Mask_AttnS1-1\n",
      "ResUnit_L4_Mid-2r-2-1_Mask_AttnS1-1\n",
      "ResUnit_L5_Mid-2r-2-1_Mask_AttnS1-1\n",
      "ResUnit_L6_Mid-2r-2-1_Mask_AttnS1-1\n",
      "ResUnit_L7_Mid-2r-2-1_Mask_AttnS1-1\n",
      "ResUnit_L8_Mid-2r-2-1_Mask_AttnS1-1\n",
      "ResUnit_L9_Mid-2r-2-1_Mask_AttnS1-1\n",
      "ResUnit_L10_Mid-2r-2-1_Mask_AttnS1-1\n",
      "ResUnit_L11_Mid-2r-2-1_Mask_AttnS1-1\n",
      "ResUnit_L1_Mid-2r-2-2_Mask_AttnS1-1\n",
      "ResUnit_L2_Mid-2r-2-2_Mask_AttnS1-1\n",
      "ResUnit_L3_Mid-2r-2-2_Mask_AttnS1-1\n",
      "ResUnit_L4_Mid-2r-2-2_Mask_AttnS1-1\n",
      "ResUnit_L5_Mid-2r-2-2_Mask_AttnS1-1\n",
      "ResUnit_L6_Mid-2r-2-2_Mask_AttnS1-1\n",
      "ResUnit_L7_Mid-2r-2-2_Mask_AttnS1-1\n",
      "ResUnit_L8_Mid-2r-2-2_Mask_AttnS1-1\n",
      "ResUnit_L9_Mid-2r-2-2_Mask_AttnS1-1\n",
      "ResUnit_L10_Mid-2r-2-2_Mask_AttnS1-1\n",
      "ResUnit_L11_Mid-2r-2-2_Mask_AttnS1-1\n",
      "ResUnit_L1_UpSamp-r-1-1_Mask_AttnS1-1\n",
      "ResUnit_L2_UpSamp-r-1-1_Mask_AttnS1-1\n",
      "ResUnit_L3_UpSamp-r-1-1_Mask_AttnS1-1\n",
      "ResUnit_L4_UpSamp-r-1-1_Mask_AttnS1-1\n",
      "ResUnit_L5_UpSamp-r-1-1_Mask_AttnS1-1\n",
      "ResUnit_L6_UpSamp-r-1-1_Mask_AttnS1-1\n",
      "ResUnit_L7_UpSamp-r-1-1_Mask_AttnS1-1\n",
      "ResUnit_L8_UpSamp-r-1-1_Mask_AttnS1-1\n",
      "ResUnit_L9_UpSamp-r-1-1_Mask_AttnS1-1\n",
      "ResUnit_L10_UpSamp-r-1-1_Mask_AttnS1-1\n",
      "ResUnit_L11_UpSamp-r-1-1_Mask_AttnS1-1\n",
      "ResUnit_L1_Output-p-1-1_AttnS1-1\n",
      "ResUnit_L2_Output-p-1-1_AttnS1-1\n",
      "ResUnit_L3_Output-p-1-1_AttnS1-1\n",
      "ResUnit_L4_Output-p-1-1_AttnS1-1\n",
      "ResUnit_L5_Output-p-1-1_AttnS1-1\n",
      "ResUnit_L6_Output-p-1-1_AttnS1-1\n",
      "ResUnit_L7_Output-p-1-1_AttnS1-1\n",
      "ResUnit_L8_Output-p-1-1_AttnS1-1\n",
      "ResUnit_L9_Output-p-1-1_AttnS1-1\n",
      "ResUnit_L10_Output-p-1-1_AttnS1-1\n",
      "ResUnit_L11_Output-p-1-1_AttnS1-1\n",
      "ResUnit_L1_NotAttnModule_2_DS\n",
      "ResUnit_L2_NotAttnModule_2_DS\n",
      "ResUnit_L3_NotAttnModule_2_DS\n",
      "ResUnit_L4_NotAttnModule_2_DS\n",
      "ResUnit_L5_NotAttnModule_2_DS\n",
      "ResUnit_L6_NotAttnModule_2_DS\n",
      "ResUnit_L7_NotAttnModule_2_DS\n",
      "ResUnit_L8_NotAttnModule_2_DS\n",
      "ResUnit_L9_NotAttnModule_2_DS\n",
      "ResUnit_L10_NotAttnModule_2_DS\n",
      "ResUnit_L11_NotAttnModule_2_DS\n",
      "ResUnit_L1_Input-p-1-1_AttnS2-1\n",
      "ResUnit_L2_Input-p-1-1_AttnS2-1\n",
      "ResUnit_L3_Input-p-1-1_AttnS2-1\n",
      "ResUnit_L4_Input-p-1-1_AttnS2-1\n",
      "ResUnit_L5_Input-p-1-1_AttnS2-1\n",
      "ResUnit_L6_Input-p-1-1_AttnS2-1\n",
      "ResUnit_L7_Input-p-1-1_AttnS2-1\n",
      "ResUnit_L8_Input-p-1-1_AttnS2-1\n",
      "ResUnit_L9_Input-p-1-1_AttnS2-1\n",
      "ResUnit_L10_Input-p-1-1_AttnS2-1\n",
      "ResUnit_L11_Input-p-1-1_AttnS2-1\n",
      "ResUnit_L1_Trunk-t-2-1_AttnS2-1\n",
      "ResUnit_L2_Trunk-t-2-1_AttnS2-1\n",
      "ResUnit_L3_Trunk-t-2-1_AttnS2-1\n",
      "ResUnit_L4_Trunk-t-2-1_AttnS2-1\n",
      "ResUnit_L5_Trunk-t-2-1_AttnS2-1\n",
      "ResUnit_L6_Trunk-t-2-1_AttnS2-1\n",
      "ResUnit_L7_Trunk-t-2-1_AttnS2-1\n",
      "ResUnit_L8_Trunk-t-2-1_AttnS2-1\n",
      "ResUnit_L9_Trunk-t-2-1_AttnS2-1\n",
      "ResUnit_L10_Trunk-t-2-1_AttnS2-1\n",
      "ResUnit_L11_Trunk-t-2-1_AttnS2-1\n",
      "ResUnit_L1_Trunk-t-2-2_AttnS2-1\n",
      "ResUnit_L2_Trunk-t-2-2_AttnS2-1\n",
      "ResUnit_L3_Trunk-t-2-2_AttnS2-1\n",
      "ResUnit_L4_Trunk-t-2-2_AttnS2-1\n",
      "ResUnit_L5_Trunk-t-2-2_AttnS2-1\n",
      "ResUnit_L6_Trunk-t-2-2_AttnS2-1\n",
      "ResUnit_L7_Trunk-t-2-2_AttnS2-1\n",
      "ResUnit_L8_Trunk-t-2-2_AttnS2-1\n",
      "ResUnit_L9_Trunk-t-2-2_AttnS2-1\n",
      "ResUnit_L10_Trunk-t-2-2_AttnS2-1\n",
      "ResUnit_L11_Trunk-t-2-2_AttnS2-1\n",
      "ResUnit_L1_DownSamp-r-1-1_Mask_AttnS2-1\n",
      "ResUnit_L2_DownSamp-r-1-1_Mask_AttnS2-1\n",
      "ResUnit_L3_DownSamp-r-1-1_Mask_AttnS2-1\n",
      "ResUnit_L4_DownSamp-r-1-1_Mask_AttnS2-1\n",
      "ResUnit_L5_DownSamp-r-1-1_Mask_AttnS2-1\n",
      "ResUnit_L6_DownSamp-r-1-1_Mask_AttnS2-1\n",
      "ResUnit_L7_DownSamp-r-1-1_Mask_AttnS2-1\n",
      "ResUnit_L8_DownSamp-r-1-1_Mask_AttnS2-1\n",
      "ResUnit_L9_DownSamp-r-1-1_Mask_AttnS2-1\n",
      "ResUnit_L10_DownSamp-r-1-1_Mask_AttnS2-1\n",
      "ResUnit_L11_DownSamp-r-1-1_Mask_AttnS2-1\n",
      "ResUnit_L1_SkipConn-Inner_Mask_AttnS2-1\n",
      "ResUnit_L2_SkipConn-Inner_Mask_AttnS2-1\n",
      "ResUnit_L3_SkipConn-Inner_Mask_AttnS2-1\n",
      "ResUnit_L4_SkipConn-Inner_Mask_AttnS2-1\n",
      "ResUnit_L5_SkipConn-Inner_Mask_AttnS2-1\n",
      "ResUnit_L6_SkipConn-Inner_Mask_AttnS2-1\n",
      "ResUnit_L7_SkipConn-Inner_Mask_AttnS2-1\n",
      "ResUnit_L8_SkipConn-Inner_Mask_AttnS2-1\n",
      "ResUnit_L9_SkipConn-Inner_Mask_AttnS2-1\n",
      "ResUnit_L10_SkipConn-Inner_Mask_AttnS2-1\n",
      "ResUnit_L11_SkipConn-Inner_Mask_AttnS2-1\n",
      "ResUnit_L1_Mid-2r-2-1_Mask_AttnS2-1\n",
      "ResUnit_L2_Mid-2r-2-1_Mask_AttnS2-1\n",
      "ResUnit_L3_Mid-2r-2-1_Mask_AttnS2-1\n",
      "ResUnit_L4_Mid-2r-2-1_Mask_AttnS2-1\n",
      "ResUnit_L5_Mid-2r-2-1_Mask_AttnS2-1\n",
      "ResUnit_L6_Mid-2r-2-1_Mask_AttnS2-1\n",
      "ResUnit_L7_Mid-2r-2-1_Mask_AttnS2-1\n",
      "ResUnit_L8_Mid-2r-2-1_Mask_AttnS2-1\n",
      "ResUnit_L9_Mid-2r-2-1_Mask_AttnS2-1\n",
      "ResUnit_L10_Mid-2r-2-1_Mask_AttnS2-1\n",
      "ResUnit_L11_Mid-2r-2-1_Mask_AttnS2-1\n",
      "ResUnit_L1_Mid-2r-2-2_Mask_AttnS2-1\n",
      "ResUnit_L2_Mid-2r-2-2_Mask_AttnS2-1\n",
      "ResUnit_L3_Mid-2r-2-2_Mask_AttnS2-1\n",
      "ResUnit_L4_Mid-2r-2-2_Mask_AttnS2-1\n",
      "ResUnit_L5_Mid-2r-2-2_Mask_AttnS2-1\n",
      "ResUnit_L6_Mid-2r-2-2_Mask_AttnS2-1\n",
      "ResUnit_L7_Mid-2r-2-2_Mask_AttnS2-1\n",
      "ResUnit_L8_Mid-2r-2-2_Mask_AttnS2-1\n",
      "ResUnit_L9_Mid-2r-2-2_Mask_AttnS2-1\n",
      "ResUnit_L10_Mid-2r-2-2_Mask_AttnS2-1\n",
      "ResUnit_L11_Mid-2r-2-2_Mask_AttnS2-1\n",
      "ResUnit_L1_UpSamp-r-1-1_Mask_AttnS2-1\n",
      "ResUnit_L2_UpSamp-r-1-1_Mask_AttnS2-1\n",
      "ResUnit_L3_UpSamp-r-1-1_Mask_AttnS2-1\n",
      "ResUnit_L4_UpSamp-r-1-1_Mask_AttnS2-1\n",
      "ResUnit_L5_UpSamp-r-1-1_Mask_AttnS2-1\n",
      "ResUnit_L6_UpSamp-r-1-1_Mask_AttnS2-1\n",
      "ResUnit_L7_UpSamp-r-1-1_Mask_AttnS2-1\n",
      "ResUnit_L8_UpSamp-r-1-1_Mask_AttnS2-1\n",
      "ResUnit_L9_UpSamp-r-1-1_Mask_AttnS2-1\n",
      "ResUnit_L10_UpSamp-r-1-1_Mask_AttnS2-1\n",
      "ResUnit_L11_UpSamp-r-1-1_Mask_AttnS2-1\n",
      "ResUnit_L1_Output-p-1-1_AttnS2-1\n",
      "ResUnit_L2_Output-p-1-1_AttnS2-1\n",
      "ResUnit_L3_Output-p-1-1_AttnS2-1\n",
      "ResUnit_L4_Output-p-1-1_AttnS2-1\n",
      "ResUnit_L5_Output-p-1-1_AttnS2-1\n",
      "ResUnit_L6_Output-p-1-1_AttnS2-1\n",
      "ResUnit_L7_Output-p-1-1_AttnS2-1\n",
      "ResUnit_L8_Output-p-1-1_AttnS2-1\n",
      "ResUnit_L9_Output-p-1-1_AttnS2-1\n",
      "ResUnit_L10_Output-p-1-1_AttnS2-1\n",
      "ResUnit_L11_Output-p-1-1_AttnS2-1\n",
      "ResUnit_L1_NotAttnModule_3_DS\n",
      "ResUnit_L2_NotAttnModule_3_DS\n",
      "ResUnit_L3_NotAttnModule_3_DS\n",
      "ResUnit_L4_NotAttnModule_3_DS\n",
      "ResUnit_L5_NotAttnModule_3_DS\n",
      "ResUnit_L6_NotAttnModule_3_DS\n",
      "ResUnit_L7_NotAttnModule_3_DS\n",
      "ResUnit_L8_NotAttnModule_3_DS\n",
      "ResUnit_L9_NotAttnModule_3_DS\n",
      "ResUnit_L10_NotAttnModule_3_DS\n",
      "ResUnit_L11_NotAttnModule_3_DS\n",
      "ResUnit_L1_Input-p-1-1_AttnS3-1\n",
      "ResUnit_L2_Input-p-1-1_AttnS3-1\n",
      "ResUnit_L3_Input-p-1-1_AttnS3-1\n",
      "ResUnit_L4_Input-p-1-1_AttnS3-1\n",
      "ResUnit_L5_Input-p-1-1_AttnS3-1\n",
      "ResUnit_L6_Input-p-1-1_AttnS3-1\n",
      "ResUnit_L7_Input-p-1-1_AttnS3-1\n",
      "ResUnit_L8_Input-p-1-1_AttnS3-1\n",
      "ResUnit_L9_Input-p-1-1_AttnS3-1\n",
      "ResUnit_L10_Input-p-1-1_AttnS3-1\n",
      "ResUnit_L11_Input-p-1-1_AttnS3-1\n",
      "ResUnit_L1_Trunk-t-2-1_AttnS3-1\n",
      "ResUnit_L2_Trunk-t-2-1_AttnS3-1\n",
      "ResUnit_L3_Trunk-t-2-1_AttnS3-1\n",
      "ResUnit_L4_Trunk-t-2-1_AttnS3-1\n",
      "ResUnit_L5_Trunk-t-2-1_AttnS3-1\n",
      "ResUnit_L6_Trunk-t-2-1_AttnS3-1\n",
      "ResUnit_L7_Trunk-t-2-1_AttnS3-1\n",
      "ResUnit_L8_Trunk-t-2-1_AttnS3-1\n",
      "ResUnit_L9_Trunk-t-2-1_AttnS3-1\n",
      "ResUnit_L10_Trunk-t-2-1_AttnS3-1\n",
      "ResUnit_L11_Trunk-t-2-1_AttnS3-1\n",
      "ResUnit_L1_Trunk-t-2-2_AttnS3-1\n",
      "ResUnit_L2_Trunk-t-2-2_AttnS3-1\n",
      "ResUnit_L3_Trunk-t-2-2_AttnS3-1\n",
      "ResUnit_L4_Trunk-t-2-2_AttnS3-1\n",
      "ResUnit_L5_Trunk-t-2-2_AttnS3-1\n",
      "ResUnit_L6_Trunk-t-2-2_AttnS3-1\n",
      "ResUnit_L7_Trunk-t-2-2_AttnS3-1\n",
      "ResUnit_L8_Trunk-t-2-2_AttnS3-1\n",
      "ResUnit_L9_Trunk-t-2-2_AttnS3-1\n",
      "ResUnit_L10_Trunk-t-2-2_AttnS3-1\n",
      "ResUnit_L11_Trunk-t-2-2_AttnS3-1\n",
      "ResUnit_L1_UpSamp-r-1-1_Mask_AttnS3-1\n",
      "ResUnit_L2_UpSamp-r-1-1_Mask_AttnS3-1\n",
      "ResUnit_L3_UpSamp-r-1-1_Mask_AttnS3-1\n",
      "ResUnit_L4_UpSamp-r-1-1_Mask_AttnS3-1\n",
      "ResUnit_L5_UpSamp-r-1-1_Mask_AttnS3-1\n",
      "ResUnit_L6_UpSamp-r-1-1_Mask_AttnS3-1\n",
      "ResUnit_L7_UpSamp-r-1-1_Mask_AttnS3-1\n",
      "ResUnit_L8_UpSamp-r-1-1_Mask_AttnS3-1\n",
      "ResUnit_L9_UpSamp-r-1-1_Mask_AttnS3-1\n",
      "ResUnit_L10_UpSamp-r-1-1_Mask_AttnS3-1\n",
      "ResUnit_L11_UpSamp-r-1-1_Mask_AttnS3-1\n",
      "ResUnit_L1_UpSamp-r-1-2_Mask_AttnS3-1\n",
      "ResUnit_L2_UpSamp-r-1-2_Mask_AttnS3-1\n",
      "ResUnit_L3_UpSamp-r-1-2_Mask_AttnS3-1\n",
      "ResUnit_L4_UpSamp-r-1-2_Mask_AttnS3-1\n",
      "ResUnit_L5_UpSamp-r-1-2_Mask_AttnS3-1\n",
      "ResUnit_L6_UpSamp-r-1-2_Mask_AttnS3-1\n",
      "ResUnit_L7_UpSamp-r-1-2_Mask_AttnS3-1\n",
      "ResUnit_L8_UpSamp-r-1-2_Mask_AttnS3-1\n",
      "ResUnit_L9_UpSamp-r-1-2_Mask_AttnS3-1\n",
      "ResUnit_L10_UpSamp-r-1-2_Mask_AttnS3-1\n",
      "ResUnit_L11_UpSamp-r-1-2_Mask_AttnS3-1\n",
      "ResUnit_L1_Output-p-1-1_AttnS3-1\n",
      "ResUnit_L2_Output-p-1-1_AttnS3-1\n",
      "ResUnit_L3_Output-p-1-1_AttnS3-1\n",
      "ResUnit_L4_Output-p-1-1_AttnS3-1\n",
      "ResUnit_L5_Output-p-1-1_AttnS3-1\n",
      "ResUnit_L6_Output-p-1-1_AttnS3-1\n",
      "ResUnit_L7_Output-p-1-1_AttnS3-1\n",
      "ResUnit_L8_Output-p-1-1_AttnS3-1\n",
      "ResUnit_L9_Output-p-1-1_AttnS3-1\n",
      "ResUnit_L10_Output-p-1-1_AttnS3-1\n",
      "ResUnit_L11_Output-p-1-1_AttnS3-1\n",
      "ResUnit_L1_NotAttnModule_4_NoDS\n",
      "ResUnit_L2_NotAttnModule_4_NoDS\n",
      "ResUnit_L3_NotAttnModule_4_NoDS\n",
      "ResUnit_L4_NotAttnModule_4_NoDS\n",
      "ResUnit_L5_NotAttnModule_4_NoDS\n",
      "ResUnit_L6_NotAttnModule_4_NoDS\n",
      "ResUnit_L7_NotAttnModule_4_NoDS\n",
      "ResUnit_L8_NotAttnModule_4_NoDS\n",
      "ResUnit_L9_NotAttnModule_4_NoDS\n",
      "ResUnit_L10_NotAttnModule_4_NoDS\n",
      "ResUnit_L11_NotAttnModule_4_NoDS\n",
      "ResUnit_L1_NotAttnModule_5_NoDS\n",
      "ResUnit_L2_NotAttnModule_5_NoDS\n",
      "ResUnit_L3_NotAttnModule_5_NoDS\n",
      "ResUnit_L4_NotAttnModule_5_NoDS\n",
      "ResUnit_L5_NotAttnModule_5_NoDS\n",
      "ResUnit_L6_NotAttnModule_5_NoDS\n",
      "ResUnit_L7_NotAttnModule_5_NoDS\n",
      "ResUnit_L8_NotAttnModule_5_NoDS\n",
      "ResUnit_L9_NotAttnModule_5_NoDS\n",
      "ResUnit_L10_NotAttnModule_5_NoDS\n",
      "ResUnit_L11_NotAttnModule_5_NoDS\n",
      "ResUnit_L1_NotAttnModule_6_NoDS\n",
      "ResUnit_L2_NotAttnModule_6_NoDS\n",
      "ResUnit_L3_NotAttnModule_6_NoDS\n",
      "ResUnit_L4_NotAttnModule_6_NoDS\n",
      "ResUnit_L5_NotAttnModule_6_NoDS\n",
      "ResUnit_L6_NotAttnModule_6_NoDS\n",
      "ResUnit_L7_NotAttnModule_6_NoDS\n",
      "ResUnit_L8_NotAttnModule_6_NoDS\n",
      "ResUnit_L9_NotAttnModule_6_NoDS\n",
      "ResUnit_L10_NotAttnModule_6_NoDS\n",
      "ResUnit_L11_NotAttnModule_6_NoDS\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Model_Input (InputLayer)       [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " Conv1_In (Conv2D)              (None, 32, 32, 32)   896         ['Model_Input[0][0]']            \n",
      "                                                                                                  \n",
      " BN_In (BatchNormalization)     (None, 32, 32, 32)   128         ['Conv1_In[0][0]']               \n",
      "                                                                                                  \n",
      " ReLU_In (Activation)           (None, 32, 32, 32)   0           ['BN_In[0][0]']                  \n",
      "                                                                                                  \n",
      " ResUnit_L1_NotAttnModule_1_NoD  (None, 32, 32, 32)  128         ['ReLU_In[0][0]']                \n",
      " S (BatchNormalization)                                                                           \n",
      "                                                                                                  \n",
      " ResUnit_L2_NotAttnModule_1_NoD  (None, 32, 32, 32)  0           ['ResUnit_L1_NotAttnModule_1_NoDS\n",
      " S (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L3_NotAttnModule_1_NoD  (None, 32, 32, 16)  528         ['ResUnit_L2_NotAttnModule_1_NoDS\n",
      " S (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L4_NotAttnModule_1_NoD  (None, 32, 32, 16)  64          ['ResUnit_L3_NotAttnModule_1_NoDS\n",
      " S (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L5_NotAttnModule_1_NoD  (None, 32, 32, 16)  0           ['ResUnit_L4_NotAttnModule_1_NoDS\n",
      " S (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L6_NotAttnModule_1_NoD  (None, 32, 32, 16)  2320        ['ResUnit_L5_NotAttnModule_1_NoDS\n",
      " S (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L7_NotAttnModule_1_NoD  (None, 32, 32, 16)  64          ['ResUnit_L6_NotAttnModule_1_NoDS\n",
      " S (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L8_NotAttnModule_1_NoD  (None, 32, 32, 16)  0           ['ResUnit_L7_NotAttnModule_1_NoDS\n",
      " S (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L9_NotAttnModule_1_NoD  (None, 32, 32, 64)  1088        ['ResUnit_L8_NotAttnModule_1_NoDS\n",
      " S (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_NotAttnModule_1_No  (None, 32, 32, 64)  2112        ['ResUnit_L2_NotAttnModule_1_NoDS\n",
      " DS (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L11_NotAttnModule_1_No  (None, 32, 32, 64)  0           ['ResUnit_L9_NotAttnModule_1_NoDS\n",
      " DS (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_NotAttnModule_1_NoD\n",
      "                                                                 S[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L1_Input-p-1-1_AttnS1-  (None, 32, 32, 64)  256         ['ResUnit_L11_NotAttnModule_1_NoD\n",
      " 1 (BatchNormalization)                                          S[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L2_Input-p-1-1_AttnS1-  (None, 32, 32, 64)  0           ['ResUnit_L1_Input-p-1-1_AttnS1-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L3_Input-p-1-1_AttnS1-  (None, 32, 32, 16)  1040        ['ResUnit_L2_Input-p-1-1_AttnS1-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L4_Input-p-1-1_AttnS1-  (None, 32, 32, 16)  64          ['ResUnit_L3_Input-p-1-1_AttnS1-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L5_Input-p-1-1_AttnS1-  (None, 32, 32, 16)  0           ['ResUnit_L4_Input-p-1-1_AttnS1-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L6_Input-p-1-1_AttnS1-  (None, 32, 32, 16)  2320        ['ResUnit_L5_Input-p-1-1_AttnS1-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L7_Input-p-1-1_AttnS1-  (None, 32, 32, 16)  64          ['ResUnit_L6_Input-p-1-1_AttnS1-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L8_Input-p-1-1_AttnS1-  (None, 32, 32, 16)  0           ['ResUnit_L7_Input-p-1-1_AttnS1-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L9_Input-p-1-1_AttnS1-  (None, 32, 32, 64)  1088        ['ResUnit_L8_Input-p-1-1_AttnS1-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_Input-p-1-1_AttnS1  (None, 32, 32, 64)  4160        ['ResUnit_L2_Input-p-1-1_AttnS1-1\n",
      " -1 (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L11_Input-p-1-1_AttnS1  (None, 32, 32, 64)  0           ['ResUnit_L9_Input-p-1-1_AttnS1-1\n",
      " -1 (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_Input-p-1-1_AttnS1-\n",
      "                                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " MaxPool_DownSamp-1_Mask_AttnS1  (None, 16, 16, 64)  0           ['ResUnit_L11_Input-p-1-1_AttnS1-\n",
      " -1 (MaxPooling2D)                                               1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L1_DownSamp-r-1-1_Mask  (None, 16, 16, 64)  256         ['MaxPool_DownSamp-1_Mask_AttnS1-\n",
      " _AttnS1-1 (BatchNormalization)                                  1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L2_DownSamp-r-1-1_Mask  (None, 16, 16, 64)  0           ['ResUnit_L1_DownSamp-r-1-1_Mask_\n",
      " _AttnS1-1 (Activation)                                          AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L3_DownSamp-r-1-1_Mask  (None, 16, 16, 16)  1040        ['ResUnit_L2_DownSamp-r-1-1_Mask_\n",
      " _AttnS1-1 (Conv2D)                                              AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L4_DownSamp-r-1-1_Mask  (None, 16, 16, 16)  64          ['ResUnit_L3_DownSamp-r-1-1_Mask_\n",
      " _AttnS1-1 (BatchNormalization)                                  AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L5_DownSamp-r-1-1_Mask  (None, 16, 16, 16)  0           ['ResUnit_L4_DownSamp-r-1-1_Mask_\n",
      " _AttnS1-1 (Activation)                                          AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L6_DownSamp-r-1-1_Mask  (None, 16, 16, 16)  2320        ['ResUnit_L5_DownSamp-r-1-1_Mask_\n",
      " _AttnS1-1 (Conv2D)                                              AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L7_DownSamp-r-1-1_Mask  (None, 16, 16, 16)  64          ['ResUnit_L6_DownSamp-r-1-1_Mask_\n",
      " _AttnS1-1 (BatchNormalization)                                  AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L8_DownSamp-r-1-1_Mask  (None, 16, 16, 16)  0           ['ResUnit_L7_DownSamp-r-1-1_Mask_\n",
      " _AttnS1-1 (Activation)                                          AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L9_DownSamp-r-1-1_Mask  (None, 16, 16, 64)  1088        ['ResUnit_L8_DownSamp-r-1-1_Mask_\n",
      " _AttnS1-1 (Conv2D)                                              AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L10_DownSamp-r-1-1_Mas  (None, 16, 16, 64)  4160        ['ResUnit_L2_DownSamp-r-1-1_Mask_\n",
      " k_AttnS1-1 (Conv2D)                                             AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L11_DownSamp-r-1-1_Mas  (None, 16, 16, 64)  0           ['ResUnit_L9_DownSamp-r-1-1_Mask_\n",
      " k_AttnS1-1 (Add)                                                AttnS1-1[0][0]',                 \n",
      "                                                                  'ResUnit_L10_DownSamp-r-1-1_Mask\n",
      "                                                                 _AttnS1-1[0][0]']                \n",
      "                                                                                                  \n",
      " MaxPool_DownSamp-2_Mask_AttnS1  (None, 8, 8, 64)    0           ['ResUnit_L11_DownSamp-r-1-1_Mask\n",
      " -1 (MaxPooling2D)                                               _AttnS1-1[0][0]']                \n",
      "                                                                                                  \n",
      " ResUnit_L1_Mid-2r-2-1_Mask_Att  (None, 8, 8, 64)    256         ['MaxPool_DownSamp-2_Mask_AttnS1-\n",
      " nS1-1 (BatchNormalization)                                      1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L2_Mid-2r-2-1_Mask_Att  (None, 8, 8, 64)    0           ['ResUnit_L1_Mid-2r-2-1_Mask_Attn\n",
      " nS1-1 (Activation)                                              S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L3_Mid-2r-2-1_Mask_Att  (None, 8, 8, 16)    1040        ['ResUnit_L2_Mid-2r-2-1_Mask_Attn\n",
      " nS1-1 (Conv2D)                                                  S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L4_Mid-2r-2-1_Mask_Att  (None, 8, 8, 16)    64          ['ResUnit_L3_Mid-2r-2-1_Mask_Attn\n",
      " nS1-1 (BatchNormalization)                                      S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L5_Mid-2r-2-1_Mask_Att  (None, 8, 8, 16)    0           ['ResUnit_L4_Mid-2r-2-1_Mask_Attn\n",
      " nS1-1 (Activation)                                              S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L6_Mid-2r-2-1_Mask_Att  (None, 8, 8, 16)    2320        ['ResUnit_L5_Mid-2r-2-1_Mask_Attn\n",
      " nS1-1 (Conv2D)                                                  S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L7_Mid-2r-2-1_Mask_Att  (None, 8, 8, 16)    64          ['ResUnit_L6_Mid-2r-2-1_Mask_Attn\n",
      " nS1-1 (BatchNormalization)                                      S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L8_Mid-2r-2-1_Mask_Att  (None, 8, 8, 16)    0           ['ResUnit_L7_Mid-2r-2-1_Mask_Attn\n",
      " nS1-1 (Activation)                                              S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L9_Mid-2r-2-1_Mask_Att  (None, 8, 8, 64)    1088        ['ResUnit_L8_Mid-2r-2-1_Mask_Attn\n",
      " nS1-1 (Conv2D)                                                  S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L10_Mid-2r-2-1_Mask_At  (None, 8, 8, 64)    4160        ['ResUnit_L2_Mid-2r-2-1_Mask_Attn\n",
      " tnS1-1 (Conv2D)                                                 S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L11_Mid-2r-2-1_Mask_At  (None, 8, 8, 64)    0           ['ResUnit_L9_Mid-2r-2-1_Mask_Attn\n",
      " tnS1-1 (Add)                                                    S1-1[0][0]',                     \n",
      "                                                                  'ResUnit_L10_Mid-2r-2-1_Mask_Att\n",
      "                                                                 nS1-1[0][0]']                    \n",
      "                                                                                                  \n",
      " ResUnit_L1_Mid-2r-2-2_Mask_Att  (None, 8, 8, 64)    256         ['ResUnit_L11_Mid-2r-2-1_Mask_Att\n",
      " nS1-1 (BatchNormalization)                                      nS1-1[0][0]']                    \n",
      "                                                                                                  \n",
      " ResUnit_L1_SkipConn-Inner_Mask  (None, 16, 16, 64)  256         ['ResUnit_L11_DownSamp-r-1-1_Mask\n",
      " _AttnS1-1 (BatchNormalization)                                  _AttnS1-1[0][0]']                \n",
      "                                                                                                  \n",
      " ResUnit_L2_Mid-2r-2-2_Mask_Att  (None, 8, 8, 64)    0           ['ResUnit_L1_Mid-2r-2-2_Mask_Attn\n",
      " nS1-1 (Activation)                                              S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L2_SkipConn-Inner_Mask  (None, 16, 16, 64)  0           ['ResUnit_L1_SkipConn-Inner_Mask_\n",
      " _AttnS1-1 (Activation)                                          AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L3_Mid-2r-2-2_Mask_Att  (None, 8, 8, 16)    1040        ['ResUnit_L2_Mid-2r-2-2_Mask_Attn\n",
      " nS1-1 (Conv2D)                                                  S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L3_SkipConn-Inner_Mask  (None, 16, 16, 16)  1040        ['ResUnit_L2_SkipConn-Inner_Mask_\n",
      " _AttnS1-1 (Conv2D)                                              AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L4_Mid-2r-2-2_Mask_Att  (None, 8, 8, 16)    64          ['ResUnit_L3_Mid-2r-2-2_Mask_Attn\n",
      " nS1-1 (BatchNormalization)                                      S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L4_SkipConn-Inner_Mask  (None, 16, 16, 16)  64          ['ResUnit_L3_SkipConn-Inner_Mask_\n",
      " _AttnS1-1 (BatchNormalization)                                  AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L5_Mid-2r-2-2_Mask_Att  (None, 8, 8, 16)    0           ['ResUnit_L4_Mid-2r-2-2_Mask_Attn\n",
      " nS1-1 (Activation)                                              S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L5_SkipConn-Inner_Mask  (None, 16, 16, 16)  0           ['ResUnit_L4_SkipConn-Inner_Mask_\n",
      " _AttnS1-1 (Activation)                                          AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L6_Mid-2r-2-2_Mask_Att  (None, 8, 8, 16)    2320        ['ResUnit_L5_Mid-2r-2-2_Mask_Attn\n",
      " nS1-1 (Conv2D)                                                  S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L6_SkipConn-Inner_Mask  (None, 16, 16, 16)  2320        ['ResUnit_L5_SkipConn-Inner_Mask_\n",
      " _AttnS1-1 (Conv2D)                                              AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L7_Mid-2r-2-2_Mask_Att  (None, 8, 8, 16)    64          ['ResUnit_L6_Mid-2r-2-2_Mask_Attn\n",
      " nS1-1 (BatchNormalization)                                      S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L7_SkipConn-Inner_Mask  (None, 16, 16, 16)  64          ['ResUnit_L6_SkipConn-Inner_Mask_\n",
      " _AttnS1-1 (BatchNormalization)                                  AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L8_Mid-2r-2-2_Mask_Att  (None, 8, 8, 16)    0           ['ResUnit_L7_Mid-2r-2-2_Mask_Attn\n",
      " nS1-1 (Activation)                                              S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L8_SkipConn-Inner_Mask  (None, 16, 16, 16)  0           ['ResUnit_L7_SkipConn-Inner_Mask_\n",
      " _AttnS1-1 (Activation)                                          AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L9_Mid-2r-2-2_Mask_Att  (None, 8, 8, 64)    1088        ['ResUnit_L8_Mid-2r-2-2_Mask_Attn\n",
      " nS1-1 (Conv2D)                                                  S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L10_Mid-2r-2-2_Mask_At  (None, 8, 8, 64)    4160        ['ResUnit_L2_Mid-2r-2-2_Mask_Attn\n",
      " tnS1-1 (Conv2D)                                                 S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L9_SkipConn-Inner_Mask  (None, 16, 16, 64)  1088        ['ResUnit_L8_SkipConn-Inner_Mask_\n",
      " _AttnS1-1 (Conv2D)                                              AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L10_SkipConn-Inner_Mas  (None, 16, 16, 64)  4160        ['ResUnit_L2_SkipConn-Inner_Mask_\n",
      " k_AttnS1-1 (Conv2D)                                             AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L11_Mid-2r-2-2_Mask_At  (None, 8, 8, 64)    0           ['ResUnit_L9_Mid-2r-2-2_Mask_Attn\n",
      " tnS1-1 (Add)                                                    S1-1[0][0]',                     \n",
      "                                                                  'ResUnit_L10_Mid-2r-2-2_Mask_Att\n",
      "                                                                 nS1-1[0][0]']                    \n",
      "                                                                                                  \n",
      " ResUnit_L11_SkipConn-Inner_Mas  (None, 16, 16, 64)  0           ['ResUnit_L9_SkipConn-Inner_Mask_\n",
      " k_AttnS1-1 (Add)                                                AttnS1-1[0][0]',                 \n",
      "                                                                  'ResUnit_L10_SkipConn-Inner_Mask\n",
      "                                                                 _AttnS1-1[0][0]']                \n",
      "                                                                                                  \n",
      " UpSamp2D-1_Mask_AttnS1-1 (UpSa  (None, 16, 16, 64)  0           ['ResUnit_L11_Mid-2r-2-2_Mask_Att\n",
      " mpling2D)                                                       nS1-1[0][0]']                    \n",
      "                                                                                                  \n",
      " Add_L1_AttnS1-1 (Add)          (None, 16, 16, 64)   0           ['ResUnit_L11_SkipConn-Inner_Mask\n",
      "                                                                 _AttnS1-1[0][0]',                \n",
      "                                                                  'UpSamp2D-1_Mask_AttnS1-1[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " ResUnit_L1_Trunk-t-2-1_AttnS1-  (None, 32, 32, 64)  256         ['ResUnit_L11_Input-p-1-1_AttnS1-\n",
      " 1 (BatchNormalization)                                          1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L1_SkipConn-Outer_Mask  (None, 16, 16, 64)  256         ['MaxPool_DownSamp-1_Mask_AttnS1-\n",
      " _AttnS1-1 (BatchNormalization)                                  1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L1_UpSamp-r-1-1_Mask_A  (None, 16, 16, 64)  256         ['Add_L1_AttnS1-1[0][0]']        \n",
      " ttnS1-1 (BatchNormalization)                                                                     \n",
      "                                                                                                  \n",
      " ResUnit_L2_Trunk-t-2-1_AttnS1-  (None, 32, 32, 64)  0           ['ResUnit_L1_Trunk-t-2-1_AttnS1-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L2_SkipConn-Outer_Mask  (None, 16, 16, 64)  0           ['ResUnit_L1_SkipConn-Outer_Mask_\n",
      " _AttnS1-1 (Activation)                                          AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L2_UpSamp-r-1-1_Mask_A  (None, 16, 16, 64)  0           ['ResUnit_L1_UpSamp-r-1-1_Mask_At\n",
      " ttnS1-1 (Activation)                                            tnS1-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L3_Trunk-t-2-1_AttnS1-  (None, 32, 32, 16)  1040        ['ResUnit_L2_Trunk-t-2-1_AttnS1-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L3_SkipConn-Outer_Mask  (None, 16, 16, 16)  1040        ['ResUnit_L2_SkipConn-Outer_Mask_\n",
      " _AttnS1-1 (Conv2D)                                              AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L3_UpSamp-r-1-1_Mask_A  (None, 16, 16, 16)  1040        ['ResUnit_L2_UpSamp-r-1-1_Mask_At\n",
      " ttnS1-1 (Conv2D)                                                tnS1-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L4_Trunk-t-2-1_AttnS1-  (None, 32, 32, 16)  64          ['ResUnit_L3_Trunk-t-2-1_AttnS1-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L4_SkipConn-Outer_Mask  (None, 16, 16, 16)  64          ['ResUnit_L3_SkipConn-Outer_Mask_\n",
      " _AttnS1-1 (BatchNormalization)                                  AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L4_UpSamp-r-1-1_Mask_A  (None, 16, 16, 16)  64          ['ResUnit_L3_UpSamp-r-1-1_Mask_At\n",
      " ttnS1-1 (BatchNormalization)                                    tnS1-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L5_Trunk-t-2-1_AttnS1-  (None, 32, 32, 16)  0           ['ResUnit_L4_Trunk-t-2-1_AttnS1-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L5_SkipConn-Outer_Mask  (None, 16, 16, 16)  0           ['ResUnit_L4_SkipConn-Outer_Mask_\n",
      " _AttnS1-1 (Activation)                                          AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L5_UpSamp-r-1-1_Mask_A  (None, 16, 16, 16)  0           ['ResUnit_L4_UpSamp-r-1-1_Mask_At\n",
      " ttnS1-1 (Activation)                                            tnS1-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L6_Trunk-t-2-1_AttnS1-  (None, 32, 32, 16)  2320        ['ResUnit_L5_Trunk-t-2-1_AttnS1-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L6_SkipConn-Outer_Mask  (None, 16, 16, 16)  2320        ['ResUnit_L5_SkipConn-Outer_Mask_\n",
      " _AttnS1-1 (Conv2D)                                              AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L6_UpSamp-r-1-1_Mask_A  (None, 16, 16, 16)  2320        ['ResUnit_L5_UpSamp-r-1-1_Mask_At\n",
      " ttnS1-1 (Conv2D)                                                tnS1-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L7_Trunk-t-2-1_AttnS1-  (None, 32, 32, 16)  64          ['ResUnit_L6_Trunk-t-2-1_AttnS1-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L7_SkipConn-Outer_Mask  (None, 16, 16, 16)  64          ['ResUnit_L6_SkipConn-Outer_Mask_\n",
      " _AttnS1-1 (BatchNormalization)                                  AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L7_UpSamp-r-1-1_Mask_A  (None, 16, 16, 16)  64          ['ResUnit_L6_UpSamp-r-1-1_Mask_At\n",
      " ttnS1-1 (BatchNormalization)                                    tnS1-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L8_Trunk-t-2-1_AttnS1-  (None, 32, 32, 16)  0           ['ResUnit_L7_Trunk-t-2-1_AttnS1-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L8_SkipConn-Outer_Mask  (None, 16, 16, 16)  0           ['ResUnit_L7_SkipConn-Outer_Mask_\n",
      " _AttnS1-1 (Activation)                                          AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L8_UpSamp-r-1-1_Mask_A  (None, 16, 16, 16)  0           ['ResUnit_L7_UpSamp-r-1-1_Mask_At\n",
      " ttnS1-1 (Activation)                                            tnS1-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L9_Trunk-t-2-1_AttnS1-  (None, 32, 32, 64)  1088        ['ResUnit_L8_Trunk-t-2-1_AttnS1-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_Trunk-t-2-1_AttnS1  (None, 32, 32, 64)  4160        ['ResUnit_L2_Trunk-t-2-1_AttnS1-1\n",
      " -1 (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L9_SkipConn-Outer_Mask  (None, 16, 16, 64)  1088        ['ResUnit_L8_SkipConn-Outer_Mask_\n",
      " _AttnS1-1 (Conv2D)                                              AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L10_SkipConn-Outer_Mas  (None, 16, 16, 64)  4160        ['ResUnit_L2_SkipConn-Outer_Mask_\n",
      " k_AttnS1-1 (Conv2D)                                             AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L9_UpSamp-r-1-1_Mask_A  (None, 16, 16, 64)  1088        ['ResUnit_L8_UpSamp-r-1-1_Mask_At\n",
      " ttnS1-1 (Conv2D)                                                tnS1-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L10_UpSamp-r-1-1_Mask_  (None, 16, 16, 64)  4160        ['ResUnit_L2_UpSamp-r-1-1_Mask_At\n",
      " AttnS1-1 (Conv2D)                                               tnS1-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L11_Trunk-t-2-1_AttnS1  (None, 32, 32, 64)  0           ['ResUnit_L9_Trunk-t-2-1_AttnS1-1\n",
      " -1 (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_Trunk-t-2-1_AttnS1-\n",
      "                                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L11_SkipConn-Outer_Mas  (None, 16, 16, 64)  0           ['ResUnit_L9_SkipConn-Outer_Mask_\n",
      " k_AttnS1-1 (Add)                                                AttnS1-1[0][0]',                 \n",
      "                                                                  'ResUnit_L10_SkipConn-Outer_Mask\n",
      "                                                                 _AttnS1-1[0][0]']                \n",
      "                                                                                                  \n",
      " ResUnit_L11_UpSamp-r-1-1_Mask_  (None, 16, 16, 64)  0           ['ResUnit_L9_UpSamp-r-1-1_Mask_At\n",
      " AttnS1-1 (Add)                                                  tnS1-1[0][0]',                   \n",
      "                                                                  'ResUnit_L10_UpSamp-r-1-1_Mask_A\n",
      "                                                                 ttnS1-1[0][0]']                  \n",
      "                                                                                                  \n",
      " ResUnit_L1_Trunk-t-2-2_AttnS1-  (None, 32, 32, 64)  256         ['ResUnit_L11_Trunk-t-2-1_AttnS1-\n",
      " 1 (BatchNormalization)                                          1[0][0]']                        \n",
      "                                                                                                  \n",
      " Add_L2_AttnS1-1 (Add)          (None, 16, 16, 64)   0           ['ResUnit_L11_SkipConn-Outer_Mask\n",
      "                                                                 _AttnS1-1[0][0]',                \n",
      "                                                                  'ResUnit_L11_UpSamp-r-1-1_Mask_A\n",
      "                                                                 ttnS1-1[0][0]']                  \n",
      "                                                                                                  \n",
      " ResUnit_L2_Trunk-t-2-2_AttnS1-  (None, 32, 32, 64)  0           ['ResUnit_L1_Trunk-t-2-2_AttnS1-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " UpSamp2D-2_Mask_AttnS1-1 (UpSa  (None, 32, 32, 64)  0           ['Add_L2_AttnS1-1[0][0]']        \n",
      " mpling2D)                                                                                        \n",
      "                                                                                                  \n",
      " ResUnit_L3_Trunk-t-2-2_AttnS1-  (None, 32, 32, 16)  1040        ['ResUnit_L2_Trunk-t-2-2_AttnS1-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L1_Attn_S2-1 (Bat  (None, 32, 32, 64)  256         ['UpSamp2D-2_Mask_AttnS1-1[0][0]'\n",
      " chNormalization)                                                ]                                \n",
      "                                                                                                  \n",
      " ResUnit_L4_Trunk-t-2-2_AttnS1-  (None, 32, 32, 16)  64          ['ResUnit_L3_Trunk-t-2-2_AttnS1-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L2_Attn_S2-1 (Act  (None, 32, 32, 64)  0           ['SpcConv_Mask_L1_Attn_S2-1[0][0]\n",
      " ivation)                                                        ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L5_Trunk-t-2-2_AttnS1-  (None, 32, 32, 16)  0           ['ResUnit_L4_Trunk-t-2-2_AttnS1-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L3_Attn_S2-1 (Con  (None, 32, 32, 64)  4160        ['SpcConv_Mask_L2_Attn_S2-1[0][0]\n",
      " v2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L6_Trunk-t-2-2_AttnS1-  (None, 32, 32, 16)  2320        ['ResUnit_L5_Trunk-t-2-2_AttnS1-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L4_Attn_S2-1 (Bat  (None, 32, 32, 64)  256         ['SpcConv_Mask_L3_Attn_S2-1[0][0]\n",
      " chNormalization)                                                ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L7_Trunk-t-2-2_AttnS1-  (None, 32, 32, 16)  64          ['ResUnit_L6_Trunk-t-2-2_AttnS1-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L5_Attn_S2-1 (Act  (None, 32, 32, 64)  0           ['SpcConv_Mask_L4_Attn_S2-1[0][0]\n",
      " ivation)                                                        ',                               \n",
      "                                                                  'SpcConv_Mask_L5_Attn_S2-1[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L8_Trunk-t-2-2_AttnS1-  (None, 32, 32, 16)  0           ['ResUnit_L7_Trunk-t-2-2_AttnS1-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L9_Trunk-t-2-2_AttnS1-  (None, 32, 32, 64)  1088        ['ResUnit_L8_Trunk-t-2-2_AttnS1-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_Trunk-t-2-2_AttnS1  (None, 32, 32, 64)  4160        ['ResUnit_L2_Trunk-t-2-2_AttnS1-1\n",
      " -1 (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L7_Attn_S2-1 (Act  (None, 32, 32, 64)  0           ['SpcConv_Mask_L5_Attn_S2-1[1][0]\n",
      " ivation)                                                        ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L11_Trunk-t-2-2_AttnS1  (None, 32, 32, 64)  0           ['ResUnit_L9_Trunk-t-2-2_AttnS1-1\n",
      " -1 (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_Trunk-t-2-2_AttnS1-\n",
      "                                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " Mult_L1_AttnS1-1 (Multiply)    (None, 32, 32, 64)   0           ['SpcConv_Mask_L7_Attn_S2-1[0][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'ResUnit_L11_Trunk-t-2-2_AttnS1-\n",
      "                                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " Add_L3_AttnS1-1 (Add)          (None, 32, 32, 64)   0           ['Mult_L1_AttnS1-1[0][0]',       \n",
      "                                                                  'ResUnit_L11_Trunk-t-2-2_AttnS1-\n",
      "                                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L1_Output-p-1-1_AttnS1  (None, 32, 32, 64)  256         ['Add_L3_AttnS1-1[0][0]']        \n",
      " -1 (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " ResUnit_L2_Output-p-1-1_AttnS1  (None, 32, 32, 64)  0           ['ResUnit_L1_Output-p-1-1_AttnS1-\n",
      " -1 (Activation)                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L3_Output-p-1-1_AttnS1  (None, 32, 32, 16)  1040        ['ResUnit_L2_Output-p-1-1_AttnS1-\n",
      " -1 (Conv2D)                                                     1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L4_Output-p-1-1_AttnS1  (None, 32, 32, 16)  64          ['ResUnit_L3_Output-p-1-1_AttnS1-\n",
      " -1 (BatchNormalization)                                         1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L5_Output-p-1-1_AttnS1  (None, 32, 32, 16)  0           ['ResUnit_L4_Output-p-1-1_AttnS1-\n",
      " -1 (Activation)                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L6_Output-p-1-1_AttnS1  (None, 32, 32, 16)  2320        ['ResUnit_L5_Output-p-1-1_AttnS1-\n",
      " -1 (Conv2D)                                                     1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L7_Output-p-1-1_AttnS1  (None, 32, 32, 16)  64          ['ResUnit_L6_Output-p-1-1_AttnS1-\n",
      " -1 (BatchNormalization)                                         1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L8_Output-p-1-1_AttnS1  (None, 32, 32, 16)  0           ['ResUnit_L7_Output-p-1-1_AttnS1-\n",
      " -1 (Activation)                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L9_Output-p-1-1_AttnS1  (None, 32, 32, 64)  1088        ['ResUnit_L8_Output-p-1-1_AttnS1-\n",
      " -1 (Conv2D)                                                     1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L10_Output-p-1-1_AttnS  (None, 32, 32, 64)  4160        ['ResUnit_L2_Output-p-1-1_AttnS1-\n",
      " 1-1 (Conv2D)                                                    1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L11_Output-p-1-1_AttnS  (None, 32, 32, 64)  0           ['ResUnit_L9_Output-p-1-1_AttnS1-\n",
      " 1-1 (Add)                                                       1[0][0]',                        \n",
      "                                                                  'ResUnit_L10_Output-p-1-1_AttnS1\n",
      "                                                                 -1[0][0]']                       \n",
      "                                                                                                  \n",
      " ResUnit_L1_NotAttnModule_2_DS   (None, 32, 32, 64)  256         ['ResUnit_L11_Output-p-1-1_AttnS1\n",
      " (BatchNormalization)                                            -1[0][0]']                       \n",
      "                                                                                                  \n",
      " ResUnit_L2_NotAttnModule_2_DS   (None, 32, 32, 64)  0           ['ResUnit_L1_NotAttnModule_2_DS[0\n",
      " (Activation)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L3_NotAttnModule_2_DS   (None, 32, 32, 32)  2080        ['ResUnit_L2_NotAttnModule_2_DS[0\n",
      " (Conv2D)                                                        ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L4_NotAttnModule_2_DS   (None, 32, 32, 32)  128         ['ResUnit_L3_NotAttnModule_2_DS[0\n",
      " (BatchNormalization)                                            ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L5_NotAttnModule_2_DS   (None, 32, 32, 32)  0           ['ResUnit_L4_NotAttnModule_2_DS[0\n",
      " (Activation)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L6_NotAttnModule_2_DS   (None, 16, 16, 32)  9248        ['ResUnit_L5_NotAttnModule_2_DS[0\n",
      " (Conv2D)                                                        ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L7_NotAttnModule_2_DS   (None, 16, 16, 32)  128         ['ResUnit_L6_NotAttnModule_2_DS[0\n",
      " (BatchNormalization)                                            ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L8_NotAttnModule_2_DS   (None, 16, 16, 32)  0           ['ResUnit_L7_NotAttnModule_2_DS[0\n",
      " (Activation)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L9_NotAttnModule_2_DS   (None, 16, 16, 128)  4224       ['ResUnit_L8_NotAttnModule_2_DS[0\n",
      " (Conv2D)                                                        ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L10_NotAttnModule_2_DS  (None, 16, 16, 128)  8320       ['ResUnit_L2_NotAttnModule_2_DS[0\n",
      "  (Conv2D)                                                       ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L11_NotAttnModule_2_DS  (None, 16, 16, 128)  0          ['ResUnit_L9_NotAttnModule_2_DS[0\n",
      "  (Add)                                                          ][0]',                           \n",
      "                                                                  'ResUnit_L10_NotAttnModule_2_DS[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " ResUnit_L1_Input-p-1-1_AttnS2-  (None, 16, 16, 128)  512        ['ResUnit_L11_NotAttnModule_2_DS[\n",
      " 1 (BatchNormalization)                                          0][0]']                          \n",
      "                                                                                                  \n",
      " ResUnit_L2_Input-p-1-1_AttnS2-  (None, 16, 16, 128)  0          ['ResUnit_L1_Input-p-1-1_AttnS2-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L3_Input-p-1-1_AttnS2-  (None, 16, 16, 32)  4128        ['ResUnit_L2_Input-p-1-1_AttnS2-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L4_Input-p-1-1_AttnS2-  (None, 16, 16, 32)  128         ['ResUnit_L3_Input-p-1-1_AttnS2-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L5_Input-p-1-1_AttnS2-  (None, 16, 16, 32)  0           ['ResUnit_L4_Input-p-1-1_AttnS2-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L6_Input-p-1-1_AttnS2-  (None, 16, 16, 32)  9248        ['ResUnit_L5_Input-p-1-1_AttnS2-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L7_Input-p-1-1_AttnS2-  (None, 16, 16, 32)  128         ['ResUnit_L6_Input-p-1-1_AttnS2-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L8_Input-p-1-1_AttnS2-  (None, 16, 16, 32)  0           ['ResUnit_L7_Input-p-1-1_AttnS2-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L9_Input-p-1-1_AttnS2-  (None, 16, 16, 128)  4224       ['ResUnit_L8_Input-p-1-1_AttnS2-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_Input-p-1-1_AttnS2  (None, 16, 16, 128)  16512      ['ResUnit_L2_Input-p-1-1_AttnS2-1\n",
      " -1 (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L11_Input-p-1-1_AttnS2  (None, 16, 16, 128)  0          ['ResUnit_L9_Input-p-1-1_AttnS2-1\n",
      " -1 (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_Input-p-1-1_AttnS2-\n",
      "                                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " MaxPool_DownSamp-1_Mask_AttnS2  (None, 8, 8, 128)   0           ['ResUnit_L11_Input-p-1-1_AttnS2-\n",
      " -1 (MaxPooling2D)                                               1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L1_DownSamp-r-1-1_Mask  (None, 8, 8, 128)   512         ['MaxPool_DownSamp-1_Mask_AttnS2-\n",
      " _AttnS2-1 (BatchNormalization)                                  1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L2_DownSamp-r-1-1_Mask  (None, 8, 8, 128)   0           ['ResUnit_L1_DownSamp-r-1-1_Mask_\n",
      " _AttnS2-1 (Activation)                                          AttnS2-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L3_DownSamp-r-1-1_Mask  (None, 8, 8, 32)    4128        ['ResUnit_L2_DownSamp-r-1-1_Mask_\n",
      " _AttnS2-1 (Conv2D)                                              AttnS2-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L4_DownSamp-r-1-1_Mask  (None, 8, 8, 32)    128         ['ResUnit_L3_DownSamp-r-1-1_Mask_\n",
      " _AttnS2-1 (BatchNormalization)                                  AttnS2-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L5_DownSamp-r-1-1_Mask  (None, 8, 8, 32)    0           ['ResUnit_L4_DownSamp-r-1-1_Mask_\n",
      " _AttnS2-1 (Activation)                                          AttnS2-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L6_DownSamp-r-1-1_Mask  (None, 8, 8, 32)    9248        ['ResUnit_L5_DownSamp-r-1-1_Mask_\n",
      " _AttnS2-1 (Conv2D)                                              AttnS2-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L7_DownSamp-r-1-1_Mask  (None, 8, 8, 32)    128         ['ResUnit_L6_DownSamp-r-1-1_Mask_\n",
      " _AttnS2-1 (BatchNormalization)                                  AttnS2-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L8_DownSamp-r-1-1_Mask  (None, 8, 8, 32)    0           ['ResUnit_L7_DownSamp-r-1-1_Mask_\n",
      " _AttnS2-1 (Activation)                                          AttnS2-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L9_DownSamp-r-1-1_Mask  (None, 8, 8, 128)   4224        ['ResUnit_L8_DownSamp-r-1-1_Mask_\n",
      " _AttnS2-1 (Conv2D)                                              AttnS2-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L10_DownSamp-r-1-1_Mas  (None, 8, 8, 128)   16512       ['ResUnit_L2_DownSamp-r-1-1_Mask_\n",
      " k_AttnS2-1 (Conv2D)                                             AttnS2-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L11_DownSamp-r-1-1_Mas  (None, 8, 8, 128)   0           ['ResUnit_L9_DownSamp-r-1-1_Mask_\n",
      " k_AttnS2-1 (Add)                                                AttnS2-1[0][0]',                 \n",
      "                                                                  'ResUnit_L10_DownSamp-r-1-1_Mask\n",
      "                                                                 _AttnS2-1[0][0]']                \n",
      "                                                                                                  \n",
      " MaxPool_DownSamp-2_Mask_AttnS2  (None, 4, 4, 128)   0           ['ResUnit_L11_DownSamp-r-1-1_Mask\n",
      " -1 (MaxPooling2D)                                               _AttnS2-1[0][0]']                \n",
      "                                                                                                  \n",
      " ResUnit_L1_Mid-2r-2-1_Mask_Att  (None, 4, 4, 128)   512         ['MaxPool_DownSamp-2_Mask_AttnS2-\n",
      " nS2-1 (BatchNormalization)                                      1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L2_Mid-2r-2-1_Mask_Att  (None, 4, 4, 128)   0           ['ResUnit_L1_Mid-2r-2-1_Mask_Attn\n",
      " nS2-1 (Activation)                                              S2-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L3_Mid-2r-2-1_Mask_Att  (None, 4, 4, 32)    4128        ['ResUnit_L2_Mid-2r-2-1_Mask_Attn\n",
      " nS2-1 (Conv2D)                                                  S2-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L4_Mid-2r-2-1_Mask_Att  (None, 4, 4, 32)    128         ['ResUnit_L3_Mid-2r-2-1_Mask_Attn\n",
      " nS2-1 (BatchNormalization)                                      S2-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L5_Mid-2r-2-1_Mask_Att  (None, 4, 4, 32)    0           ['ResUnit_L4_Mid-2r-2-1_Mask_Attn\n",
      " nS2-1 (Activation)                                              S2-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L6_Mid-2r-2-1_Mask_Att  (None, 4, 4, 32)    9248        ['ResUnit_L5_Mid-2r-2-1_Mask_Attn\n",
      " nS2-1 (Conv2D)                                                  S2-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L7_Mid-2r-2-1_Mask_Att  (None, 4, 4, 32)    128         ['ResUnit_L6_Mid-2r-2-1_Mask_Attn\n",
      " nS2-1 (BatchNormalization)                                      S2-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L8_Mid-2r-2-1_Mask_Att  (None, 4, 4, 32)    0           ['ResUnit_L7_Mid-2r-2-1_Mask_Attn\n",
      " nS2-1 (Activation)                                              S2-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L9_Mid-2r-2-1_Mask_Att  (None, 4, 4, 128)   4224        ['ResUnit_L8_Mid-2r-2-1_Mask_Attn\n",
      " nS2-1 (Conv2D)                                                  S2-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L10_Mid-2r-2-1_Mask_At  (None, 4, 4, 128)   16512       ['ResUnit_L2_Mid-2r-2-1_Mask_Attn\n",
      " tnS2-1 (Conv2D)                                                 S2-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L11_Mid-2r-2-1_Mask_At  (None, 4, 4, 128)   0           ['ResUnit_L9_Mid-2r-2-1_Mask_Attn\n",
      " tnS2-1 (Add)                                                    S2-1[0][0]',                     \n",
      "                                                                  'ResUnit_L10_Mid-2r-2-1_Mask_Att\n",
      "                                                                 nS2-1[0][0]']                    \n",
      "                                                                                                  \n",
      " ResUnit_L1_Mid-2r-2-2_Mask_Att  (None, 4, 4, 128)   512         ['ResUnit_L11_Mid-2r-2-1_Mask_Att\n",
      " nS2-1 (BatchNormalization)                                      nS2-1[0][0]']                    \n",
      "                                                                                                  \n",
      " ResUnit_L1_SkipConn-Inner_Mask  (None, 8, 8, 128)   512         ['ResUnit_L11_DownSamp-r-1-1_Mask\n",
      " _AttnS2-1 (BatchNormalization)                                  _AttnS2-1[0][0]']                \n",
      "                                                                                                  \n",
      " ResUnit_L2_Mid-2r-2-2_Mask_Att  (None, 4, 4, 128)   0           ['ResUnit_L1_Mid-2r-2-2_Mask_Attn\n",
      " nS2-1 (Activation)                                              S2-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L2_SkipConn-Inner_Mask  (None, 8, 8, 128)   0           ['ResUnit_L1_SkipConn-Inner_Mask_\n",
      " _AttnS2-1 (Activation)                                          AttnS2-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L3_Mid-2r-2-2_Mask_Att  (None, 4, 4, 32)    4128        ['ResUnit_L2_Mid-2r-2-2_Mask_Attn\n",
      " nS2-1 (Conv2D)                                                  S2-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L3_SkipConn-Inner_Mask  (None, 8, 8, 32)    4128        ['ResUnit_L2_SkipConn-Inner_Mask_\n",
      " _AttnS2-1 (Conv2D)                                              AttnS2-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L4_Mid-2r-2-2_Mask_Att  (None, 4, 4, 32)    128         ['ResUnit_L3_Mid-2r-2-2_Mask_Attn\n",
      " nS2-1 (BatchNormalization)                                      S2-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L4_SkipConn-Inner_Mask  (None, 8, 8, 32)    128         ['ResUnit_L3_SkipConn-Inner_Mask_\n",
      " _AttnS2-1 (BatchNormalization)                                  AttnS2-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L5_Mid-2r-2-2_Mask_Att  (None, 4, 4, 32)    0           ['ResUnit_L4_Mid-2r-2-2_Mask_Attn\n",
      " nS2-1 (Activation)                                              S2-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L5_SkipConn-Inner_Mask  (None, 8, 8, 32)    0           ['ResUnit_L4_SkipConn-Inner_Mask_\n",
      " _AttnS2-1 (Activation)                                          AttnS2-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L6_Mid-2r-2-2_Mask_Att  (None, 4, 4, 32)    9248        ['ResUnit_L5_Mid-2r-2-2_Mask_Attn\n",
      " nS2-1 (Conv2D)                                                  S2-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L6_SkipConn-Inner_Mask  (None, 8, 8, 32)    9248        ['ResUnit_L5_SkipConn-Inner_Mask_\n",
      " _AttnS2-1 (Conv2D)                                              AttnS2-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L7_Mid-2r-2-2_Mask_Att  (None, 4, 4, 32)    128         ['ResUnit_L6_Mid-2r-2-2_Mask_Attn\n",
      " nS2-1 (BatchNormalization)                                      S2-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L7_SkipConn-Inner_Mask  (None, 8, 8, 32)    128         ['ResUnit_L6_SkipConn-Inner_Mask_\n",
      " _AttnS2-1 (BatchNormalization)                                  AttnS2-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L8_Mid-2r-2-2_Mask_Att  (None, 4, 4, 32)    0           ['ResUnit_L7_Mid-2r-2-2_Mask_Attn\n",
      " nS2-1 (Activation)                                              S2-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L8_SkipConn-Inner_Mask  (None, 8, 8, 32)    0           ['ResUnit_L7_SkipConn-Inner_Mask_\n",
      " _AttnS2-1 (Activation)                                          AttnS2-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L9_Mid-2r-2-2_Mask_Att  (None, 4, 4, 128)   4224        ['ResUnit_L8_Mid-2r-2-2_Mask_Attn\n",
      " nS2-1 (Conv2D)                                                  S2-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L10_Mid-2r-2-2_Mask_At  (None, 4, 4, 128)   16512       ['ResUnit_L2_Mid-2r-2-2_Mask_Attn\n",
      " tnS2-1 (Conv2D)                                                 S2-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L9_SkipConn-Inner_Mask  (None, 8, 8, 128)   4224        ['ResUnit_L8_SkipConn-Inner_Mask_\n",
      " _AttnS2-1 (Conv2D)                                              AttnS2-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L10_SkipConn-Inner_Mas  (None, 8, 8, 128)   16512       ['ResUnit_L2_SkipConn-Inner_Mask_\n",
      " k_AttnS2-1 (Conv2D)                                             AttnS2-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L11_Mid-2r-2-2_Mask_At  (None, 4, 4, 128)   0           ['ResUnit_L9_Mid-2r-2-2_Mask_Attn\n",
      " tnS2-1 (Add)                                                    S2-1[0][0]',                     \n",
      "                                                                  'ResUnit_L10_Mid-2r-2-2_Mask_Att\n",
      "                                                                 nS2-1[0][0]']                    \n",
      "                                                                                                  \n",
      " ResUnit_L11_SkipConn-Inner_Mas  (None, 8, 8, 128)   0           ['ResUnit_L9_SkipConn-Inner_Mask_\n",
      " k_AttnS2-1 (Add)                                                AttnS2-1[0][0]',                 \n",
      "                                                                  'ResUnit_L10_SkipConn-Inner_Mask\n",
      "                                                                 _AttnS2-1[0][0]']                \n",
      "                                                                                                  \n",
      " UpSamp2D-1_Mask_AttnS2-1 (UpSa  (None, 8, 8, 128)   0           ['ResUnit_L11_Mid-2r-2-2_Mask_Att\n",
      " mpling2D)                                                       nS2-1[0][0]']                    \n",
      "                                                                                                  \n",
      " ResUnit_L1_Trunk-t-2-1_AttnS2-  (None, 16, 16, 128)  512        ['ResUnit_L11_Input-p-1-1_AttnS2-\n",
      " 1 (BatchNormalization)                                          1[0][0]']                        \n",
      "                                                                                                  \n",
      " Add_L1_AttnS2-1 (Add)          (None, 8, 8, 128)    0           ['ResUnit_L11_SkipConn-Inner_Mask\n",
      "                                                                 _AttnS2-1[0][0]',                \n",
      "                                                                  'UpSamp2D-1_Mask_AttnS2-1[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " ResUnit_L2_Trunk-t-2-1_AttnS2-  (None, 16, 16, 128)  0          ['ResUnit_L1_Trunk-t-2-1_AttnS2-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L1_UpSamp-r-1-1_Mask_A  (None, 8, 8, 128)   512         ['Add_L1_AttnS2-1[0][0]']        \n",
      " ttnS2-1 (BatchNormalization)                                                                     \n",
      "                                                                                                  \n",
      " ResUnit_L3_Trunk-t-2-1_AttnS2-  (None, 16, 16, 32)  4128        ['ResUnit_L2_Trunk-t-2-1_AttnS2-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L2_UpSamp-r-1-1_Mask_A  (None, 8, 8, 128)   0           ['ResUnit_L1_UpSamp-r-1-1_Mask_At\n",
      " ttnS2-1 (Activation)                                            tnS2-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L4_Trunk-t-2-1_AttnS2-  (None, 16, 16, 32)  128         ['ResUnit_L3_Trunk-t-2-1_AttnS2-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L3_UpSamp-r-1-1_Mask_A  (None, 8, 8, 32)    4128        ['ResUnit_L2_UpSamp-r-1-1_Mask_At\n",
      " ttnS2-1 (Conv2D)                                                tnS2-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L5_Trunk-t-2-1_AttnS2-  (None, 16, 16, 32)  0           ['ResUnit_L4_Trunk-t-2-1_AttnS2-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L4_UpSamp-r-1-1_Mask_A  (None, 8, 8, 32)    128         ['ResUnit_L3_UpSamp-r-1-1_Mask_At\n",
      " ttnS2-1 (BatchNormalization)                                    tnS2-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L6_Trunk-t-2-1_AttnS2-  (None, 16, 16, 32)  9248        ['ResUnit_L5_Trunk-t-2-1_AttnS2-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L5_UpSamp-r-1-1_Mask_A  (None, 8, 8, 32)    0           ['ResUnit_L4_UpSamp-r-1-1_Mask_At\n",
      " ttnS2-1 (Activation)                                            tnS2-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L7_Trunk-t-2-1_AttnS2-  (None, 16, 16, 32)  128         ['ResUnit_L6_Trunk-t-2-1_AttnS2-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L6_UpSamp-r-1-1_Mask_A  (None, 8, 8, 32)    9248        ['ResUnit_L5_UpSamp-r-1-1_Mask_At\n",
      " ttnS2-1 (Conv2D)                                                tnS2-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L8_Trunk-t-2-1_AttnS2-  (None, 16, 16, 32)  0           ['ResUnit_L7_Trunk-t-2-1_AttnS2-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L7_UpSamp-r-1-1_Mask_A  (None, 8, 8, 32)    128         ['ResUnit_L6_UpSamp-r-1-1_Mask_At\n",
      " ttnS2-1 (BatchNormalization)                                    tnS2-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L9_Trunk-t-2-1_AttnS2-  (None, 16, 16, 128)  4224       ['ResUnit_L8_Trunk-t-2-1_AttnS2-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_Trunk-t-2-1_AttnS2  (None, 16, 16, 128)  16512      ['ResUnit_L2_Trunk-t-2-1_AttnS2-1\n",
      " -1 (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L8_UpSamp-r-1-1_Mask_A  (None, 8, 8, 32)    0           ['ResUnit_L7_UpSamp-r-1-1_Mask_At\n",
      " ttnS2-1 (Activation)                                            tnS2-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L11_Trunk-t-2-1_AttnS2  (None, 16, 16, 128)  0          ['ResUnit_L9_Trunk-t-2-1_AttnS2-1\n",
      " -1 (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_Trunk-t-2-1_AttnS2-\n",
      "                                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L9_UpSamp-r-1-1_Mask_A  (None, 8, 8, 128)   4224        ['ResUnit_L8_UpSamp-r-1-1_Mask_At\n",
      " ttnS2-1 (Conv2D)                                                tnS2-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L10_UpSamp-r-1-1_Mask_  (None, 8, 8, 128)   16512       ['ResUnit_L2_UpSamp-r-1-1_Mask_At\n",
      " AttnS2-1 (Conv2D)                                               tnS2-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L1_Trunk-t-2-2_AttnS2-  (None, 16, 16, 128)  512        ['ResUnit_L11_Trunk-t-2-1_AttnS2-\n",
      " 1 (BatchNormalization)                                          1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L11_UpSamp-r-1-1_Mask_  (None, 8, 8, 128)   0           ['ResUnit_L9_UpSamp-r-1-1_Mask_At\n",
      " AttnS2-1 (Add)                                                  tnS2-1[0][0]',                   \n",
      "                                                                  'ResUnit_L10_UpSamp-r-1-1_Mask_A\n",
      "                                                                 ttnS2-1[0][0]']                  \n",
      "                                                                                                  \n",
      " ResUnit_L2_Trunk-t-2-2_AttnS2-  (None, 16, 16, 128)  0          ['ResUnit_L1_Trunk-t-2-2_AttnS2-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " UpSamp2D-2_Mask_AttnS2-1 (UpSa  (None, 16, 16, 128)  0          ['ResUnit_L11_UpSamp-r-1-1_Mask_A\n",
      " mpling2D)                                                       ttnS2-1[0][0]']                  \n",
      "                                                                                                  \n",
      " ResUnit_L3_Trunk-t-2-2_AttnS2-  (None, 16, 16, 32)  4128        ['ResUnit_L2_Trunk-t-2-2_AttnS2-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L1_Attn_S1-1 (Bat  (None, 16, 16, 128)  512        ['UpSamp2D-2_Mask_AttnS2-1[0][0]'\n",
      " chNormalization)                                                ]                                \n",
      "                                                                                                  \n",
      " ResUnit_L4_Trunk-t-2-2_AttnS2-  (None, 16, 16, 32)  128         ['ResUnit_L3_Trunk-t-2-2_AttnS2-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L2_Attn_S1-1 (Act  (None, 16, 16, 128)  0          ['SpcConv_Mask_L1_Attn_S1-1[0][0]\n",
      " ivation)                                                        ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L5_Trunk-t-2-2_AttnS2-  (None, 16, 16, 32)  0           ['ResUnit_L4_Trunk-t-2-2_AttnS2-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L3_Attn_S1-1 (Con  (None, 16, 16, 128)  16512      ['SpcConv_Mask_L2_Attn_S1-1[0][0]\n",
      " v2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L6_Trunk-t-2-2_AttnS2-  (None, 16, 16, 32)  9248        ['ResUnit_L5_Trunk-t-2-2_AttnS2-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L4_Attn_S1-1 (Bat  (None, 16, 16, 128)  512        ['SpcConv_Mask_L3_Attn_S1-1[0][0]\n",
      " chNormalization)                                                ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L7_Trunk-t-2-2_AttnS2-  (None, 16, 16, 32)  128         ['ResUnit_L6_Trunk-t-2-2_AttnS2-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L5_Attn_S1-1 (Act  (None, 16, 16, 128)  0          ['SpcConv_Mask_L4_Attn_S1-1[0][0]\n",
      " ivation)                                                        ',                               \n",
      "                                                                  'SpcConv_Mask_L5_Attn_S1-1[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L8_Trunk-t-2-2_AttnS2-  (None, 16, 16, 32)  0           ['ResUnit_L7_Trunk-t-2-2_AttnS2-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L9_Trunk-t-2-2_AttnS2-  (None, 16, 16, 128)  4224       ['ResUnit_L8_Trunk-t-2-2_AttnS2-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_Trunk-t-2-2_AttnS2  (None, 16, 16, 128)  16512      ['ResUnit_L2_Trunk-t-2-2_AttnS2-1\n",
      " -1 (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L7_Attn_S1-1 (Act  (None, 16, 16, 128)  0          ['SpcConv_Mask_L5_Attn_S1-1[1][0]\n",
      " ivation)                                                        ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L11_Trunk-t-2-2_AttnS2  (None, 16, 16, 128)  0          ['ResUnit_L9_Trunk-t-2-2_AttnS2-1\n",
      " -1 (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_Trunk-t-2-2_AttnS2-\n",
      "                                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " Mult_L1_AttnS2-1 (Multiply)    (None, 16, 16, 128)  0           ['SpcConv_Mask_L7_Attn_S1-1[0][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'ResUnit_L11_Trunk-t-2-2_AttnS2-\n",
      "                                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " Add_L2_AttnS2-1 (Add)          (None, 16, 16, 128)  0           ['Mult_L1_AttnS2-1[0][0]',       \n",
      "                                                                  'ResUnit_L11_Trunk-t-2-2_AttnS2-\n",
      "                                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L1_Output-p-1-1_AttnS2  (None, 16, 16, 128)  512        ['Add_L2_AttnS2-1[0][0]']        \n",
      " -1 (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " ResUnit_L2_Output-p-1-1_AttnS2  (None, 16, 16, 128)  0          ['ResUnit_L1_Output-p-1-1_AttnS2-\n",
      " -1 (Activation)                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L3_Output-p-1-1_AttnS2  (None, 16, 16, 32)  4128        ['ResUnit_L2_Output-p-1-1_AttnS2-\n",
      " -1 (Conv2D)                                                     1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L4_Output-p-1-1_AttnS2  (None, 16, 16, 32)  128         ['ResUnit_L3_Output-p-1-1_AttnS2-\n",
      " -1 (BatchNormalization)                                         1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L5_Output-p-1-1_AttnS2  (None, 16, 16, 32)  0           ['ResUnit_L4_Output-p-1-1_AttnS2-\n",
      " -1 (Activation)                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L6_Output-p-1-1_AttnS2  (None, 16, 16, 32)  9248        ['ResUnit_L5_Output-p-1-1_AttnS2-\n",
      " -1 (Conv2D)                                                     1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L7_Output-p-1-1_AttnS2  (None, 16, 16, 32)  128         ['ResUnit_L6_Output-p-1-1_AttnS2-\n",
      " -1 (BatchNormalization)                                         1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L8_Output-p-1-1_AttnS2  (None, 16, 16, 32)  0           ['ResUnit_L7_Output-p-1-1_AttnS2-\n",
      " -1 (Activation)                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L9_Output-p-1-1_AttnS2  (None, 16, 16, 128)  4224       ['ResUnit_L8_Output-p-1-1_AttnS2-\n",
      " -1 (Conv2D)                                                     1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L10_Output-p-1-1_AttnS  (None, 16, 16, 128)  16512      ['ResUnit_L2_Output-p-1-1_AttnS2-\n",
      " 2-1 (Conv2D)                                                    1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L11_Output-p-1-1_AttnS  (None, 16, 16, 128)  0          ['ResUnit_L9_Output-p-1-1_AttnS2-\n",
      " 2-1 (Add)                                                       1[0][0]',                        \n",
      "                                                                  'ResUnit_L10_Output-p-1-1_AttnS2\n",
      "                                                                 -1[0][0]']                       \n",
      "                                                                                                  \n",
      " ResUnit_L1_NotAttnModule_3_DS   (None, 16, 16, 128)  512        ['ResUnit_L11_Output-p-1-1_AttnS2\n",
      " (BatchNormalization)                                            -1[0][0]']                       \n",
      "                                                                                                  \n",
      " ResUnit_L2_NotAttnModule_3_DS   (None, 16, 16, 128)  0          ['ResUnit_L1_NotAttnModule_3_DS[0\n",
      " (Activation)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L3_NotAttnModule_3_DS   (None, 16, 16, 64)  8256        ['ResUnit_L2_NotAttnModule_3_DS[0\n",
      " (Conv2D)                                                        ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L4_NotAttnModule_3_DS   (None, 16, 16, 64)  256         ['ResUnit_L3_NotAttnModule_3_DS[0\n",
      " (BatchNormalization)                                            ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L5_NotAttnModule_3_DS   (None, 16, 16, 64)  0           ['ResUnit_L4_NotAttnModule_3_DS[0\n",
      " (Activation)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L6_NotAttnModule_3_DS   (None, 8, 8, 64)    36928       ['ResUnit_L5_NotAttnModule_3_DS[0\n",
      " (Conv2D)                                                        ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L7_NotAttnModule_3_DS   (None, 8, 8, 64)    256         ['ResUnit_L6_NotAttnModule_3_DS[0\n",
      " (BatchNormalization)                                            ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L8_NotAttnModule_3_DS   (None, 8, 8, 64)    0           ['ResUnit_L7_NotAttnModule_3_DS[0\n",
      " (Activation)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L9_NotAttnModule_3_DS   (None, 8, 8, 256)   16640       ['ResUnit_L8_NotAttnModule_3_DS[0\n",
      " (Conv2D)                                                        ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L10_NotAttnModule_3_DS  (None, 8, 8, 256)   33024       ['ResUnit_L2_NotAttnModule_3_DS[0\n",
      "  (Conv2D)                                                       ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L11_NotAttnModule_3_DS  (None, 8, 8, 256)   0           ['ResUnit_L9_NotAttnModule_3_DS[0\n",
      "  (Add)                                                          ][0]',                           \n",
      "                                                                  'ResUnit_L10_NotAttnModule_3_DS[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " ResUnit_L1_Input-p-1-1_AttnS3-  (None, 8, 8, 256)   1024        ['ResUnit_L11_NotAttnModule_3_DS[\n",
      " 1 (BatchNormalization)                                          0][0]']                          \n",
      "                                                                                                  \n",
      " ResUnit_L2_Input-p-1-1_AttnS3-  (None, 8, 8, 256)   0           ['ResUnit_L1_Input-p-1-1_AttnS3-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L3_Input-p-1-1_AttnS3-  (None, 8, 8, 64)    16448       ['ResUnit_L2_Input-p-1-1_AttnS3-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L4_Input-p-1-1_AttnS3-  (None, 8, 8, 64)    256         ['ResUnit_L3_Input-p-1-1_AttnS3-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L5_Input-p-1-1_AttnS3-  (None, 8, 8, 64)    0           ['ResUnit_L4_Input-p-1-1_AttnS3-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L6_Input-p-1-1_AttnS3-  (None, 8, 8, 64)    36928       ['ResUnit_L5_Input-p-1-1_AttnS3-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L7_Input-p-1-1_AttnS3-  (None, 8, 8, 64)    256         ['ResUnit_L6_Input-p-1-1_AttnS3-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L8_Input-p-1-1_AttnS3-  (None, 8, 8, 64)    0           ['ResUnit_L7_Input-p-1-1_AttnS3-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L9_Input-p-1-1_AttnS3-  (None, 8, 8, 256)   16640       ['ResUnit_L8_Input-p-1-1_AttnS3-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_Input-p-1-1_AttnS3  (None, 8, 8, 256)   65792       ['ResUnit_L2_Input-p-1-1_AttnS3-1\n",
      " -1 (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L11_Input-p-1-1_AttnS3  (None, 8, 8, 256)   0           ['ResUnit_L9_Input-p-1-1_AttnS3-1\n",
      " -1 (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_Input-p-1-1_AttnS3-\n",
      "                                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " MaxPool_DownSamp-1_Mask_AttnS3  (None, 4, 4, 256)   0           ['ResUnit_L11_Input-p-1-1_AttnS3-\n",
      " -1 (MaxPooling2D)                                               1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L1_UpSamp-r-1-1_Mask_A  (None, 4, 4, 256)   1024        ['MaxPool_DownSamp-1_Mask_AttnS3-\n",
      " ttnS3-1 (BatchNormalization)                                    1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L2_UpSamp-r-1-1_Mask_A  (None, 4, 4, 256)   0           ['ResUnit_L1_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-1 (Activation)                                            tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L3_UpSamp-r-1-1_Mask_A  (None, 4, 4, 64)    16448       ['ResUnit_L2_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-1 (Conv2D)                                                tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L4_UpSamp-r-1-1_Mask_A  (None, 4, 4, 64)    256         ['ResUnit_L3_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-1 (BatchNormalization)                                    tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L5_UpSamp-r-1-1_Mask_A  (None, 4, 4, 64)    0           ['ResUnit_L4_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-1 (Activation)                                            tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L6_UpSamp-r-1-1_Mask_A  (None, 4, 4, 64)    36928       ['ResUnit_L5_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-1 (Conv2D)                                                tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L7_UpSamp-r-1-1_Mask_A  (None, 4, 4, 64)    256         ['ResUnit_L6_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-1 (BatchNormalization)                                    tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L8_UpSamp-r-1-1_Mask_A  (None, 4, 4, 64)    0           ['ResUnit_L7_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-1 (Activation)                                            tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L9_UpSamp-r-1-1_Mask_A  (None, 4, 4, 256)   16640       ['ResUnit_L8_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-1 (Conv2D)                                                tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L10_UpSamp-r-1-1_Mask_  (None, 4, 4, 256)   65792       ['ResUnit_L2_UpSamp-r-1-1_Mask_At\n",
      " AttnS3-1 (Conv2D)                                               tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L1_Trunk-t-2-1_AttnS3-  (None, 8, 8, 256)   1024        ['ResUnit_L11_Input-p-1-1_AttnS3-\n",
      " 1 (BatchNormalization)                                          1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L11_UpSamp-r-1-1_Mask_  (None, 4, 4, 256)   0           ['ResUnit_L9_UpSamp-r-1-1_Mask_At\n",
      " AttnS3-1 (Add)                                                  tnS3-1[0][0]',                   \n",
      "                                                                  'ResUnit_L10_UpSamp-r-1-1_Mask_A\n",
      "                                                                 ttnS3-1[0][0]']                  \n",
      "                                                                                                  \n",
      " ResUnit_L2_Trunk-t-2-1_AttnS3-  (None, 8, 8, 256)   0           ['ResUnit_L1_Trunk-t-2-1_AttnS3-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L1_UpSamp-r-1-2_Mask_A  (None, 4, 4, 256)   1024        ['ResUnit_L11_UpSamp-r-1-1_Mask_A\n",
      " ttnS3-1 (BatchNormalization)                                    ttnS3-1[0][0]']                  \n",
      "                                                                                                  \n",
      " ResUnit_L3_Trunk-t-2-1_AttnS3-  (None, 8, 8, 64)    16448       ['ResUnit_L2_Trunk-t-2-1_AttnS3-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L2_UpSamp-r-1-2_Mask_A  (None, 4, 4, 256)   0           ['ResUnit_L1_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-1 (Activation)                                            tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L4_Trunk-t-2-1_AttnS3-  (None, 8, 8, 64)    256         ['ResUnit_L3_Trunk-t-2-1_AttnS3-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L3_UpSamp-r-1-2_Mask_A  (None, 4, 4, 64)    16448       ['ResUnit_L2_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-1 (Conv2D)                                                tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L5_Trunk-t-2-1_AttnS3-  (None, 8, 8, 64)    0           ['ResUnit_L4_Trunk-t-2-1_AttnS3-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L4_UpSamp-r-1-2_Mask_A  (None, 4, 4, 64)    256         ['ResUnit_L3_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-1 (BatchNormalization)                                    tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L6_Trunk-t-2-1_AttnS3-  (None, 8, 8, 64)    36928       ['ResUnit_L5_Trunk-t-2-1_AttnS3-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L5_UpSamp-r-1-2_Mask_A  (None, 4, 4, 64)    0           ['ResUnit_L4_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-1 (Activation)                                            tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L7_Trunk-t-2-1_AttnS3-  (None, 8, 8, 64)    256         ['ResUnit_L6_Trunk-t-2-1_AttnS3-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L6_UpSamp-r-1-2_Mask_A  (None, 4, 4, 64)    36928       ['ResUnit_L5_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-1 (Conv2D)                                                tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L8_Trunk-t-2-1_AttnS3-  (None, 8, 8, 64)    0           ['ResUnit_L7_Trunk-t-2-1_AttnS3-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L7_UpSamp-r-1-2_Mask_A  (None, 4, 4, 64)    256         ['ResUnit_L6_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-1 (BatchNormalization)                                    tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L9_Trunk-t-2-1_AttnS3-  (None, 8, 8, 256)   16640       ['ResUnit_L8_Trunk-t-2-1_AttnS3-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_Trunk-t-2-1_AttnS3  (None, 8, 8, 256)   65792       ['ResUnit_L2_Trunk-t-2-1_AttnS3-1\n",
      " -1 (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L8_UpSamp-r-1-2_Mask_A  (None, 4, 4, 64)    0           ['ResUnit_L7_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-1 (Activation)                                            tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L11_Trunk-t-2-1_AttnS3  (None, 8, 8, 256)   0           ['ResUnit_L9_Trunk-t-2-1_AttnS3-1\n",
      " -1 (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_Trunk-t-2-1_AttnS3-\n",
      "                                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L9_UpSamp-r-1-2_Mask_A  (None, 4, 4, 256)   16640       ['ResUnit_L8_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-1 (Conv2D)                                                tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L10_UpSamp-r-1-2_Mask_  (None, 4, 4, 256)   65792       ['ResUnit_L2_UpSamp-r-1-2_Mask_At\n",
      " AttnS3-1 (Conv2D)                                               tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L1_Trunk-t-2-2_AttnS3-  (None, 8, 8, 256)   1024        ['ResUnit_L11_Trunk-t-2-1_AttnS3-\n",
      " 1 (BatchNormalization)                                          1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L11_UpSamp-r-1-2_Mask_  (None, 4, 4, 256)   0           ['ResUnit_L9_UpSamp-r-1-2_Mask_At\n",
      " AttnS3-1 (Add)                                                  tnS3-1[0][0]',                   \n",
      "                                                                  'ResUnit_L10_UpSamp-r-1-2_Mask_A\n",
      "                                                                 ttnS3-1[0][0]']                  \n",
      "                                                                                                  \n",
      " ResUnit_L2_Trunk-t-2-2_AttnS3-  (None, 8, 8, 256)   0           ['ResUnit_L1_Trunk-t-2-2_AttnS3-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " UpSamp2D-1_Mask_AttnS3-1 (UpSa  (None, 8, 8, 256)   0           ['ResUnit_L11_UpSamp-r-1-2_Mask_A\n",
      " mpling2D)                                                       ttnS3-1[0][0]']                  \n",
      "                                                                                                  \n",
      " ResUnit_L3_Trunk-t-2-2_AttnS3-  (None, 8, 8, 64)    16448       ['ResUnit_L2_Trunk-t-2-2_AttnS3-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L1_Attn_S3-1 (Bat  (None, 8, 8, 256)   1024        ['UpSamp2D-1_Mask_AttnS3-1[0][0]'\n",
      " chNormalization)                                                ]                                \n",
      "                                                                                                  \n",
      " ResUnit_L4_Trunk-t-2-2_AttnS3-  (None, 8, 8, 64)    256         ['ResUnit_L3_Trunk-t-2-2_AttnS3-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L2_Attn_S3-1 (Act  (None, 8, 8, 256)   0           ['SpcConv_Mask_L1_Attn_S3-1[0][0]\n",
      " ivation)                                                        ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L5_Trunk-t-2-2_AttnS3-  (None, 8, 8, 64)    0           ['ResUnit_L4_Trunk-t-2-2_AttnS3-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L3_Attn_S3-1 (Con  (None, 8, 8, 256)   65792       ['SpcConv_Mask_L2_Attn_S3-1[0][0]\n",
      " v2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L6_Trunk-t-2-2_AttnS3-  (None, 8, 8, 64)    36928       ['ResUnit_L5_Trunk-t-2-2_AttnS3-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L4_Attn_S3-1 (Bat  (None, 8, 8, 256)   1024        ['SpcConv_Mask_L3_Attn_S3-1[0][0]\n",
      " chNormalization)                                                ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L7_Trunk-t-2-2_AttnS3-  (None, 8, 8, 64)    256         ['ResUnit_L6_Trunk-t-2-2_AttnS3-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L5_Attn_S3-1 (Act  (None, 8, 8, 256)   0           ['SpcConv_Mask_L4_Attn_S3-1[0][0]\n",
      " ivation)                                                        ',                               \n",
      "                                                                  'SpcConv_Mask_L5_Attn_S3-1[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L8_Trunk-t-2-2_AttnS3-  (None, 8, 8, 64)    0           ['ResUnit_L7_Trunk-t-2-2_AttnS3-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L9_Trunk-t-2-2_AttnS3-  (None, 8, 8, 256)   16640       ['ResUnit_L8_Trunk-t-2-2_AttnS3-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_Trunk-t-2-2_AttnS3  (None, 8, 8, 256)   65792       ['ResUnit_L2_Trunk-t-2-2_AttnS3-1\n",
      " -1 (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L7_Attn_S3-1 (Act  (None, 8, 8, 256)   0           ['SpcConv_Mask_L5_Attn_S3-1[1][0]\n",
      " ivation)                                                        ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L11_Trunk-t-2-2_AttnS3  (None, 8, 8, 256)   0           ['ResUnit_L9_Trunk-t-2-2_AttnS3-1\n",
      " -1 (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_Trunk-t-2-2_AttnS3-\n",
      "                                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " Mult_L1_AttnS3-1 (Multiply)    (None, 8, 8, 256)    0           ['SpcConv_Mask_L7_Attn_S3-1[0][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'ResUnit_L11_Trunk-t-2-2_AttnS3-\n",
      "                                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " Add_L1_AttnS3-1 (Add)          (None, 8, 8, 256)    0           ['Mult_L1_AttnS3-1[0][0]',       \n",
      "                                                                  'ResUnit_L11_Trunk-t-2-2_AttnS3-\n",
      "                                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L1_Output-p-1-1_AttnS3  (None, 8, 8, 256)   1024        ['Add_L1_AttnS3-1[0][0]']        \n",
      " -1 (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " ResUnit_L2_Output-p-1-1_AttnS3  (None, 8, 8, 256)   0           ['ResUnit_L1_Output-p-1-1_AttnS3-\n",
      " -1 (Activation)                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L3_Output-p-1-1_AttnS3  (None, 8, 8, 64)    16448       ['ResUnit_L2_Output-p-1-1_AttnS3-\n",
      " -1 (Conv2D)                                                     1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L4_Output-p-1-1_AttnS3  (None, 8, 8, 64)    256         ['ResUnit_L3_Output-p-1-1_AttnS3-\n",
      " -1 (BatchNormalization)                                         1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L5_Output-p-1-1_AttnS3  (None, 8, 8, 64)    0           ['ResUnit_L4_Output-p-1-1_AttnS3-\n",
      " -1 (Activation)                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L6_Output-p-1-1_AttnS3  (None, 8, 8, 64)    36928       ['ResUnit_L5_Output-p-1-1_AttnS3-\n",
      " -1 (Conv2D)                                                     1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L7_Output-p-1-1_AttnS3  (None, 8, 8, 64)    256         ['ResUnit_L6_Output-p-1-1_AttnS3-\n",
      " -1 (BatchNormalization)                                         1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L8_Output-p-1-1_AttnS3  (None, 8, 8, 64)    0           ['ResUnit_L7_Output-p-1-1_AttnS3-\n",
      " -1 (Activation)                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L9_Output-p-1-1_AttnS3  (None, 8, 8, 256)   16640       ['ResUnit_L8_Output-p-1-1_AttnS3-\n",
      " -1 (Conv2D)                                                     1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L10_Output-p-1-1_AttnS  (None, 8, 8, 256)   65792       ['ResUnit_L2_Output-p-1-1_AttnS3-\n",
      " 3-1 (Conv2D)                                                    1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L11_Output-p-1-1_AttnS  (None, 8, 8, 256)   0           ['ResUnit_L9_Output-p-1-1_AttnS3-\n",
      " 3-1 (Add)                                                       1[0][0]',                        \n",
      "                                                                  'ResUnit_L10_Output-p-1-1_AttnS3\n",
      "                                                                 -1[0][0]']                       \n",
      "                                                                                                  \n",
      " ResUnit_L1_NotAttnModule_4_NoD  (None, 8, 8, 256)   1024        ['ResUnit_L11_Output-p-1-1_AttnS3\n",
      " S (BatchNormalization)                                          -1[0][0]']                       \n",
      "                                                                                                  \n",
      " ResUnit_L2_NotAttnModule_4_NoD  (None, 8, 8, 256)   0           ['ResUnit_L1_NotAttnModule_4_NoDS\n",
      " S (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L3_NotAttnModule_4_NoD  (None, 8, 8, 128)   32896       ['ResUnit_L2_NotAttnModule_4_NoDS\n",
      " S (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L4_NotAttnModule_4_NoD  (None, 8, 8, 128)   512         ['ResUnit_L3_NotAttnModule_4_NoDS\n",
      " S (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L5_NotAttnModule_4_NoD  (None, 8, 8, 128)   0           ['ResUnit_L4_NotAttnModule_4_NoDS\n",
      " S (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L6_NotAttnModule_4_NoD  (None, 8, 8, 128)   147584      ['ResUnit_L5_NotAttnModule_4_NoDS\n",
      " S (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L7_NotAttnModule_4_NoD  (None, 8, 8, 128)   512         ['ResUnit_L6_NotAttnModule_4_NoDS\n",
      " S (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L8_NotAttnModule_4_NoD  (None, 8, 8, 128)   0           ['ResUnit_L7_NotAttnModule_4_NoDS\n",
      " S (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L9_NotAttnModule_4_NoD  (None, 8, 8, 512)   66048       ['ResUnit_L8_NotAttnModule_4_NoDS\n",
      " S (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_NotAttnModule_4_No  (None, 8, 8, 512)   131584      ['ResUnit_L2_NotAttnModule_4_NoDS\n",
      " DS (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L11_NotAttnModule_4_No  (None, 8, 8, 512)   0           ['ResUnit_L9_NotAttnModule_4_NoDS\n",
      " DS (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_NotAttnModule_4_NoD\n",
      "                                                                 S[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L1_NotAttnModule_5_NoD  (None, 8, 8, 512)   2048        ['ResUnit_L11_NotAttnModule_4_NoD\n",
      " S (BatchNormalization)                                          S[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L2_NotAttnModule_5_NoD  (None, 8, 8, 512)   0           ['ResUnit_L1_NotAttnModule_5_NoDS\n",
      " S (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L3_NotAttnModule_5_NoD  (None, 8, 8, 128)   65664       ['ResUnit_L2_NotAttnModule_5_NoDS\n",
      " S (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L4_NotAttnModule_5_NoD  (None, 8, 8, 128)   512         ['ResUnit_L3_NotAttnModule_5_NoDS\n",
      " S (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L5_NotAttnModule_5_NoD  (None, 8, 8, 128)   0           ['ResUnit_L4_NotAttnModule_5_NoDS\n",
      " S (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L6_NotAttnModule_5_NoD  (None, 8, 8, 128)   147584      ['ResUnit_L5_NotAttnModule_5_NoDS\n",
      " S (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L7_NotAttnModule_5_NoD  (None, 8, 8, 128)   512         ['ResUnit_L6_NotAttnModule_5_NoDS\n",
      " S (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L8_NotAttnModule_5_NoD  (None, 8, 8, 128)   0           ['ResUnit_L7_NotAttnModule_5_NoDS\n",
      " S (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L9_NotAttnModule_5_NoD  (None, 8, 8, 512)   66048       ['ResUnit_L8_NotAttnModule_5_NoDS\n",
      " S (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_NotAttnModule_5_No  (None, 8, 8, 512)   262656      ['ResUnit_L2_NotAttnModule_5_NoDS\n",
      " DS (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L11_NotAttnModule_5_No  (None, 8, 8, 512)   0           ['ResUnit_L9_NotAttnModule_5_NoDS\n",
      " DS (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_NotAttnModule_5_NoD\n",
      "                                                                 S[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L1_NotAttnModule_6_NoD  (None, 8, 8, 512)   2048        ['ResUnit_L11_NotAttnModule_5_NoD\n",
      " S (BatchNormalization)                                          S[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L2_NotAttnModule_6_NoD  (None, 8, 8, 512)   0           ['ResUnit_L1_NotAttnModule_6_NoDS\n",
      " S (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L3_NotAttnModule_6_NoD  (None, 8, 8, 128)   65664       ['ResUnit_L2_NotAttnModule_6_NoDS\n",
      " S (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L4_NotAttnModule_6_NoD  (None, 8, 8, 128)   512         ['ResUnit_L3_NotAttnModule_6_NoDS\n",
      " S (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L5_NotAttnModule_6_NoD  (None, 8, 8, 128)   0           ['ResUnit_L4_NotAttnModule_6_NoDS\n",
      " S (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L6_NotAttnModule_6_NoD  (None, 8, 8, 128)   147584      ['ResUnit_L5_NotAttnModule_6_NoDS\n",
      " S (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L7_NotAttnModule_6_NoD  (None, 8, 8, 128)   512         ['ResUnit_L6_NotAttnModule_6_NoDS\n",
      " S (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L8_NotAttnModule_6_NoD  (None, 8, 8, 128)   0           ['ResUnit_L7_NotAttnModule_6_NoDS\n",
      " S (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L9_NotAttnModule_6_NoD  (None, 8, 8, 512)   66048       ['ResUnit_L8_NotAttnModule_6_NoDS\n",
      " S (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_NotAttnModule_6_No  (None, 8, 8, 512)   262656      ['ResUnit_L2_NotAttnModule_6_NoDS\n",
      " DS (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L11_NotAttnModule_6_No  (None, 8, 8, 512)   0           ['ResUnit_L9_NotAttnModule_6_NoDS\n",
      " DS (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_NotAttnModule_6_NoD\n",
      "                                                                 S[0][0]']                        \n",
      "                                                                                                  \n",
      " BN_Out (BatchNormalization)    (None, 8, 8, 512)    2048        ['ResUnit_L11_NotAttnModule_6_NoD\n",
      "                                                                 S[0][0]']                        \n",
      "                                                                                                  \n",
      " ReLU_Out (Activation)          (None, 8, 8, 512)    0           ['BN_Out[0][0]']                 \n",
      "                                                                                                  \n",
      " AvgPool_Out (AveragePooling2D)  (None, 1, 1, 512)   0           ['ReLU_Out[0][0]']               \n",
      "                                                                                                  \n",
      " Flatten_Out (Flatten)          (None, 512)          0           ['AvgPool_Out[0][0]']            \n",
      "                                                                                                  \n",
      " Final_Out (Dense)              (None, 10)           5130        ['Flatten_Out[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,922,922\n",
      "Trainable params: 2,905,066\n",
      "Non-trainable params: 17,856\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "output_classes = 10\n",
    "\n",
    "ran56 = ResidualAttentionModel_56(input_shape, output_classes, use_bias=True)\n",
    "\n",
    "model = ran56.return_Model()\n",
    "\n",
    "model.compile(tf.keras.optimizers.Adam(), \n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acdcc6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/ran56_v1/graphs/ran56_v1_modelsummary.txt\n"
     ]
    }
   ],
   "source": [
    "global summary_filename \n",
    "summary_filename = graph_path + '/{}'.format(model_name[1:]) + '_modelsummary.txt'\n",
    "print(summary_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e4f3c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(summary_filename, 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e311780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021/cp-{epoch}.ckpt\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path_ckpt = checkpoint_path + '/' + time.ctime().replace(':','_').replace(' ', '_') + '/cp-{epoch}.ckpt'\n",
    "print(checkpoint_path_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5e2584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot_img_file = '/tmp/ran56.png'\n",
    "# tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)\n",
    "\n",
    "earlyStopping_TrainAcc = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=10)\n",
    "checkpoint_CB = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path_ckpt, verbose=1, save_weights_only=True)\n",
    "reduceLR = tf.keras.callbacks.ReduceLROnPlateau(patience=5,  monitor='loss')\n",
    "callback_list = list()\n",
    "callback_list.append(earlyStopping_TrainAcc)\n",
    "callback_list.append(reduceLR)\n",
    "callback_list.append(checkpoint_CB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad033994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 1.7728 - accuracy: 0.3381\n",
      "Epoch 00001: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-1.ckpt\n",
      "625/625 [==============================] - 65s 89ms/step - loss: 1.7728 - accuracy: 0.3381 - val_loss: 1.6579 - val_accuracy: 0.4042 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 1.4249 - accuracy: 0.4785\n",
      "Epoch 00002: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-2.ckpt\n",
      "625/625 [==============================] - 54s 86ms/step - loss: 1.4249 - accuracy: 0.4785 - val_loss: 3.1722 - val_accuracy: 0.3344 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 1.2418 - accuracy: 0.5540\n",
      "Epoch 00003: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-3.ckpt\n",
      "625/625 [==============================] - 53s 85ms/step - loss: 1.2418 - accuracy: 0.5540 - val_loss: 1.4989 - val_accuracy: 0.4931 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 1.1066 - accuracy: 0.6065\n",
      "Epoch 00004: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-4.ckpt\n",
      "625/625 [==============================] - 53s 85ms/step - loss: 1.1066 - accuracy: 0.6065 - val_loss: 1.1457 - val_accuracy: 0.6077 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 1.0006 - accuracy: 0.6468\n",
      "Epoch 00005: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-5.ckpt\n",
      "625/625 [==============================] - 54s 86ms/step - loss: 1.0006 - accuracy: 0.6468 - val_loss: 1.2628 - val_accuracy: 0.5811 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.9192 - accuracy: 0.6748\n",
      "Epoch 00006: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-6.ckpt\n",
      "625/625 [==============================] - 54s 87ms/step - loss: 0.9192 - accuracy: 0.6748 - val_loss: 1.0654 - val_accuracy: 0.6263 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.8529 - accuracy: 0.6995\n",
      "Epoch 00007: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-7.ckpt\n",
      "625/625 [==============================] - 54s 86ms/step - loss: 0.8529 - accuracy: 0.6995 - val_loss: 0.9393 - val_accuracy: 0.6710 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.7956 - accuracy: 0.7184\n",
      "Epoch 00008: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-8.ckpt\n",
      "625/625 [==============================] - 59s 94ms/step - loss: 0.7956 - accuracy: 0.7184 - val_loss: 1.0756 - val_accuracy: 0.6511 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.7552 - accuracy: 0.7350\n",
      "Epoch 00009: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-9.ckpt\n",
      "625/625 [==============================] - 58s 93ms/step - loss: 0.7552 - accuracy: 0.7350 - val_loss: 0.9315 - val_accuracy: 0.6829 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.7108 - accuracy: 0.7502\n",
      "Epoch 00010: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-10.ckpt\n",
      "625/625 [==============================] - 56s 89ms/step - loss: 0.7108 - accuracy: 0.7502 - val_loss: 0.8832 - val_accuracy: 0.6940 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.6808 - accuracy: 0.7645\n",
      "Epoch 00011: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-11.ckpt\n",
      "625/625 [==============================] - 56s 90ms/step - loss: 0.6808 - accuracy: 0.7645 - val_loss: 0.7994 - val_accuracy: 0.7241 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.6482 - accuracy: 0.7720\n",
      "Epoch 00012: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-12.ckpt\n",
      "625/625 [==============================] - 57s 91ms/step - loss: 0.6482 - accuracy: 0.7720 - val_loss: 0.7135 - val_accuracy: 0.7475 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.6237 - accuracy: 0.7810\n",
      "Epoch 00013: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-13.ckpt\n",
      "625/625 [==============================] - 56s 89ms/step - loss: 0.6237 - accuracy: 0.7810 - val_loss: 0.7073 - val_accuracy: 0.7531 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.6038 - accuracy: 0.7893\n",
      "Epoch 00014: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-14.ckpt\n",
      "625/625 [==============================] - 58s 92ms/step - loss: 0.6038 - accuracy: 0.7893 - val_loss: 0.8597 - val_accuracy: 0.7161 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.5743 - accuracy: 0.8011\n",
      "Epoch 00015: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-15.ckpt\n",
      "625/625 [==============================] - 56s 90ms/step - loss: 0.5743 - accuracy: 0.8011 - val_loss: 0.8020 - val_accuracy: 0.7415 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.5623 - accuracy: 0.8059\n",
      "Epoch 00016: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-16.ckpt\n",
      "625/625 [==============================] - 60s 97ms/step - loss: 0.5623 - accuracy: 0.8059 - val_loss: 0.6167 - val_accuracy: 0.7833 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.5365 - accuracy: 0.8112\n",
      "Epoch 00017: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-17.ckpt\n",
      "625/625 [==============================] - 54s 86ms/step - loss: 0.5365 - accuracy: 0.8112 - val_loss: 0.6387 - val_accuracy: 0.7815 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.5284 - accuracy: 0.8170\n",
      "Epoch 00018: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-18.ckpt\n",
      "625/625 [==============================] - 57s 92ms/step - loss: 0.5284 - accuracy: 0.8170 - val_loss: 0.9078 - val_accuracy: 0.7158 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.5049 - accuracy: 0.8255\n",
      "Epoch 00019: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-19.ckpt\n",
      "625/625 [==============================] - 57s 91ms/step - loss: 0.5049 - accuracy: 0.8255 - val_loss: 0.6863 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.4886 - accuracy: 0.8295\n",
      "Epoch 00020: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-20.ckpt\n",
      "625/625 [==============================] - 57s 91ms/step - loss: 0.4886 - accuracy: 0.8295 - val_loss: 0.5770 - val_accuracy: 0.8019 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.4740 - accuracy: 0.8359\n",
      "Epoch 00021: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-21.ckpt\n",
      "625/625 [==============================] - 52s 82ms/step - loss: 0.4740 - accuracy: 0.8359 - val_loss: 0.6155 - val_accuracy: 0.7905 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.4642 - accuracy: 0.8361\n",
      "Epoch 00022: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-22.ckpt\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.4642 - accuracy: 0.8361 - val_loss: 0.6236 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.4471 - accuracy: 0.8434\n",
      "Epoch 00023: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-23.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.4471 - accuracy: 0.8434 - val_loss: 0.5100 - val_accuracy: 0.8262 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.4390 - accuracy: 0.8465\n",
      "Epoch 00024: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-24.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.4390 - accuracy: 0.8465 - val_loss: 0.5442 - val_accuracy: 0.8151 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.4306 - accuracy: 0.8503\n",
      "Epoch 00025: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-25.ckpt\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.4306 - accuracy: 0.8503 - val_loss: 0.5617 - val_accuracy: 0.8110 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.4126 - accuracy: 0.8579\n",
      "Epoch 00026: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-26.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.4126 - accuracy: 0.8579 - val_loss: 0.5194 - val_accuracy: 0.8239 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.4077 - accuracy: 0.8582\n",
      "Epoch 00027: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-27.ckpt\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.4077 - accuracy: 0.8582 - val_loss: 0.5268 - val_accuracy: 0.8153 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3911 - accuracy: 0.8631\n",
      "Epoch 00028: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-28.ckpt\n",
      "625/625 [==============================] - 52s 84ms/step - loss: 0.3911 - accuracy: 0.8631 - val_loss: 0.5288 - val_accuracy: 0.8229 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3883 - accuracy: 0.8647\n",
      "Epoch 00029: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-29.ckpt\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.3883 - accuracy: 0.8647 - val_loss: 0.6978 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3772 - accuracy: 0.8687\n",
      "Epoch 00030: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-30.ckpt\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.3772 - accuracy: 0.8687 - val_loss: 0.5161 - val_accuracy: 0.8306 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3673 - accuracy: 0.8723\n",
      "Epoch 00031: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-31.ckpt\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.3673 - accuracy: 0.8723 - val_loss: 0.5807 - val_accuracy: 0.8109 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3648 - accuracy: 0.8721\n",
      "Epoch 00032: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-32.ckpt\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.3648 - accuracy: 0.8721 - val_loss: 0.4950 - val_accuracy: 0.8341 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3558 - accuracy: 0.8761\n",
      "Epoch 00033: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-33.ckpt\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.3558 - accuracy: 0.8761 - val_loss: 0.4971 - val_accuracy: 0.8359 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3443 - accuracy: 0.8798\n",
      "Epoch 00034: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-34.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.3443 - accuracy: 0.8798 - val_loss: 0.4828 - val_accuracy: 0.8370 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3364 - accuracy: 0.8827\n",
      "Epoch 00035: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-35.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.3364 - accuracy: 0.8827 - val_loss: 0.4886 - val_accuracy: 0.8353 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3326 - accuracy: 0.8856\n",
      "Epoch 00036: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-36.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.3326 - accuracy: 0.8856 - val_loss: 0.4857 - val_accuracy: 0.8405 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3202 - accuracy: 0.8876\n",
      "Epoch 00037: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-37.ckpt\n",
      "625/625 [==============================] - 54s 87ms/step - loss: 0.3202 - accuracy: 0.8876 - val_loss: 0.5066 - val_accuracy: 0.8352 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3172 - accuracy: 0.8899\n",
      "Epoch 00038: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-38.ckpt\n",
      "625/625 [==============================] - 56s 90ms/step - loss: 0.3172 - accuracy: 0.8899 - val_loss: 0.4535 - val_accuracy: 0.8531 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3117 - accuracy: 0.8898\n",
      "Epoch 00039: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-39.ckpt\n",
      "625/625 [==============================] - 57s 91ms/step - loss: 0.3117 - accuracy: 0.8898 - val_loss: 0.5866 - val_accuracy: 0.8169 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3043 - accuracy: 0.8932\n",
      "Epoch 00040: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-40.ckpt\n",
      "625/625 [==============================] - 58s 93ms/step - loss: 0.3043 - accuracy: 0.8932 - val_loss: 0.4319 - val_accuracy: 0.8558 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2961 - accuracy: 0.8961\n",
      "Epoch 00041: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-41.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.2961 - accuracy: 0.8961 - val_loss: 0.5633 - val_accuracy: 0.8220 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2902 - accuracy: 0.8966\n",
      "Epoch 00042: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-42.ckpt\n",
      "625/625 [==============================] - 53s 84ms/step - loss: 0.2902 - accuracy: 0.8966 - val_loss: 0.4499 - val_accuracy: 0.8497 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2864 - accuracy: 0.8991\n",
      "Epoch 00043: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-43.ckpt\n",
      "625/625 [==============================] - 54s 86ms/step - loss: 0.2864 - accuracy: 0.8991 - val_loss: 0.4828 - val_accuracy: 0.8406 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2833 - accuracy: 0.9007\n",
      "Epoch 00044: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-44.ckpt\n",
      "625/625 [==============================] - 54s 86ms/step - loss: 0.2833 - accuracy: 0.9007 - val_loss: 0.4951 - val_accuracy: 0.8384 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2784 - accuracy: 0.9028\n",
      "Epoch 00045: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-45.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.2784 - accuracy: 0.9028 - val_loss: 0.4151 - val_accuracy: 0.8569 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2685 - accuracy: 0.9060\n",
      "Epoch 00046: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-46.ckpt\n",
      "625/625 [==============================] - 53s 85ms/step - loss: 0.2685 - accuracy: 0.9060 - val_loss: 0.4429 - val_accuracy: 0.8569 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2616 - accuracy: 0.9061\n",
      "Epoch 00047: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-47.ckpt\n",
      "625/625 [==============================] - 55s 88ms/step - loss: 0.2616 - accuracy: 0.9061 - val_loss: 0.5738 - val_accuracy: 0.8320 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2578 - accuracy: 0.9088\n",
      "Epoch 00048: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-48.ckpt\n",
      "625/625 [==============================] - 56s 89ms/step - loss: 0.2578 - accuracy: 0.9088 - val_loss: 0.4134 - val_accuracy: 0.8610 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2572 - accuracy: 0.9089\n",
      "Epoch 00049: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-49.ckpt\n",
      "625/625 [==============================] - 52s 84ms/step - loss: 0.2572 - accuracy: 0.9089 - val_loss: 0.4020 - val_accuracy: 0.8673 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2499 - accuracy: 0.9110\n",
      "Epoch 00050: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-50.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.2499 - accuracy: 0.9110 - val_loss: 0.4669 - val_accuracy: 0.8488 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2498 - accuracy: 0.9120\n",
      "Epoch 00051: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-51.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.2498 - accuracy: 0.9120 - val_loss: 0.4696 - val_accuracy: 0.8503 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2451 - accuracy: 0.9142\n",
      "Epoch 00052: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-52.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.2451 - accuracy: 0.9142 - val_loss: 0.5672 - val_accuracy: 0.8311 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2383 - accuracy: 0.9153\n",
      "Epoch 00053: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-53.ckpt\n",
      "625/625 [==============================] - 53s 85ms/step - loss: 0.2383 - accuracy: 0.9153 - val_loss: 0.5054 - val_accuracy: 0.8464 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2347 - accuracy: 0.9181\n",
      "Epoch 00054: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-54.ckpt\n",
      "625/625 [==============================] - 53s 85ms/step - loss: 0.2347 - accuracy: 0.9181 - val_loss: 0.4740 - val_accuracy: 0.8433 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2292 - accuracy: 0.9179\n",
      "Epoch 00055: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-55.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.2292 - accuracy: 0.9179 - val_loss: 0.4824 - val_accuracy: 0.8444 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2318 - accuracy: 0.9182\n",
      "Epoch 00056: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-56.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.2318 - accuracy: 0.9182 - val_loss: 0.4380 - val_accuracy: 0.8564 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2243 - accuracy: 0.9203\n",
      "Epoch 00057: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-57.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.2243 - accuracy: 0.9203 - val_loss: 0.4564 - val_accuracy: 0.8522 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2154 - accuracy: 0.9227\n",
      "Epoch 00058: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-58.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.2154 - accuracy: 0.9227 - val_loss: 0.4392 - val_accuracy: 0.8659 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2166 - accuracy: 0.9243\n",
      "Epoch 00059: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-59.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.2166 - accuracy: 0.9243 - val_loss: 0.4088 - val_accuracy: 0.8716 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2091 - accuracy: 0.9268\n",
      "Epoch 00060: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-60.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.2091 - accuracy: 0.9268 - val_loss: 0.3976 - val_accuracy: 0.8685 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2108 - accuracy: 0.9253\n",
      "Epoch 00061: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-61.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.2108 - accuracy: 0.9253 - val_loss: 0.3691 - val_accuracy: 0.8745 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2059 - accuracy: 0.9273\n",
      "Epoch 00062: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-62.ckpt\n",
      "625/625 [==============================] - 52s 82ms/step - loss: 0.2059 - accuracy: 0.9273 - val_loss: 0.4139 - val_accuracy: 0.8678 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1998 - accuracy: 0.9295\n",
      "Epoch 00063: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-63.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1998 - accuracy: 0.9295 - val_loss: 0.4399 - val_accuracy: 0.8659 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1975 - accuracy: 0.9311\n",
      "Epoch 00064: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-64.ckpt\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1975 - accuracy: 0.9311 - val_loss: 0.4317 - val_accuracy: 0.8650 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1935 - accuracy: 0.9317\n",
      "Epoch 00065: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-65.ckpt\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1935 - accuracy: 0.9317 - val_loss: 0.4114 - val_accuracy: 0.8708 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1922 - accuracy: 0.9324\n",
      "Epoch 00066: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-66.ckpt\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1922 - accuracy: 0.9324 - val_loss: 0.4324 - val_accuracy: 0.8655 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1871 - accuracy: 0.9334\n",
      "Epoch 00067: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-67.ckpt\n",
      "625/625 [==============================] - 52s 82ms/step - loss: 0.1871 - accuracy: 0.9334 - val_loss: 0.4159 - val_accuracy: 0.8760 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1837 - accuracy: 0.9344\n",
      "Epoch 00068: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-68.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1837 - accuracy: 0.9344 - val_loss: 0.3926 - val_accuracy: 0.8727 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1845 - accuracy: 0.9347\n",
      "Epoch 00069: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-69.ckpt\n",
      "625/625 [==============================] - 52s 84ms/step - loss: 0.1845 - accuracy: 0.9347 - val_loss: 0.4220 - val_accuracy: 0.8715 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1844 - accuracy: 0.9334\n",
      "Epoch 00070: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-70.ckpt\n",
      "625/625 [==============================] - 55s 88ms/step - loss: 0.1844 - accuracy: 0.9334 - val_loss: 0.4012 - val_accuracy: 0.8712 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1808 - accuracy: 0.9360\n",
      "Epoch 00071: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-71.ckpt\n",
      "625/625 [==============================] - 58s 93ms/step - loss: 0.1808 - accuracy: 0.9360 - val_loss: 0.5257 - val_accuracy: 0.8502 - lr: 0.0010\n",
      "Epoch 72/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1780 - accuracy: 0.9373\n",
      "Epoch 00072: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-72.ckpt\n",
      "625/625 [==============================] - 53s 84ms/step - loss: 0.1780 - accuracy: 0.9373 - val_loss: 0.4229 - val_accuracy: 0.8719 - lr: 0.0010\n",
      "Epoch 73/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1749 - accuracy: 0.9380\n",
      "Epoch 00073: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-73.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1749 - accuracy: 0.9380 - val_loss: 0.4027 - val_accuracy: 0.8722 - lr: 0.0010\n",
      "Epoch 74/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1677 - accuracy: 0.9406\n",
      "Epoch 00074: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-74.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1677 - accuracy: 0.9406 - val_loss: 0.4140 - val_accuracy: 0.8764 - lr: 0.0010\n",
      "Epoch 75/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1708 - accuracy: 0.9403\n",
      "Epoch 00075: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-75.ckpt\n",
      "625/625 [==============================] - 54s 86ms/step - loss: 0.1708 - accuracy: 0.9403 - val_loss: 0.5837 - val_accuracy: 0.8264 - lr: 0.0010\n",
      "Epoch 76/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1650 - accuracy: 0.9398\n",
      "Epoch 00076: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-76.ckpt\n",
      "625/625 [==============================] - 55s 88ms/step - loss: 0.1650 - accuracy: 0.9398 - val_loss: 0.3622 - val_accuracy: 0.8853 - lr: 0.0010\n",
      "Epoch 77/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1663 - accuracy: 0.9408\n",
      "Epoch 00077: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-77.ckpt\n",
      "625/625 [==============================] - 56s 90ms/step - loss: 0.1663 - accuracy: 0.9408 - val_loss: 0.4125 - val_accuracy: 0.8709 - lr: 0.0010\n",
      "Epoch 78/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1592 - accuracy: 0.9434\n",
      "Epoch 00078: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-78.ckpt\n",
      "625/625 [==============================] - 53s 85ms/step - loss: 0.1592 - accuracy: 0.9434 - val_loss: 0.4097 - val_accuracy: 0.8770 - lr: 0.0010\n",
      "Epoch 79/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1596 - accuracy: 0.9434\n",
      "Epoch 00079: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-79.ckpt\n",
      "625/625 [==============================] - 55s 88ms/step - loss: 0.1596 - accuracy: 0.9434 - val_loss: 0.4046 - val_accuracy: 0.8768 - lr: 0.0010\n",
      "Epoch 80/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1559 - accuracy: 0.9451\n",
      "Epoch 00080: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-80.ckpt\n",
      "625/625 [==============================] - 52s 84ms/step - loss: 0.1559 - accuracy: 0.9451 - val_loss: 0.3532 - val_accuracy: 0.8927 - lr: 0.0010\n",
      "Epoch 81/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1548 - accuracy: 0.9448\n",
      "Epoch 00081: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-81.ckpt\n",
      "625/625 [==============================] - 53s 85ms/step - loss: 0.1548 - accuracy: 0.9448 - val_loss: 0.4652 - val_accuracy: 0.8673 - lr: 0.0010\n",
      "Epoch 82/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1534 - accuracy: 0.9455\n",
      "Epoch 00082: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-82.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1534 - accuracy: 0.9455 - val_loss: 0.4290 - val_accuracy: 0.8759 - lr: 0.0010\n",
      "Epoch 83/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1546 - accuracy: 0.9460\n",
      "Epoch 00083: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-83.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1546 - accuracy: 0.9460 - val_loss: 0.4894 - val_accuracy: 0.8576 - lr: 0.0010\n",
      "Epoch 84/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1486 - accuracy: 0.9482\n",
      "Epoch 00084: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-84.ckpt\n",
      "625/625 [==============================] - 53s 85ms/step - loss: 0.1486 - accuracy: 0.9482 - val_loss: 0.4603 - val_accuracy: 0.8621 - lr: 0.0010\n",
      "Epoch 85/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1447 - accuracy: 0.9493\n",
      "Epoch 00085: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-85.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1447 - accuracy: 0.9493 - val_loss: 0.3980 - val_accuracy: 0.8781 - lr: 0.0010\n",
      "Epoch 86/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1441 - accuracy: 0.9500\n",
      "Epoch 00086: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-86.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1441 - accuracy: 0.9500 - val_loss: 0.3915 - val_accuracy: 0.8855 - lr: 0.0010\n",
      "Epoch 87/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1436 - accuracy: 0.9487\n",
      "Epoch 00087: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-87.ckpt\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1436 - accuracy: 0.9487 - val_loss: 0.4578 - val_accuracy: 0.8672 - lr: 0.0010\n",
      "Epoch 88/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1451 - accuracy: 0.9493\n",
      "Epoch 00088: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-88.ckpt\n",
      "625/625 [==============================] - 52s 84ms/step - loss: 0.1451 - accuracy: 0.9493 - val_loss: 0.3795 - val_accuracy: 0.8847 - lr: 0.0010\n",
      "Epoch 89/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1353 - accuracy: 0.9523\n",
      "Epoch 00089: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-89.ckpt\n",
      "625/625 [==============================] - 52s 82ms/step - loss: 0.1353 - accuracy: 0.9523 - val_loss: 0.3900 - val_accuracy: 0.8872 - lr: 0.0010\n",
      "Epoch 90/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1341 - accuracy: 0.9526\n",
      "Epoch 00090: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-90.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1341 - accuracy: 0.9526 - val_loss: 0.4034 - val_accuracy: 0.8838 - lr: 0.0010\n",
      "Epoch 91/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1367 - accuracy: 0.9513\n",
      "Epoch 00091: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-91.ckpt\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1367 - accuracy: 0.9513 - val_loss: 0.4439 - val_accuracy: 0.8639 - lr: 0.0010\n",
      "Epoch 92/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1330 - accuracy: 0.9532\n",
      "Epoch 00092: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-92.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1330 - accuracy: 0.9532 - val_loss: 0.4203 - val_accuracy: 0.8777 - lr: 0.0010\n",
      "Epoch 93/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1313 - accuracy: 0.9526\n",
      "Epoch 00093: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-93.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1313 - accuracy: 0.9526 - val_loss: 0.5353 - val_accuracy: 0.8496 - lr: 0.0010\n",
      "Epoch 94/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1301 - accuracy: 0.9533\n",
      "Epoch 00094: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-94.ckpt\n",
      "625/625 [==============================] - 53s 86ms/step - loss: 0.1301 - accuracy: 0.9533 - val_loss: 0.3636 - val_accuracy: 0.8917 - lr: 0.0010\n",
      "Epoch 95/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1237 - accuracy: 0.9557\n",
      "Epoch 00095: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-95.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1237 - accuracy: 0.9557 - val_loss: 0.4034 - val_accuracy: 0.8799 - lr: 0.0010\n",
      "Epoch 96/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1280 - accuracy: 0.9540\n",
      "Epoch 00096: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-96.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1280 - accuracy: 0.9540 - val_loss: 0.3872 - val_accuracy: 0.8853 - lr: 0.0010\n",
      "Epoch 97/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1235 - accuracy: 0.9559\n",
      "Epoch 00097: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-97.ckpt\n",
      "625/625 [==============================] - 52s 84ms/step - loss: 0.1235 - accuracy: 0.9559 - val_loss: 0.4421 - val_accuracy: 0.8735 - lr: 0.0010\n",
      "Epoch 98/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1223 - accuracy: 0.9567\n",
      "Epoch 00098: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-98.ckpt\n",
      "625/625 [==============================] - 52s 84ms/step - loss: 0.1223 - accuracy: 0.9567 - val_loss: 0.4273 - val_accuracy: 0.8715 - lr: 0.0010\n",
      "Epoch 99/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1184 - accuracy: 0.9580\n",
      "Epoch 00099: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-99.ckpt\n",
      "625/625 [==============================] - 53s 85ms/step - loss: 0.1184 - accuracy: 0.9580 - val_loss: 0.4104 - val_accuracy: 0.8835 - lr: 0.0010\n",
      "Epoch 100/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1215 - accuracy: 0.9564\n",
      "Epoch 00100: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-100.ckpt\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1215 - accuracy: 0.9564 - val_loss: 0.4260 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 101/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1230 - accuracy: 0.9573\n",
      "Epoch 00101: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-101.ckpt\n",
      "625/625 [==============================] - 52s 82ms/step - loss: 0.1230 - accuracy: 0.9573 - val_loss: 0.4276 - val_accuracy: 0.8740 - lr: 0.0010\n",
      "Epoch 102/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1163 - accuracy: 0.9584\n",
      "Epoch 00102: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-102.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1163 - accuracy: 0.9584 - val_loss: 0.3929 - val_accuracy: 0.8887 - lr: 0.0010\n",
      "Epoch 103/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1145 - accuracy: 0.9597\n",
      "Epoch 00103: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-103.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1145 - accuracy: 0.9597 - val_loss: 0.4314 - val_accuracy: 0.8832 - lr: 0.0010\n",
      "Epoch 104/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1144 - accuracy: 0.9589\n",
      "Epoch 00104: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-104.ckpt\n",
      "625/625 [==============================] - 53s 84ms/step - loss: 0.1144 - accuracy: 0.9589 - val_loss: 0.3706 - val_accuracy: 0.8918 - lr: 0.0010\n",
      "Epoch 105/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1150 - accuracy: 0.9590\n",
      "Epoch 00105: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-105.ckpt\n",
      "625/625 [==============================] - 53s 85ms/step - loss: 0.1150 - accuracy: 0.9590 - val_loss: 0.4256 - val_accuracy: 0.8820 - lr: 0.0010\n",
      "Epoch 106/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1156 - accuracy: 0.9593\n",
      "Epoch 00106: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-106.ckpt\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1156 - accuracy: 0.9593 - val_loss: 0.4595 - val_accuracy: 0.8787 - lr: 0.0010\n",
      "Epoch 107/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1105 - accuracy: 0.9616\n",
      "Epoch 00107: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-107.ckpt\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1105 - accuracy: 0.9616 - val_loss: 0.4066 - val_accuracy: 0.8827 - lr: 0.0010\n",
      "Epoch 108/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1132 - accuracy: 0.9603\n",
      "Epoch 00108: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-108.ckpt\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1132 - accuracy: 0.9603 - val_loss: 0.3909 - val_accuracy: 0.8851 - lr: 0.0010\n",
      "Epoch 109/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1065 - accuracy: 0.9627\n",
      "Epoch 00109: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-109.ckpt\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1065 - accuracy: 0.9627 - val_loss: 0.3985 - val_accuracy: 0.8889 - lr: 0.0010\n",
      "Epoch 110/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1074 - accuracy: 0.9625\n",
      "Epoch 00110: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-110.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1074 - accuracy: 0.9625 - val_loss: 0.4975 - val_accuracy: 0.8628 - lr: 0.0010\n",
      "Epoch 111/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1095 - accuracy: 0.9617\n",
      "Epoch 00111: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-111.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1095 - accuracy: 0.9617 - val_loss: 0.3926 - val_accuracy: 0.8870 - lr: 0.0010\n",
      "Epoch 112/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1079 - accuracy: 0.9611\n",
      "Epoch 00112: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-112.ckpt\n",
      "625/625 [==============================] - 52s 84ms/step - loss: 0.1079 - accuracy: 0.9611 - val_loss: 0.4368 - val_accuracy: 0.8777 - lr: 0.0010\n",
      "Epoch 113/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1070 - accuracy: 0.9618\n",
      "Epoch 00113: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-113.ckpt\n",
      "625/625 [==============================] - 52s 82ms/step - loss: 0.1070 - accuracy: 0.9618 - val_loss: 0.4118 - val_accuracy: 0.8826 - lr: 0.0010\n",
      "Epoch 114/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1030 - accuracy: 0.9629\n",
      "Epoch 00114: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-114.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1030 - accuracy: 0.9629 - val_loss: 0.3902 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Epoch 115/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1021 - accuracy: 0.9635 ETA: 0s - loss: 0\n",
      "Epoch 00115: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-115.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1021 - accuracy: 0.9635 - val_loss: 0.4166 - val_accuracy: 0.8824 - lr: 0.0010\n",
      "Epoch 116/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1048 - accuracy: 0.9625\n",
      "Epoch 00116: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-116.ckpt\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1048 - accuracy: 0.9625 - val_loss: 0.4670 - val_accuracy: 0.8765 - lr: 0.0010\n",
      "Epoch 117/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1012 - accuracy: 0.9645\n",
      "Epoch 00117: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-117.ckpt\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1012 - accuracy: 0.9645 - val_loss: 0.4115 - val_accuracy: 0.8881 - lr: 0.0010\n",
      "Epoch 118/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0986 - accuracy: 0.9650\n",
      "Epoch 00118: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-118.ckpt\n",
      "625/625 [==============================] - 50s 81ms/step - loss: 0.0986 - accuracy: 0.9650 - val_loss: 0.4026 - val_accuracy: 0.8886 - lr: 0.0010\n",
      "Epoch 119/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0994 - accuracy: 0.9647\n",
      "Epoch 00119: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-119.ckpt\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.0994 - accuracy: 0.9647 - val_loss: 0.4357 - val_accuracy: 0.8764 - lr: 0.0010\n",
      "Epoch 120/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0958 - accuracy: 0.9665\n",
      "Epoch 00120: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-120.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.0958 - accuracy: 0.9665 - val_loss: 0.3782 - val_accuracy: 0.8958 - lr: 0.0010\n",
      "Epoch 121/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0963 - accuracy: 0.9663\n",
      "Epoch 00121: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-121.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.0963 - accuracy: 0.9663 - val_loss: 0.4354 - val_accuracy: 0.8807 - lr: 0.0010\n",
      "Epoch 122/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0941 - accuracy: 0.9669\n",
      "Epoch 00122: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-122.ckpt\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.0941 - accuracy: 0.9669 - val_loss: 0.3797 - val_accuracy: 0.8944 - lr: 0.0010\n",
      "Epoch 123/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0946 - accuracy: 0.9666\n",
      "Epoch 00123: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-123.ckpt\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.0946 - accuracy: 0.9666 - val_loss: 0.4391 - val_accuracy: 0.8810 - lr: 0.0010\n",
      "Epoch 124/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0961 - accuracy: 0.9668\n",
      "Epoch 00124: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-124.ckpt\n",
      "625/625 [==============================] - 50s 79ms/step - loss: 0.0961 - accuracy: 0.9668 - val_loss: 0.4221 - val_accuracy: 0.8858 - lr: 0.0010\n",
      "Epoch 125/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0941 - accuracy: 0.9675\n",
      "Epoch 00125: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-125.ckpt\n",
      "625/625 [==============================] - 50s 81ms/step - loss: 0.0941 - accuracy: 0.9675 - val_loss: 0.4630 - val_accuracy: 0.8760 - lr: 0.0010\n",
      "Epoch 126/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0931 - accuracy: 0.9675\n",
      "Epoch 00126: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-126.ckpt\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.0931 - accuracy: 0.9675 - val_loss: 0.4170 - val_accuracy: 0.8855 - lr: 0.0010\n",
      "Epoch 127/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0906 - accuracy: 0.9680\n",
      "Epoch 00127: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-127.ckpt\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.0906 - accuracy: 0.9680 - val_loss: 0.3731 - val_accuracy: 0.8941 - lr: 0.0010\n",
      "Epoch 128/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0871 - accuracy: 0.9686\n",
      "Epoch 00128: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-128.ckpt\n",
      "625/625 [==============================] - 50s 81ms/step - loss: 0.0871 - accuracy: 0.9686 - val_loss: 0.5008 - val_accuracy: 0.8706 - lr: 0.0010\n",
      "Epoch 129/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0932 - accuracy: 0.9674\n",
      "Epoch 00129: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-129.ckpt\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.0932 - accuracy: 0.9674 - val_loss: 0.4793 - val_accuracy: 0.8652 - lr: 0.0010\n",
      "Epoch 130/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 0.9696\n",
      "Epoch 00130: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-130.ckpt\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.0869 - accuracy: 0.9696 - val_loss: 0.4177 - val_accuracy: 0.8887 - lr: 0.0010\n",
      "Epoch 131/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0874 - accuracy: 0.9689\n",
      "Epoch 00131: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-131.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.0874 - accuracy: 0.9689 - val_loss: 0.4233 - val_accuracy: 0.8867 - lr: 0.0010\n",
      "Epoch 132/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 0.9700\n",
      "Epoch 00132: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-132.ckpt\n",
      "625/625 [==============================] - 49s 78ms/step - loss: 0.0839 - accuracy: 0.9700 - val_loss: 0.3935 - val_accuracy: 0.8948 - lr: 0.0010\n",
      "Epoch 133/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.9692\n",
      "Epoch 00133: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-133.ckpt\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.0860 - accuracy: 0.9692 - val_loss: 0.3934 - val_accuracy: 0.8962 - lr: 0.0010\n",
      "Epoch 134/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0825 - accuracy: 0.9703\n",
      "Epoch 00134: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-134.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.0825 - accuracy: 0.9703 - val_loss: 0.4174 - val_accuracy: 0.8892 - lr: 0.0010\n",
      "Epoch 135/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0841 - accuracy: 0.9703\n",
      "Epoch 00135: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-135.ckpt\n",
      "625/625 [==============================] - 53s 84ms/step - loss: 0.0841 - accuracy: 0.9703 - val_loss: 0.4687 - val_accuracy: 0.8778 - lr: 0.0010\n",
      "Epoch 136/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 0.9693\n",
      "Epoch 00136: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-136.ckpt\n",
      "625/625 [==============================] - 53s 84ms/step - loss: 0.0848 - accuracy: 0.9693 - val_loss: 0.3861 - val_accuracy: 0.8970 - lr: 0.0010\n",
      "Epoch 137/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 0.9683\n",
      "Epoch 00137: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-137.ckpt\n",
      "625/625 [==============================] - 52s 84ms/step - loss: 0.0869 - accuracy: 0.9683 - val_loss: 0.3747 - val_accuracy: 0.8963 - lr: 0.0010\n",
      "Epoch 138/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 0.9704\n",
      "Epoch 00138: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-138.ckpt\n",
      "625/625 [==============================] - 53s 84ms/step - loss: 0.0839 - accuracy: 0.9704 - val_loss: 0.3955 - val_accuracy: 0.8934 - lr: 0.0010\n",
      "Epoch 139/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0814 - accuracy: 0.9711\n",
      "Epoch 00139: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-139.ckpt\n",
      "625/625 [==============================] - 52s 84ms/step - loss: 0.0814 - accuracy: 0.9711 - val_loss: 0.3929 - val_accuracy: 0.8940 - lr: 0.0010\n",
      "Epoch 140/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0801 - accuracy: 0.9718\n",
      "Epoch 00140: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-140.ckpt\n",
      "625/625 [==============================] - 52s 84ms/step - loss: 0.0801 - accuracy: 0.9718 - val_loss: 0.4310 - val_accuracy: 0.8860 - lr: 0.0010\n",
      "Epoch 141/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0817 - accuracy: 0.9712\n",
      "Epoch 00141: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-141.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.0817 - accuracy: 0.9712 - val_loss: 0.3869 - val_accuracy: 0.8930 - lr: 0.0010\n",
      "Epoch 142/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0818 - accuracy: 0.9715\n",
      "Epoch 00142: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-142.ckpt\n",
      "625/625 [==============================] - 52s 84ms/step - loss: 0.0818 - accuracy: 0.9715 - val_loss: 0.3766 - val_accuracy: 0.8971 - lr: 0.0010\n",
      "Epoch 143/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.9729\n",
      "Epoch 00143: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-143.ckpt\n",
      "625/625 [==============================] - 53s 84ms/step - loss: 0.0778 - accuracy: 0.9729 - val_loss: 0.4126 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Epoch 144/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0756 - accuracy: 0.9733\n",
      "Epoch 00144: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-144.ckpt\n",
      "625/625 [==============================] - 53s 84ms/step - loss: 0.0756 - accuracy: 0.9733 - val_loss: 0.4105 - val_accuracy: 0.8906 - lr: 0.0010\n",
      "Epoch 145/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0760 - accuracy: 0.9732\n",
      "Epoch 00145: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-145.ckpt\n",
      "625/625 [==============================] - 52s 84ms/step - loss: 0.0760 - accuracy: 0.9732 - val_loss: 0.4826 - val_accuracy: 0.8795 - lr: 0.0010\n",
      "Epoch 146/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9736\n",
      "Epoch 00146: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-146.ckpt\n",
      "625/625 [==============================] - 53s 86ms/step - loss: 0.0754 - accuracy: 0.9736 - val_loss: 0.3669 - val_accuracy: 0.8971 - lr: 0.0010\n",
      "Epoch 147/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0744 - accuracy: 0.9740\n",
      "Epoch 00147: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-147.ckpt\n",
      "625/625 [==============================] - 54s 86ms/step - loss: 0.0744 - accuracy: 0.9740 - val_loss: 0.4322 - val_accuracy: 0.8879 - lr: 0.0010\n",
      "Epoch 148/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0782 - accuracy: 0.9714\n",
      "Epoch 00148: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-148.ckpt\n",
      "625/625 [==============================] - 53s 84ms/step - loss: 0.0782 - accuracy: 0.9714 - val_loss: 0.4086 - val_accuracy: 0.8937 - lr: 0.0010\n",
      "Epoch 149/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0716 - accuracy: 0.9740\n",
      "Epoch 00149: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-149.ckpt\n",
      "625/625 [==============================] - 53s 85ms/step - loss: 0.0716 - accuracy: 0.9740 - val_loss: 0.4010 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Epoch 150/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0726 - accuracy: 0.9744\n",
      "Epoch 00150: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-150.ckpt\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.0726 - accuracy: 0.9744 - val_loss: 0.4531 - val_accuracy: 0.8891 - lr: 0.0010\n",
      "Epoch 151/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0788 - accuracy: 0.9718\n",
      "Epoch 00151: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-151.ckpt\n",
      "625/625 [==============================] - 53s 85ms/step - loss: 0.0788 - accuracy: 0.9718 - val_loss: 0.4071 - val_accuracy: 0.8880 - lr: 0.0010\n",
      "Epoch 152/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0722 - accuracy: 0.9742\n",
      "Epoch 00152: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-152.ckpt\n",
      "625/625 [==============================] - 53s 84ms/step - loss: 0.0722 - accuracy: 0.9742 - val_loss: 0.3907 - val_accuracy: 0.8925 - lr: 0.0010\n",
      "Epoch 153/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.9749\n",
      "Epoch 00153: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-153.ckpt\n",
      "625/625 [==============================] - 52s 84ms/step - loss: 0.0718 - accuracy: 0.9749 - val_loss: 0.3653 - val_accuracy: 0.9008 - lr: 0.0010\n",
      "Epoch 154/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0671 - accuracy: 0.9766\n",
      "Epoch 00154: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-154.ckpt\n",
      "625/625 [==============================] - 52s 84ms/step - loss: 0.0671 - accuracy: 0.9766 - val_loss: 0.4306 - val_accuracy: 0.8925 - lr: 0.0010\n",
      "Epoch 155/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0715 - accuracy: 0.9745\n",
      "Epoch 00155: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-155.ckpt\n",
      "625/625 [==============================] - 53s 84ms/step - loss: 0.0715 - accuracy: 0.9745 - val_loss: 0.4287 - val_accuracy: 0.8936 - lr: 0.0010\n",
      "Epoch 156/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0727 - accuracy: 0.9740\n",
      "Epoch 00156: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-156.ckpt\n",
      "625/625 [==============================] - 50s 80ms/step - loss: 0.0727 - accuracy: 0.9740 - val_loss: 0.4447 - val_accuracy: 0.8840 - lr: 0.0010\n",
      "Epoch 157/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0671 - accuracy: 0.9764\n",
      "Epoch 00157: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-157.ckpt\n",
      "625/625 [==============================] - 48s 77ms/step - loss: 0.0671 - accuracy: 0.9764 - val_loss: 0.4622 - val_accuracy: 0.8818 - lr: 0.0010\n",
      "Epoch 158/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.9756\n",
      "Epoch 00158: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-158.ckpt\n",
      "625/625 [==============================] - 47s 75ms/step - loss: 0.0700 - accuracy: 0.9756 - val_loss: 0.3912 - val_accuracy: 0.8952 - lr: 0.0010\n",
      "Epoch 159/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0708 - accuracy: 0.9753\n",
      "Epoch 00159: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-159.ckpt\n",
      "625/625 [==============================] - 50s 81ms/step - loss: 0.0708 - accuracy: 0.9753 - val_loss: 0.4134 - val_accuracy: 0.8875 - lr: 0.0010\n",
      "Epoch 160/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0455 - accuracy: 0.9844\n",
      "Epoch 00160: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-160.ckpt\n",
      "625/625 [==============================] - 49s 78ms/step - loss: 0.0455 - accuracy: 0.9844 - val_loss: 0.3071 - val_accuracy: 0.9141 - lr: 1.0000e-04\n",
      "Epoch 161/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9882\n",
      "Epoch 00161: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-161.ckpt\n",
      "625/625 [==============================] - 50s 80ms/step - loss: 0.0346 - accuracy: 0.9882 - val_loss: 0.3115 - val_accuracy: 0.9135 - lr: 1.0000e-04\n",
      "Epoch 162/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.9898\n",
      "Epoch 00162: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-162.ckpt\n",
      "625/625 [==============================] - 50s 80ms/step - loss: 0.0313 - accuracy: 0.9898 - val_loss: 0.3053 - val_accuracy: 0.9173 - lr: 1.0000e-04\n",
      "Epoch 163/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0280 - accuracy: 0.9908\n",
      "Epoch 00163: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-163.ckpt\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.0280 - accuracy: 0.9908 - val_loss: 0.3188 - val_accuracy: 0.9176 - lr: 1.0000e-04\n",
      "Epoch 164/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 0.9909\n",
      "Epoch 00164: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-164.ckpt\n",
      "625/625 [==============================] - 48s 76ms/step - loss: 0.0271 - accuracy: 0.9909 - val_loss: 0.3241 - val_accuracy: 0.9156 - lr: 1.0000e-04\n",
      "Epoch 165/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9916\n",
      "Epoch 00165: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-165.ckpt\n",
      "625/625 [==============================] - 49s 78ms/step - loss: 0.0256 - accuracy: 0.9916 - val_loss: 0.3064 - val_accuracy: 0.9184 - lr: 1.0000e-04\n",
      "Epoch 166/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.9922\n",
      "Epoch 00166: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-166.ckpt\n",
      "625/625 [==============================] - 50s 80ms/step - loss: 0.0239 - accuracy: 0.9922 - val_loss: 0.3085 - val_accuracy: 0.9199 - lr: 1.0000e-04\n",
      "Epoch 167/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 0.9923\n",
      "Epoch 00167: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-167.ckpt\n",
      "625/625 [==============================] - 49s 79ms/step - loss: 0.0242 - accuracy: 0.9923 - val_loss: 0.3094 - val_accuracy: 0.9186 - lr: 1.0000e-04\n",
      "Epoch 168/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9927\n",
      "Epoch 00168: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-168.ckpt\n",
      "625/625 [==============================] - 49s 78ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 0.3200 - val_accuracy: 0.9191 - lr: 1.0000e-04\n",
      "Epoch 169/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9929\n",
      "Epoch 00169: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-169.ckpt\n",
      "625/625 [==============================] - 49s 78ms/step - loss: 0.0219 - accuracy: 0.9929 - val_loss: 0.3322 - val_accuracy: 0.9165 - lr: 1.0000e-04\n",
      "Epoch 170/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9937\n",
      "Epoch 00170: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-170.ckpt\n",
      "625/625 [==============================] - 50s 80ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 0.3193 - val_accuracy: 0.9233 - lr: 1.0000e-04\n",
      "Epoch 171/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9930\n",
      "Epoch 00171: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-171.ckpt\n",
      "625/625 [==============================] - 49s 79ms/step - loss: 0.0201 - accuracy: 0.9930 - val_loss: 0.3219 - val_accuracy: 0.9215 - lr: 1.0000e-04\n",
      "Epoch 172/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9935\n",
      "Epoch 00172: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-172.ckpt\n",
      "625/625 [==============================] - 49s 79ms/step - loss: 0.0196 - accuracy: 0.9935 - val_loss: 0.3150 - val_accuracy: 0.9178 - lr: 1.0000e-04\n",
      "Epoch 173/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9946\n",
      "Epoch 00173: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-173.ckpt\n",
      "625/625 [==============================] - 49s 78ms/step - loss: 0.0171 - accuracy: 0.9946 - val_loss: 0.3266 - val_accuracy: 0.9193 - lr: 1.0000e-04\n",
      "Epoch 174/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9933\n",
      "Epoch 00174: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-174.ckpt\n",
      "625/625 [==============================] - 49s 79ms/step - loss: 0.0188 - accuracy: 0.9933 - val_loss: 0.3259 - val_accuracy: 0.9195 - lr: 1.0000e-04\n",
      "Epoch 175/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9949\n",
      "Epoch 00175: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-175.ckpt\n",
      "625/625 [==============================] - 49s 78ms/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 0.3296 - val_accuracy: 0.9177 - lr: 1.0000e-04\n",
      "Epoch 176/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9940\n",
      "Epoch 00176: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-176.ckpt\n",
      "625/625 [==============================] - 49s 78ms/step - loss: 0.0181 - accuracy: 0.9940 - val_loss: 0.3181 - val_accuracy: 0.9216 - lr: 1.0000e-04\n",
      "Epoch 177/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9939\n",
      "Epoch 00177: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-177.ckpt\n",
      "625/625 [==============================] - 49s 78ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 0.3251 - val_accuracy: 0.9216 - lr: 1.0000e-04\n",
      "Epoch 178/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9945\n",
      "Epoch 00178: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-178.ckpt\n",
      "625/625 [==============================] - 50s 80ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 0.3340 - val_accuracy: 0.9196 - lr: 1.0000e-04\n",
      "Epoch 179/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.9946\n",
      "Epoch 00179: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-179.ckpt\n",
      "625/625 [==============================] - 48s 77ms/step - loss: 0.0167 - accuracy: 0.9946 - val_loss: 0.3354 - val_accuracy: 0.9198 - lr: 1.0000e-04\n",
      "Epoch 180/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.9949\n",
      "Epoch 00180: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-180.ckpt\n",
      "625/625 [==============================] - 50s 80ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.3279 - val_accuracy: 0.9196 - lr: 1.0000e-04\n",
      "Epoch 181/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.9947\n",
      "Epoch 00181: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-181.ckpt\n",
      "625/625 [==============================] - 49s 78ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.3343 - val_accuracy: 0.9216 - lr: 1.0000e-04\n",
      "Epoch 182/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9945\n",
      "Epoch 00182: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-182.ckpt\n",
      "625/625 [==============================] - 50s 79ms/step - loss: 0.0163 - accuracy: 0.9945 - val_loss: 0.3248 - val_accuracy: 0.9204 - lr: 1.0000e-04\n",
      "Epoch 183/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9948\n",
      "Epoch 00183: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-183.ckpt\n",
      "625/625 [==============================] - 49s 78ms/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 0.3352 - val_accuracy: 0.9196 - lr: 1.0000e-04\n",
      "Epoch 184/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9952\n",
      "Epoch 00184: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-184.ckpt\n",
      "625/625 [==============================] - 49s 78ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 0.3288 - val_accuracy: 0.9224 - lr: 1.0000e-04\n",
      "Epoch 185/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9947\n",
      "Epoch 00185: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-185.ckpt\n",
      "625/625 [==============================] - 49s 79ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.3297 - val_accuracy: 0.9190 - lr: 1.0000e-04\n",
      "Epoch 186/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9950\n",
      "Epoch 00186: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-186.ckpt\n",
      "625/625 [==============================] - 49s 79ms/step - loss: 0.0147 - accuracy: 0.9950 - val_loss: 0.3418 - val_accuracy: 0.9189 - lr: 1.0000e-04\n",
      "Epoch 187/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.9952\n",
      "Epoch 00187: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-187.ckpt\n",
      "625/625 [==============================] - 49s 79ms/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 0.3463 - val_accuracy: 0.9191 - lr: 1.0000e-04\n",
      "Epoch 188/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9948\n",
      "Epoch 00188: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-188.ckpt\n",
      "625/625 [==============================] - 50s 80ms/step - loss: 0.0147 - accuracy: 0.9948 - val_loss: 0.3421 - val_accuracy: 0.9187 - lr: 1.0000e-04\n",
      "Epoch 189/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9953\n",
      "Epoch 00189: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-189.ckpt\n",
      "625/625 [==============================] - 50s 80ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.3505 - val_accuracy: 0.9200 - lr: 1.0000e-04\n",
      "Epoch 190/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.9946\n",
      "Epoch 00190: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-190.ckpt\n",
      "625/625 [==============================] - 50s 79ms/step - loss: 0.0156 - accuracy: 0.9946 - val_loss: 0.3499 - val_accuracy: 0.9189 - lr: 1.0000e-04\n",
      "Epoch 191/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.9955\n",
      "Epoch 00191: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-191.ckpt\n",
      "625/625 [==============================] - 48s 77ms/step - loss: 0.0145 - accuracy: 0.9955 - val_loss: 0.3382 - val_accuracy: 0.9213 - lr: 1.0000e-04\n",
      "Epoch 192/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9948\n",
      "Epoch 00192: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-192.ckpt\n",
      "625/625 [==============================] - 49s 79ms/step - loss: 0.0150 - accuracy: 0.9948 - val_loss: 0.3452 - val_accuracy: 0.9201 - lr: 1.0000e-04\n",
      "Epoch 193/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9953\n",
      "Epoch 00193: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-193.ckpt\n",
      "625/625 [==============================] - 49s 79ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 0.3428 - val_accuracy: 0.9209 - lr: 1.0000e-04\n",
      "Epoch 194/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.9956\n",
      "Epoch 00194: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-194.ckpt\n",
      "625/625 [==============================] - 49s 79ms/step - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.3589 - val_accuracy: 0.9205 - lr: 1.0000e-04\n",
      "Epoch 195/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9955\n",
      "Epoch 00195: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-195.ckpt\n",
      "625/625 [==============================] - 49s 79ms/step - loss: 0.0131 - accuracy: 0.9955 - val_loss: 0.3434 - val_accuracy: 0.9224 - lr: 1.0000e-04\n",
      "Epoch 196/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9954\n",
      "Epoch 00196: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-196.ckpt\n",
      "625/625 [==============================] - 49s 79ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.3602 - val_accuracy: 0.9184 - lr: 1.0000e-04\n",
      "Epoch 197/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9951\n",
      "Epoch 00197: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-197.ckpt\n",
      "625/625 [==============================] - 48s 78ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.3485 - val_accuracy: 0.9210 - lr: 1.0000e-04\n",
      "Epoch 198/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.9956\n",
      "Epoch 00198: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-198.ckpt\n",
      "625/625 [==============================] - 48s 77ms/step - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.3418 - val_accuracy: 0.9224 - lr: 1.0000e-04\n",
      "Epoch 199/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.9956\n",
      "Epoch 00199: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-199.ckpt\n",
      "625/625 [==============================] - 48s 77ms/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.3479 - val_accuracy: 0.9221 - lr: 1.0000e-04\n",
      "Epoch 200/200\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9961\n",
      "Epoch 00200: saving model to ./models/ran56_v1/history/checkpoints/Tue_Dec_21_03_03_26_2021\\cp-200.ckpt\n",
      "625/625 [==============================] - 48s 76ms/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 0.3519 - val_accuracy: 0.9194 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "ran56_v1_history = model.fit(datagen.flow(X_train, y_train, batch_size=64, subset='training'), validation_data=datagen.flow(X_train, y_train, batch_size=64, subset='validation'),\n",
    "                    epochs=200, callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5ed6895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/ran56_v1/graphs/ran56_v1_Loss.png\n",
      "./models/ran56_v1/graphs/ran56_v1_Accuracy.png\n"
     ]
    }
   ],
   "source": [
    "plot_loss_filename = graph_path + '/ran56_v1_Loss.png'\n",
    "print(plot_loss_filename)\n",
    "plot_acc_filename = graph_path + '/ran56_v1_Accuracy.png'\n",
    "print(plot_acc_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4765a030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "plt.title(\"Attention 56, v1: Training Loss vs. Validation Loss\", fontsize=18)\n",
    "plt.plot(ran56_v1_history.history['loss'], label='training loss', color='red')\n",
    "plt.plot(ran56_v1_history.history['val_loss'], label = 'validation loss', color='blue')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.savefig(plot_loss_filename)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3bda23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "plt.title(\"Attention 56, v2: Training Accuracy vs Validation Accuracy\", fontsize=18)\n",
    "plt.plot(ran56_v1_history.history['accuracy'], label='training accuracy', color='g')\n",
    "plt.plot(ran56_v1_history.history['val_accuracy'], label = 'validation accuracy', color='c')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.savefig(plot_acc_filename)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a32fc9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/ran56_v1/history/ran56_v1_history_Tue_Dec_21_05_58_59_2021\n"
     ]
    }
   ],
   "source": [
    "history_filename = history_path + '/ran56_v1_history_' + time.ctime().replace(' ','_').replace(':','_')\n",
    "print(history_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c08b214e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(history_filename+'.npy', ran56_v1_history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83c22a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ran56_v2_history=np.load(history_filename+'.npy', allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e729122d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran56_v1/saved_models/ran56_v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran56_v1/saved_models/ran56_v1\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    }
   ],
   "source": [
    "model.save(saved_model_path + '/ran56_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e80e71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59b5bca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)\n",
    "preds = np.argmax(preds, axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fae43323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      1000\n",
      "           1       0.91      0.98      0.94      1000\n",
      "           2       0.91      0.91      0.91      1000\n",
      "           3       0.84      0.84      0.84      1000\n",
      "           4       0.90      0.92      0.91      1000\n",
      "           5       0.92      0.84      0.88      1000\n",
      "           6       0.91      0.96      0.94      1000\n",
      "           7       0.96      0.93      0.95      1000\n",
      "           8       0.95      0.95      0.95      1000\n",
      "           9       0.94      0.94      0.94      1000\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_true, preds)\n",
    "cr=  classification_report(y_true, preds)\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(cr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b62cea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
