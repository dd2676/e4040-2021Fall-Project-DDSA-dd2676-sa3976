{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcb109ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle, os, sys, time\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "from utils.MyRAN92_v2 import ResidualAttentionModel_92\n",
    "from contextlib import redirect_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60850bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "print(gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eae87dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/ran92_v2_arl\n",
      "./models/ran92_v2_arl/history\n",
      "./models/ran92_v2_arl/saved_models\n",
      "./models/ran92_v2_arl/graphs\n"
     ]
    }
   ],
   "source": [
    "path = './models'\n",
    "model_name = '/ran92_v2_arl'\n",
    "model_path = path + model_name\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "    print(model_path)\n",
    "else:\n",
    "    print(model_path + ' already exists.')\n",
    "\n",
    "history_path = model_path + '/history'\n",
    "if not os.path.exists(history_path):\n",
    "    os.makedirs(history_path)\n",
    "    print(history_path)\n",
    "else:\n",
    "    print(history_path + ' already exists.')\n",
    "\n",
    "saved_model_path = model_path + '/saved_models'\n",
    "if not os.path.exists(saved_model_path):\n",
    "    os.makedirs(saved_model_path)\n",
    "    print(saved_model_path)\n",
    "else:\n",
    "    print(saved_model_path + ' already exists.')\n",
    "\n",
    "graph_path = model_path + '/graphs'\n",
    "if not os.path.exists(graph_path):\n",
    "    os.makedirs(graph_path)\n",
    "    print(graph_path)\n",
    "else:\n",
    "    print(graph_path + ' already exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dc362d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27829a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=20,\n",
    "                                                          width_shift_range=0.2,\n",
    "                                                          height_shift_range=0.2,\n",
    "                                                          horizontal_flip=True,\n",
    "                                                          validation_split=0.2)\n",
    "\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "# train_mean = np.mean(X_train, axis=(0,1,2))\n",
    "# train_std = np.std(X_train, axis=(0,1,2))\n",
    "# np.save(\"train_mean.npy\", train_mean)\n",
    "# np.save(\"train_std.npy\", train_std)\n",
    "\n",
    "train_mean = np.load(\"train_mean.npy\")\n",
    "train_std = np.load(\"train_std.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "908cb873",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train = X_train - X_train.mean()#train_mean) / train_std\n",
    "X_test = (X_test - X_test.mean())\n",
    "\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "output_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28ac1ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Model_Input (InputLayer)       [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " Conv1_In (Conv2D)              (None, 32, 32, 32)   864         ['Model_Input[0][0]']            \n",
      "                                                                                                  \n",
      " BN_In (BatchNormalization)     (None, 32, 32, 32)   128         ['Conv1_In[0][0]']               \n",
      "                                                                                                  \n",
      " ReLU_In (Activation)           (None, 32, 32, 32)   0           ['BN_In[0][0]']                  \n",
      "                                                                                                  \n",
      " ResUnit_L1_NotAttnModule_1_NoD  (None, 32, 32, 32)  128         ['ReLU_In[0][0]']                \n",
      " S (BatchNormalization)                                                                           \n",
      "                                                                                                  \n",
      " ResUnit_L2_NotAttnModule_1_NoD  (None, 32, 32, 32)  0           ['ResUnit_L1_NotAttnModule_1_NoDS\n",
      " S (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L3_NotAttnModule_1_NoD  (None, 32, 32, 32)  1024        ['ResUnit_L2_NotAttnModule_1_NoDS\n",
      " S (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L4_NotAttnModule_1_NoD  (None, 32, 32, 32)  128         ['ResUnit_L3_NotAttnModule_1_NoDS\n",
      " S (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L5_NotAttnModule_1_NoD  (None, 32, 32, 32)  0           ['ResUnit_L4_NotAttnModule_1_NoDS\n",
      " S (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L6_NotAttnModule_1_NoD  (None, 32, 32, 32)  9216        ['ResUnit_L5_NotAttnModule_1_NoDS\n",
      " S (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L7_NotAttnModule_1_NoD  (None, 32, 32, 32)  128         ['ResUnit_L6_NotAttnModule_1_NoDS\n",
      " S (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L8_NotAttnModule_1_NoD  (None, 32, 32, 32)  0           ['ResUnit_L7_NotAttnModule_1_NoDS\n",
      " S (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L9_NotAttnModule_1_NoD  (None, 32, 32, 128)  4096       ['ResUnit_L8_NotAttnModule_1_NoDS\n",
      " S (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_NotAttnModule_1_No  (None, 32, 32, 128)  4096       ['ResUnit_L2_NotAttnModule_1_NoDS\n",
      " DS (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L11_NotAttnModule_1_No  (None, 32, 32, 128)  0          ['ResUnit_L9_NotAttnModule_1_NoDS\n",
      " DS (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_NotAttnModule_1_NoD\n",
      "                                                                 S[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L1_Input-p-1-1_AttnS1-  (None, 32, 32, 128)  512        ['ResUnit_L11_NotAttnModule_1_NoD\n",
      " 1 (BatchNormalization)                                          S[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L2_Input-p-1-1_AttnS1-  (None, 32, 32, 128)  0          ['ResUnit_L1_Input-p-1-1_AttnS1-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L3_Input-p-1-1_AttnS1-  (None, 32, 32, 32)  4096        ['ResUnit_L2_Input-p-1-1_AttnS1-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L4_Input-p-1-1_AttnS1-  (None, 32, 32, 32)  128         ['ResUnit_L3_Input-p-1-1_AttnS1-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L5_Input-p-1-1_AttnS1-  (None, 32, 32, 32)  0           ['ResUnit_L4_Input-p-1-1_AttnS1-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L6_Input-p-1-1_AttnS1-  (None, 32, 32, 32)  9216        ['ResUnit_L5_Input-p-1-1_AttnS1-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L7_Input-p-1-1_AttnS1-  (None, 32, 32, 32)  128         ['ResUnit_L6_Input-p-1-1_AttnS1-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L8_Input-p-1-1_AttnS1-  (None, 32, 32, 32)  0           ['ResUnit_L7_Input-p-1-1_AttnS1-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L9_Input-p-1-1_AttnS1-  (None, 32, 32, 128)  4096       ['ResUnit_L8_Input-p-1-1_AttnS1-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_Input-p-1-1_AttnS1  (None, 32, 32, 128)  16384      ['ResUnit_L2_Input-p-1-1_AttnS1-1\n",
      " -1 (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L11_Input-p-1-1_AttnS1  (None, 32, 32, 128)  0          ['ResUnit_L9_Input-p-1-1_AttnS1-1\n",
      " -1 (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_Input-p-1-1_AttnS1-\n",
      "                                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " MaxPool_DownSamp-1_Mask_AttnS1  (None, 16, 16, 128)  0          ['ResUnit_L11_Input-p-1-1_AttnS1-\n",
      " -1 (MaxPooling2D)                                               1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L1_DownSamp-r-1-1_Mask  (None, 16, 16, 128)  512        ['MaxPool_DownSamp-1_Mask_AttnS1-\n",
      " _AttnS1-1 (BatchNormalization)                                  1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L2_DownSamp-r-1-1_Mask  (None, 16, 16, 128)  0          ['ResUnit_L1_DownSamp-r-1-1_Mask_\n",
      " _AttnS1-1 (Activation)                                          AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L3_DownSamp-r-1-1_Mask  (None, 16, 16, 32)  4096        ['ResUnit_L2_DownSamp-r-1-1_Mask_\n",
      " _AttnS1-1 (Conv2D)                                              AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L4_DownSamp-r-1-1_Mask  (None, 16, 16, 32)  128         ['ResUnit_L3_DownSamp-r-1-1_Mask_\n",
      " _AttnS1-1 (BatchNormalization)                                  AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L5_DownSamp-r-1-1_Mask  (None, 16, 16, 32)  0           ['ResUnit_L4_DownSamp-r-1-1_Mask_\n",
      " _AttnS1-1 (Activation)                                          AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L6_DownSamp-r-1-1_Mask  (None, 16, 16, 32)  9216        ['ResUnit_L5_DownSamp-r-1-1_Mask_\n",
      " _AttnS1-1 (Conv2D)                                              AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L7_DownSamp-r-1-1_Mask  (None, 16, 16, 32)  128         ['ResUnit_L6_DownSamp-r-1-1_Mask_\n",
      " _AttnS1-1 (BatchNormalization)                                  AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L8_DownSamp-r-1-1_Mask  (None, 16, 16, 32)  0           ['ResUnit_L7_DownSamp-r-1-1_Mask_\n",
      " _AttnS1-1 (Activation)                                          AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L9_DownSamp-r-1-1_Mask  (None, 16, 16, 128)  4096       ['ResUnit_L8_DownSamp-r-1-1_Mask_\n",
      " _AttnS1-1 (Conv2D)                                              AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L10_DownSamp-r-1-1_Mas  (None, 16, 16, 128)  16384      ['ResUnit_L2_DownSamp-r-1-1_Mask_\n",
      " k_AttnS1-1 (Conv2D)                                             AttnS1-1[0][0]']                 \n",
      "                                                                                                  \n",
      " ResUnit_L11_DownSamp-r-1-1_Mas  (None, 16, 16, 128)  0          ['ResUnit_L9_DownSamp-r-1-1_Mask_\n",
      " k_AttnS1-1 (Add)                                                AttnS1-1[0][0]',                 \n",
      "                                                                  'ResUnit_L10_DownSamp-r-1-1_Mask\n",
      "                                                                 _AttnS1-1[0][0]']                \n",
      "                                                                                                  \n",
      " MaxPool_DownSamp-2_Mask_AttnS1  (None, 8, 8, 128)   0           ['ResUnit_L11_DownSamp-r-1-1_Mask\n",
      " -1 (MaxPooling2D)                                               _AttnS1-1[0][0]']                \n",
      "                                                                                                  \n",
      " ResUnit_L1_Mid-2r-2-1_Mask_Att  (None, 8, 8, 128)   512         ['MaxPool_DownSamp-2_Mask_AttnS1-\n",
      " nS1-1 (BatchNormalization)                                      1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L2_Mid-2r-2-1_Mask_Att  (None, 8, 8, 128)   0           ['ResUnit_L1_Mid-2r-2-1_Mask_Attn\n",
      " nS1-1 (Activation)                                              S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L3_Mid-2r-2-1_Mask_Att  (None, 8, 8, 32)    4096        ['ResUnit_L2_Mid-2r-2-1_Mask_Attn\n",
      " nS1-1 (Conv2D)                                                  S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L4_Mid-2r-2-1_Mask_Att  (None, 8, 8, 32)    128         ['ResUnit_L3_Mid-2r-2-1_Mask_Attn\n",
      " nS1-1 (BatchNormalization)                                      S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L5_Mid-2r-2-1_Mask_Att  (None, 8, 8, 32)    0           ['ResUnit_L4_Mid-2r-2-1_Mask_Attn\n",
      " nS1-1 (Activation)                                              S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L6_Mid-2r-2-1_Mask_Att  (None, 8, 8, 32)    9216        ['ResUnit_L5_Mid-2r-2-1_Mask_Attn\n",
      " nS1-1 (Conv2D)                                                  S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L7_Mid-2r-2-1_Mask_Att  (None, 8, 8, 32)    128         ['ResUnit_L6_Mid-2r-2-1_Mask_Attn\n",
      " nS1-1 (BatchNormalization)                                      S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L8_Mid-2r-2-1_Mask_Att  (None, 8, 8, 32)    0           ['ResUnit_L7_Mid-2r-2-1_Mask_Attn\n",
      " nS1-1 (Activation)                                              S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L9_Mid-2r-2-1_Mask_Att  (None, 8, 8, 128)   4096        ['ResUnit_L8_Mid-2r-2-1_Mask_Attn\n",
      " nS1-1 (Conv2D)                                                  S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L10_Mid-2r-2-1_Mask_At  (None, 8, 8, 128)   16384       ['ResUnit_L2_Mid-2r-2-1_Mask_Attn\n",
      " tnS1-1 (Conv2D)                                                 S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L11_Mid-2r-2-1_Mask_At  (None, 8, 8, 128)   0           ['ResUnit_L9_Mid-2r-2-1_Mask_Attn\n",
      " tnS1-1 (Add)                                                    S1-1[0][0]',                     \n",
      "                                                                  'ResUnit_L10_Mid-2r-2-1_Mask_Att\n",
      "                                                                 nS1-1[0][0]']                    \n",
      "                                                                                                  \n",
      " ResUnit_L1_Mid-2r-2-2_Mask_Att  (None, 8, 8, 128)   512         ['ResUnit_L11_Mid-2r-2-1_Mask_Att\n",
      " nS1-1 (BatchNormalization)                                      nS1-1[0][0]']                    \n",
      "                                                                                                  \n",
      " ResUnit_L2_Mid-2r-2-2_Mask_Att  (None, 8, 8, 128)   0           ['ResUnit_L1_Mid-2r-2-2_Mask_Attn\n",
      " nS1-1 (Activation)                                              S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L3_Mid-2r-2-2_Mask_Att  (None, 8, 8, 32)    4096        ['ResUnit_L2_Mid-2r-2-2_Mask_Attn\n",
      " nS1-1 (Conv2D)                                                  S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L1_SkipConn-1_Mask_Att  (None, 16, 16, 128)  512        ['ResUnit_L11_DownSamp-r-1-1_Mask\n",
      " nS1-1 (BatchNormalization)                                      _AttnS1-1[0][0]']                \n",
      "                                                                                                  \n",
      " ResUnit_L4_Mid-2r-2-2_Mask_Att  (None, 8, 8, 32)    128         ['ResUnit_L3_Mid-2r-2-2_Mask_Attn\n",
      " nS1-1 (BatchNormalization)                                      S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L2_SkipConn-1_Mask_Att  (None, 16, 16, 128)  0          ['ResUnit_L1_SkipConn-1_Mask_Attn\n",
      " nS1-1 (Activation)                                              S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L5_Mid-2r-2-2_Mask_Att  (None, 8, 8, 32)    0           ['ResUnit_L4_Mid-2r-2-2_Mask_Attn\n",
      " nS1-1 (Activation)                                              S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L3_SkipConn-1_Mask_Att  (None, 16, 16, 32)  4096        ['ResUnit_L2_SkipConn-1_Mask_Attn\n",
      " nS1-1 (Conv2D)                                                  S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L1_Trunk-t-2-1_AttnS1-  (None, 32, 32, 128)  512        ['ResUnit_L11_Input-p-1-1_AttnS1-\n",
      " 1 (BatchNormalization)                                          1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L6_Mid-2r-2-2_Mask_Att  (None, 8, 8, 32)    9216        ['ResUnit_L5_Mid-2r-2-2_Mask_Attn\n",
      " nS1-1 (Conv2D)                                                  S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L4_SkipConn-1_Mask_Att  (None, 16, 16, 32)  128         ['ResUnit_L3_SkipConn-1_Mask_Attn\n",
      " nS1-1 (BatchNormalization)                                      S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L2_Trunk-t-2-1_AttnS1-  (None, 32, 32, 128)  0          ['ResUnit_L1_Trunk-t-2-1_AttnS1-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L7_Mid-2r-2-2_Mask_Att  (None, 8, 8, 32)    128         ['ResUnit_L6_Mid-2r-2-2_Mask_Attn\n",
      " nS1-1 (BatchNormalization)                                      S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L5_SkipConn-1_Mask_Att  (None, 16, 16, 32)  0           ['ResUnit_L4_SkipConn-1_Mask_Attn\n",
      " nS1-1 (Activation)                                              S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L3_Trunk-t-2-1_AttnS1-  (None, 32, 32, 32)  4096        ['ResUnit_L2_Trunk-t-2-1_AttnS1-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L8_Mid-2r-2-2_Mask_Att  (None, 8, 8, 32)    0           ['ResUnit_L7_Mid-2r-2-2_Mask_Attn\n",
      " nS1-1 (Activation)                                              S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L6_SkipConn-1_Mask_Att  (None, 16, 16, 32)  9216        ['ResUnit_L5_SkipConn-1_Mask_Attn\n",
      " nS1-1 (Conv2D)                                                  S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L4_Trunk-t-2-1_AttnS1-  (None, 32, 32, 32)  128         ['ResUnit_L3_Trunk-t-2-1_AttnS1-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L9_Mid-2r-2-2_Mask_Att  (None, 8, 8, 128)   4096        ['ResUnit_L8_Mid-2r-2-2_Mask_Attn\n",
      " nS1-1 (Conv2D)                                                  S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L10_Mid-2r-2-2_Mask_At  (None, 8, 8, 128)   16384       ['ResUnit_L2_Mid-2r-2-2_Mask_Attn\n",
      " tnS1-1 (Conv2D)                                                 S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L7_SkipConn-1_Mask_Att  (None, 16, 16, 32)  128         ['ResUnit_L6_SkipConn-1_Mask_Attn\n",
      " nS1-1 (BatchNormalization)                                      S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L5_Trunk-t-2-1_AttnS1-  (None, 32, 32, 32)  0           ['ResUnit_L4_Trunk-t-2-1_AttnS1-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L11_Mid-2r-2-2_Mask_At  (None, 8, 8, 128)   0           ['ResUnit_L9_Mid-2r-2-2_Mask_Attn\n",
      " tnS1-1 (Add)                                                    S1-1[0][0]',                     \n",
      "                                                                  'ResUnit_L10_Mid-2r-2-2_Mask_Att\n",
      "                                                                 nS1-1[0][0]']                    \n",
      "                                                                                                  \n",
      " ResUnit_L8_SkipConn-1_Mask_Att  (None, 16, 16, 32)  0           ['ResUnit_L7_SkipConn-1_Mask_Attn\n",
      " nS1-1 (Activation)                                              S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L6_Trunk-t-2-1_AttnS1-  (None, 32, 32, 32)  9216        ['ResUnit_L5_Trunk-t-2-1_AttnS1-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " UpSamp2D-1_Mask_AttnS1-1 (UpSa  (None, 16, 16, 128)  0          ['ResUnit_L11_Mid-2r-2-2_Mask_Att\n",
      " mpling2D)                                                       nS1-1[0][0]']                    \n",
      "                                                                                                  \n",
      " ResUnit_L9_SkipConn-1_Mask_Att  (None, 16, 16, 128)  4096       ['ResUnit_L8_SkipConn-1_Mask_Attn\n",
      " nS1-1 (Conv2D)                                                  S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L10_SkipConn-1_Mask_At  (None, 16, 16, 128)  16384      ['ResUnit_L2_SkipConn-1_Mask_Attn\n",
      " tnS1-1 (Conv2D)                                                 S1-1[0][0]']                     \n",
      "                                                                                                  \n",
      " ResUnit_L7_Trunk-t-2-1_AttnS1-  (None, 32, 32, 32)  128         ['ResUnit_L6_Trunk-t-2-1_AttnS1-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " Add_L1_AttnS1-1 (Add)          (None, 16, 16, 128)  0           ['ResUnit_L11_DownSamp-r-1-1_Mask\n",
      "                                                                 _AttnS1-1[0][0]',                \n",
      "                                                                  'UpSamp2D-1_Mask_AttnS1-1[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " ResUnit_L11_SkipConn-1_Mask_At  (None, 16, 16, 128)  0          ['ResUnit_L9_SkipConn-1_Mask_Attn\n",
      " tnS1-1 (Add)                                                    S1-1[0][0]',                     \n",
      "                                                                  'ResUnit_L10_SkipConn-1_Mask_Att\n",
      "                                                                 nS1-1[0][0]']                    \n",
      "                                                                                                  \n",
      " ResUnit_L8_Trunk-t-2-1_AttnS1-  (None, 32, 32, 32)  0           ['ResUnit_L7_Trunk-t-2-1_AttnS1-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " Add_L2_AttnS1-1 (Add)          (None, 16, 16, 128)  0           ['Add_L1_AttnS1-1[0][0]',        \n",
      "                                                                  'ResUnit_L11_SkipConn-1_Mask_Att\n",
      "                                                                 nS1-1[0][0]']                    \n",
      "                                                                                                  \n",
      " ResUnit_L9_Trunk-t-2-1_AttnS1-  (None, 32, 32, 128)  4096       ['ResUnit_L8_Trunk-t-2-1_AttnS1-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_Trunk-t-2-1_AttnS1  (None, 32, 32, 128)  16384      ['ResUnit_L2_Trunk-t-2-1_AttnS1-1\n",
      " -1 (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L1_UpSamp-r-1-1_Mask_A  (None, 16, 16, 128)  512        ['Add_L2_AttnS1-1[0][0]']        \n",
      " ttnS1-1 (BatchNormalization)                                                                     \n",
      "                                                                                                  \n",
      " ResUnit_L11_Trunk-t-2-1_AttnS1  (None, 32, 32, 128)  0          ['ResUnit_L9_Trunk-t-2-1_AttnS1-1\n",
      " -1 (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_Trunk-t-2-1_AttnS1-\n",
      "                                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L2_UpSamp-r-1-1_Mask_A  (None, 16, 16, 128)  0          ['ResUnit_L1_UpSamp-r-1-1_Mask_At\n",
      " ttnS1-1 (Activation)                                            tnS1-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L1_Trunk-t-2-2_AttnS1-  (None, 32, 32, 128)  512        ['ResUnit_L11_Trunk-t-2-1_AttnS1-\n",
      " 1 (BatchNormalization)                                          1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L3_UpSamp-r-1-1_Mask_A  (None, 16, 16, 32)  4096        ['ResUnit_L2_UpSamp-r-1-1_Mask_At\n",
      " ttnS1-1 (Conv2D)                                                tnS1-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L2_Trunk-t-2-2_AttnS1-  (None, 32, 32, 128)  0          ['ResUnit_L1_Trunk-t-2-2_AttnS1-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L4_UpSamp-r-1-1_Mask_A  (None, 16, 16, 32)  128         ['ResUnit_L3_UpSamp-r-1-1_Mask_At\n",
      " ttnS1-1 (BatchNormalization)                                    tnS1-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L3_Trunk-t-2-2_AttnS1-  (None, 32, 32, 32)  4096        ['ResUnit_L2_Trunk-t-2-2_AttnS1-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L5_UpSamp-r-1-1_Mask_A  (None, 16, 16, 32)  0           ['ResUnit_L4_UpSamp-r-1-1_Mask_At\n",
      " ttnS1-1 (Activation)                                            tnS1-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L4_Trunk-t-2-2_AttnS1-  (None, 32, 32, 32)  128         ['ResUnit_L3_Trunk-t-2-2_AttnS1-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L6_UpSamp-r-1-1_Mask_A  (None, 16, 16, 32)  9216        ['ResUnit_L5_UpSamp-r-1-1_Mask_At\n",
      " ttnS1-1 (Conv2D)                                                tnS1-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L5_Trunk-t-2-2_AttnS1-  (None, 32, 32, 32)  0           ['ResUnit_L4_Trunk-t-2-2_AttnS1-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L7_UpSamp-r-1-1_Mask_A  (None, 16, 16, 32)  128         ['ResUnit_L6_UpSamp-r-1-1_Mask_At\n",
      " ttnS1-1 (BatchNormalization)                                    tnS1-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L6_Trunk-t-2-2_AttnS1-  (None, 32, 32, 32)  9216        ['ResUnit_L5_Trunk-t-2-2_AttnS1-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L8_UpSamp-r-1-1_Mask_A  (None, 16, 16, 32)  0           ['ResUnit_L7_UpSamp-r-1-1_Mask_At\n",
      " ttnS1-1 (Activation)                                            tnS1-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L7_Trunk-t-2-2_AttnS1-  (None, 32, 32, 32)  128         ['ResUnit_L6_Trunk-t-2-2_AttnS1-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L9_UpSamp-r-1-1_Mask_A  (None, 16, 16, 128)  4096       ['ResUnit_L8_UpSamp-r-1-1_Mask_At\n",
      " ttnS1-1 (Conv2D)                                                tnS1-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L10_UpSamp-r-1-1_Mask_  (None, 16, 16, 128)  16384      ['ResUnit_L2_UpSamp-r-1-1_Mask_At\n",
      " AttnS1-1 (Conv2D)                                               tnS1-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L8_Trunk-t-2-2_AttnS1-  (None, 32, 32, 32)  0           ['ResUnit_L7_Trunk-t-2-2_AttnS1-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L11_UpSamp-r-1-1_Mask_  (None, 16, 16, 128)  0          ['ResUnit_L9_UpSamp-r-1-1_Mask_At\n",
      " AttnS1-1 (Add)                                                  tnS1-1[0][0]',                   \n",
      "                                                                  'ResUnit_L10_UpSamp-r-1-1_Mask_A\n",
      "                                                                 ttnS1-1[0][0]']                  \n",
      "                                                                                                  \n",
      " ResUnit_L9_Trunk-t-2-2_AttnS1-  (None, 32, 32, 128)  4096       ['ResUnit_L8_Trunk-t-2-2_AttnS1-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_Trunk-t-2-2_AttnS1  (None, 32, 32, 128)  16384      ['ResUnit_L2_Trunk-t-2-2_AttnS1-1\n",
      " -1 (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " UpSamp2D-2_Mask_AttnS1-1 (UpSa  (None, 32, 32, 128)  0          ['ResUnit_L11_UpSamp-r-1-1_Mask_A\n",
      " mpling2D)                                                       ttnS1-1[0][0]']                  \n",
      "                                                                                                  \n",
      " ResUnit_L11_Trunk-t-2-2_AttnS1  (None, 32, 32, 128)  0          ['ResUnit_L9_Trunk-t-2-2_AttnS1-1\n",
      " -1 (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_Trunk-t-2-2_AttnS1-\n",
      "                                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " Add_L3_AttnS1-1 (Add)          (None, 32, 32, 128)  0           ['UpSamp2D-2_Mask_AttnS1-1[0][0]'\n",
      "                                                                 , 'ResUnit_L11_Trunk-t-2-2_AttnS1\n",
      "                                                                 -1[0][0]']                       \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L1_Attn_S1-1 (Bat  (None, 32, 32, 128)  512        ['Add_L3_AttnS1-1[0][0]']        \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L2_Attn_S1-1 (Act  (None, 32, 32, 128)  0          ['SpcConv_Mask_L1_Attn_S1-1[0][0]\n",
      " ivation)                                                        ']                               \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L3_Attn_S1-1 (Con  (None, 32, 32, 128)  16384      ['SpcConv_Mask_L2_Attn_S1-1[0][0]\n",
      " v2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L4_Attn_S1-1 (Bat  (None, 32, 32, 128)  512        ['SpcConv_Mask_L3_Attn_S1-1[0][0]\n",
      " chNormalization)                                                ']                               \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L5_Attn_S1-1 (Act  (None, 32, 32, 128)  0          ['SpcConv_Mask_L4_Attn_S1-1[0][0]\n",
      " ivation)                                                        ',                               \n",
      "                                                                  'SpcConv_Mask_L5_Attn_S1-1[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L7_Attn_S1-1 (Act  (None, 32, 32, 128)  0          ['SpcConv_Mask_L5_Attn_S1-1[1][0]\n",
      " ivation)                                                        ']                               \n",
      "                                                                                                  \n",
      " Mult_L1_AttnS1-1 (Multiply)    (None, 32, 32, 128)  0           ['SpcConv_Mask_L7_Attn_S1-1[0][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'ResUnit_L11_Trunk-t-2-2_AttnS1-\n",
      "                                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " Add_L4_AttnS1-1 (Add)          (None, 32, 32, 128)  0           ['Mult_L1_AttnS1-1[0][0]',       \n",
      "                                                                  'ResUnit_L11_Trunk-t-2-2_AttnS1-\n",
      "                                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L1_Output-p-1-1_AttnS1  (None, 32, 32, 128)  512        ['Add_L4_AttnS1-1[0][0]']        \n",
      " -1 (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " ResUnit_L2_Output-p-1-1_AttnS1  (None, 32, 32, 128)  0          ['ResUnit_L1_Output-p-1-1_AttnS1-\n",
      " -1 (Activation)                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L3_Output-p-1-1_AttnS1  (None, 32, 32, 32)  4096        ['ResUnit_L2_Output-p-1-1_AttnS1-\n",
      " -1 (Conv2D)                                                     1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L4_Output-p-1-1_AttnS1  (None, 32, 32, 32)  128         ['ResUnit_L3_Output-p-1-1_AttnS1-\n",
      " -1 (BatchNormalization)                                         1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L5_Output-p-1-1_AttnS1  (None, 32, 32, 32)  0           ['ResUnit_L4_Output-p-1-1_AttnS1-\n",
      " -1 (Activation)                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L6_Output-p-1-1_AttnS1  (None, 32, 32, 32)  9216        ['ResUnit_L5_Output-p-1-1_AttnS1-\n",
      " -1 (Conv2D)                                                     1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L7_Output-p-1-1_AttnS1  (None, 32, 32, 32)  128         ['ResUnit_L6_Output-p-1-1_AttnS1-\n",
      " -1 (BatchNormalization)                                         1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L8_Output-p-1-1_AttnS1  (None, 32, 32, 32)  0           ['ResUnit_L7_Output-p-1-1_AttnS1-\n",
      " -1 (Activation)                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L9_Output-p-1-1_AttnS1  (None, 32, 32, 128)  4096       ['ResUnit_L8_Output-p-1-1_AttnS1-\n",
      " -1 (Conv2D)                                                     1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L10_Output-p-1-1_AttnS  (None, 32, 32, 128)  16384      ['ResUnit_L2_Output-p-1-1_AttnS1-\n",
      " 1-1 (Conv2D)                                                    1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L11_Output-p-1-1_AttnS  (None, 32, 32, 128)  0          ['ResUnit_L9_Output-p-1-1_AttnS1-\n",
      " 1-1 (Add)                                                       1[0][0]',                        \n",
      "                                                                  'ResUnit_L10_Output-p-1-1_AttnS1\n",
      "                                                                 -1[0][0]']                       \n",
      "                                                                                                  \n",
      " ResUnit_L1_NotAttnModule_2_DS   (None, 32, 32, 128)  512        ['ResUnit_L11_Output-p-1-1_AttnS1\n",
      " (BatchNormalization)                                            -1[0][0]']                       \n",
      "                                                                                                  \n",
      " ResUnit_L2_NotAttnModule_2_DS   (None, 32, 32, 128)  0          ['ResUnit_L1_NotAttnModule_2_DS[0\n",
      " (Activation)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L3_NotAttnModule_2_DS   (None, 32, 32, 64)  8192        ['ResUnit_L2_NotAttnModule_2_DS[0\n",
      " (Conv2D)                                                        ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L4_NotAttnModule_2_DS   (None, 32, 32, 64)  256         ['ResUnit_L3_NotAttnModule_2_DS[0\n",
      " (BatchNormalization)                                            ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L5_NotAttnModule_2_DS   (None, 32, 32, 64)  0           ['ResUnit_L4_NotAttnModule_2_DS[0\n",
      " (Activation)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L6_NotAttnModule_2_DS   (None, 16, 16, 64)  36864       ['ResUnit_L5_NotAttnModule_2_DS[0\n",
      " (Conv2D)                                                        ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L7_NotAttnModule_2_DS   (None, 16, 16, 64)  256         ['ResUnit_L6_NotAttnModule_2_DS[0\n",
      " (BatchNormalization)                                            ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L8_NotAttnModule_2_DS   (None, 16, 16, 64)  0           ['ResUnit_L7_NotAttnModule_2_DS[0\n",
      " (Activation)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L9_NotAttnModule_2_DS   (None, 16, 16, 256)  16384      ['ResUnit_L8_NotAttnModule_2_DS[0\n",
      " (Conv2D)                                                        ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L10_NotAttnModule_2_DS  (None, 16, 16, 256)  32768      ['ResUnit_L2_NotAttnModule_2_DS[0\n",
      "  (Conv2D)                                                       ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L11_NotAttnModule_2_DS  (None, 16, 16, 256)  0          ['ResUnit_L9_NotAttnModule_2_DS[0\n",
      "  (Add)                                                          ][0]',                           \n",
      "                                                                  'ResUnit_L10_NotAttnModule_2_DS[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " ResUnit_L1_Input-p-1-1_AttnS2-  (None, 16, 16, 256)  1024       ['ResUnit_L11_NotAttnModule_2_DS[\n",
      " 1 (BatchNormalization)                                          0][0]',                          \n",
      "                                                                  'ResUnit_L11_Output-p-1-1_AttnS2\n",
      "                                                                 -1[0][0]']                       \n",
      "                                                                                                  \n",
      " ResUnit_L2_Input-p-1-1_AttnS2-  (None, 16, 16, 256)  0          ['ResUnit_L1_Input-p-1-1_AttnS2-1\n",
      " 1 (Activation)                                                  [0][0]',                         \n",
      "                                                                  'ResUnit_L1_Input-p-1-1_AttnS2-1\n",
      "                                                                 [1][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L3_Input-p-1-1_AttnS2-  (None, 16, 16, 64)  16384       ['ResUnit_L2_Input-p-1-1_AttnS2-1\n",
      " 1 (Conv2D)                                                      [0][0]',                         \n",
      "                                                                  'ResUnit_L2_Input-p-1-1_AttnS2-1\n",
      "                                                                 [1][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L4_Input-p-1-1_AttnS2-  (None, 16, 16, 64)  256         ['ResUnit_L3_Input-p-1-1_AttnS2-1\n",
      " 1 (BatchNormalization)                                          [0][0]',                         \n",
      "                                                                  'ResUnit_L3_Input-p-1-1_AttnS2-1\n",
      "                                                                 [1][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L5_Input-p-1-1_AttnS2-  (None, 16, 16, 64)  0           ['ResUnit_L4_Input-p-1-1_AttnS2-1\n",
      " 1 (Activation)                                                  [0][0]',                         \n",
      "                                                                  'ResUnit_L4_Input-p-1-1_AttnS2-1\n",
      "                                                                 [1][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L6_Input-p-1-1_AttnS2-  (None, 16, 16, 64)  36864       ['ResUnit_L5_Input-p-1-1_AttnS2-1\n",
      " 1 (Conv2D)                                                      [0][0]',                         \n",
      "                                                                  'ResUnit_L5_Input-p-1-1_AttnS2-1\n",
      "                                                                 [1][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L7_Input-p-1-1_AttnS2-  (None, 16, 16, 64)  256         ['ResUnit_L6_Input-p-1-1_AttnS2-1\n",
      " 1 (BatchNormalization)                                          [0][0]',                         \n",
      "                                                                  'ResUnit_L6_Input-p-1-1_AttnS2-1\n",
      "                                                                 [1][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L8_Input-p-1-1_AttnS2-  (None, 16, 16, 64)  0           ['ResUnit_L7_Input-p-1-1_AttnS2-1\n",
      " 1 (Activation)                                                  [0][0]',                         \n",
      "                                                                  'ResUnit_L7_Input-p-1-1_AttnS2-1\n",
      "                                                                 [1][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L9_Input-p-1-1_AttnS2-  (None, 16, 16, 256)  16384      ['ResUnit_L8_Input-p-1-1_AttnS2-1\n",
      " 1 (Conv2D)                                                      [0][0]',                         \n",
      "                                                                  'ResUnit_L8_Input-p-1-1_AttnS2-1\n",
      "                                                                 [1][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_Input-p-1-1_AttnS2  (None, 16, 16, 256)  65536      ['ResUnit_L2_Input-p-1-1_AttnS2-1\n",
      " -1 (Conv2D)                                                     [0][0]',                         \n",
      "                                                                  'ResUnit_L2_Input-p-1-1_AttnS2-1\n",
      "                                                                 [1][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L11_Input-p-1-1_AttnS2  (None, 16, 16, 256)  0          ['ResUnit_L9_Input-p-1-1_AttnS2-1\n",
      " -1 (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_Input-p-1-1_AttnS2-\n",
      "                                                                 1[0][0]',                        \n",
      "                                                                  'ResUnit_L9_Input-p-1-1_AttnS2-1\n",
      "                                                                 [1][0]',                         \n",
      "                                                                  'ResUnit_L10_Input-p-1-1_AttnS2-\n",
      "                                                                 1[1][0]']                        \n",
      "                                                                                                  \n",
      " MaxPool_DownSamp-1_Mask_AttnS2  (None, 8, 8, 256)   0           ['ResUnit_L11_Input-p-1-1_AttnS2-\n",
      " -1 (MaxPooling2D)                                               1[0][0]',                        \n",
      "                                                                  'ResUnit_L11_Input-p-1-1_AttnS2-\n",
      "                                                                 1[1][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L1_UpSamp-r-1-1_Mask_A  (None, 8, 8, 256)   1024        ['MaxPool_DownSamp-1_Mask_AttnS2-\n",
      " ttnS2-1 (BatchNormalization)                                    1[0][0]',                        \n",
      "                                                                  'MaxPool_DownSamp-1_Mask_AttnS2-\n",
      "                                                                 1[1][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L2_UpSamp-r-1-1_Mask_A  (None, 8, 8, 256)   0           ['ResUnit_L1_UpSamp-r-1-1_Mask_At\n",
      " ttnS2-1 (Activation)                                            tnS2-1[0][0]',                   \n",
      "                                                                  'ResUnit_L1_UpSamp-r-1-1_Mask_At\n",
      "                                                                 tnS2-1[1][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L1_Trunk-t-2-1_AttnS2-  (None, 16, 16, 256)  1024       ['ResUnit_L11_Input-p-1-1_AttnS2-\n",
      " 1 (BatchNormalization)                                          1[0][0]',                        \n",
      "                                                                  'ResUnit_L11_Input-p-1-1_AttnS2-\n",
      "                                                                 1[1][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L3_UpSamp-r-1-1_Mask_A  (None, 8, 8, 64)    16384       ['ResUnit_L2_UpSamp-r-1-1_Mask_At\n",
      " ttnS2-1 (Conv2D)                                                tnS2-1[0][0]',                   \n",
      "                                                                  'ResUnit_L2_UpSamp-r-1-1_Mask_At\n",
      "                                                                 tnS2-1[1][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L2_Trunk-t-2-1_AttnS2-  (None, 16, 16, 256)  0          ['ResUnit_L1_Trunk-t-2-1_AttnS2-1\n",
      " 1 (Activation)                                                  [0][0]',                         \n",
      "                                                                  'ResUnit_L1_Trunk-t-2-1_AttnS2-1\n",
      "                                                                 [1][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L4_UpSamp-r-1-1_Mask_A  (None, 8, 8, 64)    256         ['ResUnit_L3_UpSamp-r-1-1_Mask_At\n",
      " ttnS2-1 (BatchNormalization)                                    tnS2-1[0][0]',                   \n",
      "                                                                  'ResUnit_L3_UpSamp-r-1-1_Mask_At\n",
      "                                                                 tnS2-1[1][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L3_Trunk-t-2-1_AttnS2-  (None, 16, 16, 64)  16384       ['ResUnit_L2_Trunk-t-2-1_AttnS2-1\n",
      " 1 (Conv2D)                                                      [0][0]',                         \n",
      "                                                                  'ResUnit_L2_Trunk-t-2-1_AttnS2-1\n",
      "                                                                 [1][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L5_UpSamp-r-1-1_Mask_A  (None, 8, 8, 64)    0           ['ResUnit_L4_UpSamp-r-1-1_Mask_At\n",
      " ttnS2-1 (Activation)                                            tnS2-1[0][0]',                   \n",
      "                                                                  'ResUnit_L4_UpSamp-r-1-1_Mask_At\n",
      "                                                                 tnS2-1[1][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L4_Trunk-t-2-1_AttnS2-  (None, 16, 16, 64)  256         ['ResUnit_L3_Trunk-t-2-1_AttnS2-1\n",
      " 1 (BatchNormalization)                                          [0][0]',                         \n",
      "                                                                  'ResUnit_L3_Trunk-t-2-1_AttnS2-1\n",
      "                                                                 [1][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L6_UpSamp-r-1-1_Mask_A  (None, 8, 8, 64)    36864       ['ResUnit_L5_UpSamp-r-1-1_Mask_At\n",
      " ttnS2-1 (Conv2D)                                                tnS2-1[0][0]',                   \n",
      "                                                                  'ResUnit_L5_UpSamp-r-1-1_Mask_At\n",
      "                                                                 tnS2-1[1][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L5_Trunk-t-2-1_AttnS2-  (None, 16, 16, 64)  0           ['ResUnit_L4_Trunk-t-2-1_AttnS2-1\n",
      " 1 (Activation)                                                  [0][0]',                         \n",
      "                                                                  'ResUnit_L4_Trunk-t-2-1_AttnS2-1\n",
      "                                                                 [1][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L7_UpSamp-r-1-1_Mask_A  (None, 8, 8, 64)    256         ['ResUnit_L6_UpSamp-r-1-1_Mask_At\n",
      " ttnS2-1 (BatchNormalization)                                    tnS2-1[0][0]',                   \n",
      "                                                                  'ResUnit_L6_UpSamp-r-1-1_Mask_At\n",
      "                                                                 tnS2-1[1][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L6_Trunk-t-2-1_AttnS2-  (None, 16, 16, 64)  36864       ['ResUnit_L5_Trunk-t-2-1_AttnS2-1\n",
      " 1 (Conv2D)                                                      [0][0]',                         \n",
      "                                                                  'ResUnit_L5_Trunk-t-2-1_AttnS2-1\n",
      "                                                                 [1][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L8_UpSamp-r-1-1_Mask_A  (None, 8, 8, 64)    0           ['ResUnit_L7_UpSamp-r-1-1_Mask_At\n",
      " ttnS2-1 (Activation)                                            tnS2-1[0][0]',                   \n",
      "                                                                  'ResUnit_L7_UpSamp-r-1-1_Mask_At\n",
      "                                                                 tnS2-1[1][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L7_Trunk-t-2-1_AttnS2-  (None, 16, 16, 64)  256         ['ResUnit_L6_Trunk-t-2-1_AttnS2-1\n",
      " 1 (BatchNormalization)                                          [0][0]',                         \n",
      "                                                                  'ResUnit_L6_Trunk-t-2-1_AttnS2-1\n",
      "                                                                 [1][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L9_UpSamp-r-1-1_Mask_A  (None, 8, 8, 256)   16384       ['ResUnit_L8_UpSamp-r-1-1_Mask_At\n",
      " ttnS2-1 (Conv2D)                                                tnS2-1[0][0]',                   \n",
      "                                                                  'ResUnit_L8_UpSamp-r-1-1_Mask_At\n",
      "                                                                 tnS2-1[1][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L10_UpSamp-r-1-1_Mask_  (None, 8, 8, 256)   65536       ['ResUnit_L2_UpSamp-r-1-1_Mask_At\n",
      " AttnS2-1 (Conv2D)                                               tnS2-1[0][0]',                   \n",
      "                                                                  'ResUnit_L2_UpSamp-r-1-1_Mask_At\n",
      "                                                                 tnS2-1[1][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L8_Trunk-t-2-1_AttnS2-  (None, 16, 16, 64)  0           ['ResUnit_L7_Trunk-t-2-1_AttnS2-1\n",
      " 1 (Activation)                                                  [0][0]',                         \n",
      "                                                                  'ResUnit_L7_Trunk-t-2-1_AttnS2-1\n",
      "                                                                 [1][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L11_UpSamp-r-1-1_Mask_  (None, 8, 8, 256)   0           ['ResUnit_L9_UpSamp-r-1-1_Mask_At\n",
      " AttnS2-1 (Add)                                                  tnS2-1[0][0]',                   \n",
      "                                                                  'ResUnit_L10_UpSamp-r-1-1_Mask_A\n",
      "                                                                 ttnS2-1[0][0]',                  \n",
      "                                                                  'ResUnit_L9_UpSamp-r-1-1_Mask_At\n",
      "                                                                 tnS2-1[1][0]',                   \n",
      "                                                                  'ResUnit_L10_UpSamp-r-1-1_Mask_A\n",
      "                                                                 ttnS2-1[1][0]']                  \n",
      "                                                                                                  \n",
      " ResUnit_L9_Trunk-t-2-1_AttnS2-  (None, 16, 16, 256)  16384      ['ResUnit_L8_Trunk-t-2-1_AttnS2-1\n",
      " 1 (Conv2D)                                                      [0][0]',                         \n",
      "                                                                  'ResUnit_L8_Trunk-t-2-1_AttnS2-1\n",
      "                                                                 [1][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_Trunk-t-2-1_AttnS2  (None, 16, 16, 256)  65536      ['ResUnit_L2_Trunk-t-2-1_AttnS2-1\n",
      " -1 (Conv2D)                                                     [0][0]',                         \n",
      "                                                                  'ResUnit_L2_Trunk-t-2-1_AttnS2-1\n",
      "                                                                 [1][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L1_UpSamp-r-1-2_Mask_A  (None, 8, 8, 256)   1024        ['ResUnit_L11_UpSamp-r-1-1_Mask_A\n",
      " ttnS2-1 (BatchNormalization)                                    ttnS2-1[0][0]',                  \n",
      "                                                                  'ResUnit_L11_UpSamp-r-1-1_Mask_A\n",
      "                                                                 ttnS2-1[1][0]']                  \n",
      "                                                                                                  \n",
      " ResUnit_L11_Trunk-t-2-1_AttnS2  (None, 16, 16, 256)  0          ['ResUnit_L9_Trunk-t-2-1_AttnS2-1\n",
      " -1 (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_Trunk-t-2-1_AttnS2-\n",
      "                                                                 1[0][0]',                        \n",
      "                                                                  'ResUnit_L9_Trunk-t-2-1_AttnS2-1\n",
      "                                                                 [1][0]',                         \n",
      "                                                                  'ResUnit_L10_Trunk-t-2-1_AttnS2-\n",
      "                                                                 1[1][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L2_UpSamp-r-1-2_Mask_A  (None, 8, 8, 256)   0           ['ResUnit_L1_UpSamp-r-1-2_Mask_At\n",
      " ttnS2-1 (Activation)                                            tnS2-1[0][0]',                   \n",
      "                                                                  'ResUnit_L1_UpSamp-r-1-2_Mask_At\n",
      "                                                                 tnS2-1[1][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L1_Trunk-t-2-2_AttnS2-  (None, 16, 16, 256)  1024       ['ResUnit_L11_Trunk-t-2-1_AttnS2-\n",
      " 1 (BatchNormalization)                                          1[0][0]',                        \n",
      "                                                                  'ResUnit_L11_Trunk-t-2-1_AttnS2-\n",
      "                                                                 1[1][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L3_UpSamp-r-1-2_Mask_A  (None, 8, 8, 64)    16384       ['ResUnit_L2_UpSamp-r-1-2_Mask_At\n",
      " ttnS2-1 (Conv2D)                                                tnS2-1[0][0]',                   \n",
      "                                                                  'ResUnit_L2_UpSamp-r-1-2_Mask_At\n",
      "                                                                 tnS2-1[1][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L2_Trunk-t-2-2_AttnS2-  (None, 16, 16, 256)  0          ['ResUnit_L1_Trunk-t-2-2_AttnS2-1\n",
      " 1 (Activation)                                                  [0][0]',                         \n",
      "                                                                  'ResUnit_L1_Trunk-t-2-2_AttnS2-1\n",
      "                                                                 [1][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L4_UpSamp-r-1-2_Mask_A  (None, 8, 8, 64)    256         ['ResUnit_L3_UpSamp-r-1-2_Mask_At\n",
      " ttnS2-1 (BatchNormalization)                                    tnS2-1[0][0]',                   \n",
      "                                                                  'ResUnit_L3_UpSamp-r-1-2_Mask_At\n",
      "                                                                 tnS2-1[1][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L3_Trunk-t-2-2_AttnS2-  (None, 16, 16, 64)  16384       ['ResUnit_L2_Trunk-t-2-2_AttnS2-1\n",
      " 1 (Conv2D)                                                      [0][0]',                         \n",
      "                                                                  'ResUnit_L2_Trunk-t-2-2_AttnS2-1\n",
      "                                                                 [1][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L5_UpSamp-r-1-2_Mask_A  (None, 8, 8, 64)    0           ['ResUnit_L4_UpSamp-r-1-2_Mask_At\n",
      " ttnS2-1 (Activation)                                            tnS2-1[0][0]',                   \n",
      "                                                                  'ResUnit_L4_UpSamp-r-1-2_Mask_At\n",
      "                                                                 tnS2-1[1][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L4_Trunk-t-2-2_AttnS2-  (None, 16, 16, 64)  256         ['ResUnit_L3_Trunk-t-2-2_AttnS2-1\n",
      " 1 (BatchNormalization)                                          [0][0]',                         \n",
      "                                                                  'ResUnit_L3_Trunk-t-2-2_AttnS2-1\n",
      "                                                                 [1][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L6_UpSamp-r-1-2_Mask_A  (None, 8, 8, 64)    36864       ['ResUnit_L5_UpSamp-r-1-2_Mask_At\n",
      " ttnS2-1 (Conv2D)                                                tnS2-1[0][0]',                   \n",
      "                                                                  'ResUnit_L5_UpSamp-r-1-2_Mask_At\n",
      "                                                                 tnS2-1[1][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L5_Trunk-t-2-2_AttnS2-  (None, 16, 16, 64)  0           ['ResUnit_L4_Trunk-t-2-2_AttnS2-1\n",
      " 1 (Activation)                                                  [0][0]',                         \n",
      "                                                                  'ResUnit_L4_Trunk-t-2-2_AttnS2-1\n",
      "                                                                 [1][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L7_UpSamp-r-1-2_Mask_A  (None, 8, 8, 64)    256         ['ResUnit_L6_UpSamp-r-1-2_Mask_At\n",
      " ttnS2-1 (BatchNormalization)                                    tnS2-1[0][0]',                   \n",
      "                                                                  'ResUnit_L6_UpSamp-r-1-2_Mask_At\n",
      "                                                                 tnS2-1[1][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L6_Trunk-t-2-2_AttnS2-  (None, 16, 16, 64)  36864       ['ResUnit_L5_Trunk-t-2-2_AttnS2-1\n",
      " 1 (Conv2D)                                                      [0][0]',                         \n",
      "                                                                  'ResUnit_L5_Trunk-t-2-2_AttnS2-1\n",
      "                                                                 [1][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L8_UpSamp-r-1-2_Mask_A  (None, 8, 8, 64)    0           ['ResUnit_L7_UpSamp-r-1-2_Mask_At\n",
      " ttnS2-1 (Activation)                                            tnS2-1[0][0]',                   \n",
      "                                                                  'ResUnit_L7_UpSamp-r-1-2_Mask_At\n",
      "                                                                 tnS2-1[1][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L7_Trunk-t-2-2_AttnS2-  (None, 16, 16, 64)  256         ['ResUnit_L6_Trunk-t-2-2_AttnS2-1\n",
      " 1 (BatchNormalization)                                          [0][0]',                         \n",
      "                                                                  'ResUnit_L6_Trunk-t-2-2_AttnS2-1\n",
      "                                                                 [1][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L9_UpSamp-r-1-2_Mask_A  (None, 8, 8, 256)   16384       ['ResUnit_L8_UpSamp-r-1-2_Mask_At\n",
      " ttnS2-1 (Conv2D)                                                tnS2-1[0][0]',                   \n",
      "                                                                  'ResUnit_L8_UpSamp-r-1-2_Mask_At\n",
      "                                                                 tnS2-1[1][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L10_UpSamp-r-1-2_Mask_  (None, 8, 8, 256)   65536       ['ResUnit_L2_UpSamp-r-1-2_Mask_At\n",
      " AttnS2-1 (Conv2D)                                               tnS2-1[0][0]',                   \n",
      "                                                                  'ResUnit_L2_UpSamp-r-1-2_Mask_At\n",
      "                                                                 tnS2-1[1][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L8_Trunk-t-2-2_AttnS2-  (None, 16, 16, 64)  0           ['ResUnit_L7_Trunk-t-2-2_AttnS2-1\n",
      " 1 (Activation)                                                  [0][0]',                         \n",
      "                                                                  'ResUnit_L7_Trunk-t-2-2_AttnS2-1\n",
      "                                                                 [1][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L11_UpSamp-r-1-2_Mask_  (None, 8, 8, 256)   0           ['ResUnit_L9_UpSamp-r-1-2_Mask_At\n",
      " AttnS2-1 (Add)                                                  tnS2-1[0][0]',                   \n",
      "                                                                  'ResUnit_L10_UpSamp-r-1-2_Mask_A\n",
      "                                                                 ttnS2-1[0][0]',                  \n",
      "                                                                  'ResUnit_L9_UpSamp-r-1-2_Mask_At\n",
      "                                                                 tnS2-1[1][0]',                   \n",
      "                                                                  'ResUnit_L10_UpSamp-r-1-2_Mask_A\n",
      "                                                                 ttnS2-1[1][0]']                  \n",
      "                                                                                                  \n",
      " ResUnit_L9_Trunk-t-2-2_AttnS2-  (None, 16, 16, 256)  16384      ['ResUnit_L8_Trunk-t-2-2_AttnS2-1\n",
      " 1 (Conv2D)                                                      [0][0]',                         \n",
      "                                                                  'ResUnit_L8_Trunk-t-2-2_AttnS2-1\n",
      "                                                                 [1][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_Trunk-t-2-2_AttnS2  (None, 16, 16, 256)  65536      ['ResUnit_L2_Trunk-t-2-2_AttnS2-1\n",
      " -1 (Conv2D)                                                     [0][0]',                         \n",
      "                                                                  'ResUnit_L2_Trunk-t-2-2_AttnS2-1\n",
      "                                                                 [1][0]']                         \n",
      "                                                                                                  \n",
      " UpSamp2D-1_Mask_AttnS2-1 (UpSa  (None, 16, 16, 256)  0          ['ResUnit_L11_UpSamp-r-1-2_Mask_A\n",
      " mpling2D)                                                       ttnS2-1[0][0]',                  \n",
      "                                                                  'ResUnit_L11_UpSamp-r-1-2_Mask_A\n",
      "                                                                 ttnS2-1[1][0]']                  \n",
      "                                                                                                  \n",
      " ResUnit_L11_Trunk-t-2-2_AttnS2  (None, 16, 16, 256)  0          ['ResUnit_L9_Trunk-t-2-2_AttnS2-1\n",
      " -1 (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_Trunk-t-2-2_AttnS2-\n",
      "                                                                 1[0][0]',                        \n",
      "                                                                  'ResUnit_L9_Trunk-t-2-2_AttnS2-1\n",
      "                                                                 [1][0]',                         \n",
      "                                                                  'ResUnit_L10_Trunk-t-2-2_AttnS2-\n",
      "                                                                 1[1][0]']                        \n",
      "                                                                                                  \n",
      " Add_L1_AttnS2-1 (Add)          (None, 16, 16, 256)  0           ['UpSamp2D-1_Mask_AttnS2-1[0][0]'\n",
      "                                                                 , 'ResUnit_L11_Trunk-t-2-2_AttnS2\n",
      "                                                                 -1[0][0]',                       \n",
      "                                                                  'UpSamp2D-1_Mask_AttnS2-1[1][0]'\n",
      "                                                                 , 'ResUnit_L11_Trunk-t-2-2_AttnS2\n",
      "                                                                 -1[1][0]']                       \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L1_Attn_S2-1 (Bat  (None, 16, 16, 256)  1024       ['Add_L1_AttnS2-1[0][0]',        \n",
      " chNormalization)                                                 'Add_L1_AttnS2-1[1][0]']        \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L2_Attn_S2-1 (Act  (None, 16, 16, 256)  0          ['SpcConv_Mask_L1_Attn_S2-1[0][0]\n",
      " ivation)                                                        ',                               \n",
      "                                                                  'SpcConv_Mask_L1_Attn_S2-1[1][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L3_Attn_S2-1 (Con  (None, 16, 16, 256)  65536      ['SpcConv_Mask_L2_Attn_S2-1[0][0]\n",
      " v2D)                                                            ',                               \n",
      "                                                                  'SpcConv_Mask_L2_Attn_S2-1[1][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L4_Attn_S2-1 (Bat  (None, 16, 16, 256)  1024       ['SpcConv_Mask_L3_Attn_S2-1[0][0]\n",
      " chNormalization)                                                ',                               \n",
      "                                                                  'SpcConv_Mask_L3_Attn_S2-1[1][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L5_Attn_S2-1 (Act  (None, 16, 16, 256)  0          ['SpcConv_Mask_L4_Attn_S2-1[0][0]\n",
      " ivation)                                                        ',                               \n",
      "                                                                  'SpcConv_Mask_L5_Attn_S2-1[0][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'SpcConv_Mask_L4_Attn_S2-1[1][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'SpcConv_Mask_L5_Attn_S2-1[2][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L7_Attn_S2-1 (Act  (None, 16, 16, 256)  0          ['SpcConv_Mask_L5_Attn_S2-1[1][0]\n",
      " ivation)                                                        ',                               \n",
      "                                                                  'SpcConv_Mask_L5_Attn_S2-1[3][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " Mult_L1_AttnS2-1 (Multiply)    (None, 16, 16, 256)  0           ['SpcConv_Mask_L7_Attn_S2-1[0][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'ResUnit_L11_Trunk-t-2-2_AttnS2-\n",
      "                                                                 1[0][0]',                        \n",
      "                                                                  'SpcConv_Mask_L7_Attn_S2-1[1][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'ResUnit_L11_Trunk-t-2-2_AttnS2-\n",
      "                                                                 1[1][0]']                        \n",
      "                                                                                                  \n",
      " Add_L2_AttnS2-1 (Add)          (None, 16, 16, 256)  0           ['Mult_L1_AttnS2-1[0][0]',       \n",
      "                                                                  'ResUnit_L11_Trunk-t-2-2_AttnS2-\n",
      "                                                                 1[0][0]',                        \n",
      "                                                                  'Mult_L1_AttnS2-1[1][0]',       \n",
      "                                                                  'ResUnit_L11_Trunk-t-2-2_AttnS2-\n",
      "                                                                 1[1][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L1_Output-p-1-1_AttnS2  (None, 16, 16, 256)  1024       ['Add_L2_AttnS2-1[0][0]',        \n",
      " -1 (BatchNormalization)                                          'Add_L2_AttnS2-1[1][0]']        \n",
      "                                                                                                  \n",
      " ResUnit_L2_Output-p-1-1_AttnS2  (None, 16, 16, 256)  0          ['ResUnit_L1_Output-p-1-1_AttnS2-\n",
      " -1 (Activation)                                                 1[0][0]',                        \n",
      "                                                                  'ResUnit_L1_Output-p-1-1_AttnS2-\n",
      "                                                                 1[1][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L3_Output-p-1-1_AttnS2  (None, 16, 16, 64)  16384       ['ResUnit_L2_Output-p-1-1_AttnS2-\n",
      " -1 (Conv2D)                                                     1[0][0]',                        \n",
      "                                                                  'ResUnit_L2_Output-p-1-1_AttnS2-\n",
      "                                                                 1[1][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L4_Output-p-1-1_AttnS2  (None, 16, 16, 64)  256         ['ResUnit_L3_Output-p-1-1_AttnS2-\n",
      " -1 (BatchNormalization)                                         1[0][0]',                        \n",
      "                                                                  'ResUnit_L3_Output-p-1-1_AttnS2-\n",
      "                                                                 1[1][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L5_Output-p-1-1_AttnS2  (None, 16, 16, 64)  0           ['ResUnit_L4_Output-p-1-1_AttnS2-\n",
      " -1 (Activation)                                                 1[0][0]',                        \n",
      "                                                                  'ResUnit_L4_Output-p-1-1_AttnS2-\n",
      "                                                                 1[1][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L6_Output-p-1-1_AttnS2  (None, 16, 16, 64)  36864       ['ResUnit_L5_Output-p-1-1_AttnS2-\n",
      " -1 (Conv2D)                                                     1[0][0]',                        \n",
      "                                                                  'ResUnit_L5_Output-p-1-1_AttnS2-\n",
      "                                                                 1[1][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L7_Output-p-1-1_AttnS2  (None, 16, 16, 64)  256         ['ResUnit_L6_Output-p-1-1_AttnS2-\n",
      " -1 (BatchNormalization)                                         1[0][0]',                        \n",
      "                                                                  'ResUnit_L6_Output-p-1-1_AttnS2-\n",
      "                                                                 1[1][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L8_Output-p-1-1_AttnS2  (None, 16, 16, 64)  0           ['ResUnit_L7_Output-p-1-1_AttnS2-\n",
      " -1 (Activation)                                                 1[0][0]',                        \n",
      "                                                                  'ResUnit_L7_Output-p-1-1_AttnS2-\n",
      "                                                                 1[1][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L9_Output-p-1-1_AttnS2  (None, 16, 16, 256)  16384      ['ResUnit_L8_Output-p-1-1_AttnS2-\n",
      " -1 (Conv2D)                                                     1[0][0]',                        \n",
      "                                                                  'ResUnit_L8_Output-p-1-1_AttnS2-\n",
      "                                                                 1[1][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L10_Output-p-1-1_AttnS  (None, 16, 16, 256)  65536      ['ResUnit_L2_Output-p-1-1_AttnS2-\n",
      " 2-1 (Conv2D)                                                    1[0][0]',                        \n",
      "                                                                  'ResUnit_L2_Output-p-1-1_AttnS2-\n",
      "                                                                 1[1][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L11_Output-p-1-1_AttnS  (None, 16, 16, 256)  0          ['ResUnit_L9_Output-p-1-1_AttnS2-\n",
      " 2-1 (Add)                                                       1[0][0]',                        \n",
      "                                                                  'ResUnit_L10_Output-p-1-1_AttnS2\n",
      "                                                                 -1[0][0]',                       \n",
      "                                                                  'ResUnit_L9_Output-p-1-1_AttnS2-\n",
      "                                                                 1[1][0]',                        \n",
      "                                                                  'ResUnit_L10_Output-p-1-1_AttnS2\n",
      "                                                                 -1[1][0]']                       \n",
      "                                                                                                  \n",
      " ResUnit_L1_NotAttnModule_3_DS   (None, 16, 16, 256)  1024       ['ResUnit_L11_Output-p-1-1_AttnS2\n",
      " (BatchNormalization)                                            -1[1][0]']                       \n",
      "                                                                                                  \n",
      " ResUnit_L2_NotAttnModule_3_DS   (None, 16, 16, 256)  0          ['ResUnit_L1_NotAttnModule_3_DS[0\n",
      " (Activation)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L3_NotAttnModule_3_DS   (None, 16, 16, 128)  32768      ['ResUnit_L2_NotAttnModule_3_DS[0\n",
      " (Conv2D)                                                        ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L4_NotAttnModule_3_DS   (None, 16, 16, 128)  512        ['ResUnit_L3_NotAttnModule_3_DS[0\n",
      " (BatchNormalization)                                            ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L5_NotAttnModule_3_DS   (None, 16, 16, 128)  0          ['ResUnit_L4_NotAttnModule_3_DS[0\n",
      " (Activation)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L6_NotAttnModule_3_DS   (None, 8, 8, 128)   147456      ['ResUnit_L5_NotAttnModule_3_DS[0\n",
      " (Conv2D)                                                        ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L7_NotAttnModule_3_DS   (None, 8, 8, 128)   512         ['ResUnit_L6_NotAttnModule_3_DS[0\n",
      " (BatchNormalization)                                            ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L8_NotAttnModule_3_DS   (None, 8, 8, 128)   0           ['ResUnit_L7_NotAttnModule_3_DS[0\n",
      " (Activation)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L9_NotAttnModule_3_DS   (None, 8, 8, 512)   65536       ['ResUnit_L8_NotAttnModule_3_DS[0\n",
      " (Conv2D)                                                        ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L10_NotAttnModule_3_DS  (None, 8, 8, 512)   131072      ['ResUnit_L2_NotAttnModule_3_DS[0\n",
      "  (Conv2D)                                                       ][0]']                           \n",
      "                                                                                                  \n",
      " ResUnit_L11_NotAttnModule_3_DS  (None, 8, 8, 512)   0           ['ResUnit_L9_NotAttnModule_3_DS[0\n",
      "  (Add)                                                          ][0]',                           \n",
      "                                                                  'ResUnit_L10_NotAttnModule_3_DS[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " ResUnit_L1_Input-p-1-1_AttnS3-  (None, 8, 8, 512)   2048        ['ResUnit_L11_NotAttnModule_3_DS[\n",
      " 1 (BatchNormalization)                                          0][0]']                          \n",
      "                                                                                                  \n",
      " ResUnit_L2_Input-p-1-1_AttnS3-  (None, 8, 8, 512)   0           ['ResUnit_L1_Input-p-1-1_AttnS3-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L3_Input-p-1-1_AttnS3-  (None, 8, 8, 128)   65536       ['ResUnit_L2_Input-p-1-1_AttnS3-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L4_Input-p-1-1_AttnS3-  (None, 8, 8, 128)   512         ['ResUnit_L3_Input-p-1-1_AttnS3-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L5_Input-p-1-1_AttnS3-  (None, 8, 8, 128)   0           ['ResUnit_L4_Input-p-1-1_AttnS3-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L6_Input-p-1-1_AttnS3-  (None, 8, 8, 128)   147456      ['ResUnit_L5_Input-p-1-1_AttnS3-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L7_Input-p-1-1_AttnS3-  (None, 8, 8, 128)   512         ['ResUnit_L6_Input-p-1-1_AttnS3-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L8_Input-p-1-1_AttnS3-  (None, 8, 8, 128)   0           ['ResUnit_L7_Input-p-1-1_AttnS3-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L9_Input-p-1-1_AttnS3-  (None, 8, 8, 512)   65536       ['ResUnit_L8_Input-p-1-1_AttnS3-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_Input-p-1-1_AttnS3  (None, 8, 8, 512)   262144      ['ResUnit_L2_Input-p-1-1_AttnS3-1\n",
      " -1 (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L11_Input-p-1-1_AttnS3  (None, 8, 8, 512)   0           ['ResUnit_L9_Input-p-1-1_AttnS3-1\n",
      " -1 (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_Input-p-1-1_AttnS3-\n",
      "                                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L1_UpSamp-r-1-1_Mask_A  (None, 8, 8, 512)   2048        ['ResUnit_L11_Input-p-1-1_AttnS3-\n",
      " ttnS3-1 (BatchNormalization)                                    1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L2_UpSamp-r-1-1_Mask_A  (None, 8, 8, 512)   0           ['ResUnit_L1_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-1 (Activation)                                            tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L3_UpSamp-r-1-1_Mask_A  (None, 8, 8, 128)   65536       ['ResUnit_L2_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-1 (Conv2D)                                                tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L4_UpSamp-r-1-1_Mask_A  (None, 8, 8, 128)   512         ['ResUnit_L3_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-1 (BatchNormalization)                                    tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L5_UpSamp-r-1-1_Mask_A  (None, 8, 8, 128)   0           ['ResUnit_L4_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-1 (Activation)                                            tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L6_UpSamp-r-1-1_Mask_A  (None, 8, 8, 128)   147456      ['ResUnit_L5_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-1 (Conv2D)                                                tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L7_UpSamp-r-1-1_Mask_A  (None, 8, 8, 128)   512         ['ResUnit_L6_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-1 (BatchNormalization)                                    tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L8_UpSamp-r-1-1_Mask_A  (None, 8, 8, 128)   0           ['ResUnit_L7_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-1 (Activation)                                            tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L1_Trunk-t-2-1_AttnS3-  (None, 8, 8, 512)   2048        ['ResUnit_L11_Input-p-1-1_AttnS3-\n",
      " 1 (BatchNormalization)                                          1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L9_UpSamp-r-1-1_Mask_A  (None, 8, 8, 512)   65536       ['ResUnit_L8_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-1 (Conv2D)                                                tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L10_UpSamp-r-1-1_Mask_  (None, 8, 8, 512)   262144      ['ResUnit_L2_UpSamp-r-1-1_Mask_At\n",
      " AttnS3-1 (Conv2D)                                               tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L2_Trunk-t-2-1_AttnS3-  (None, 8, 8, 512)   0           ['ResUnit_L1_Trunk-t-2-1_AttnS3-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L11_UpSamp-r-1-1_Mask_  (None, 8, 8, 512)   0           ['ResUnit_L9_UpSamp-r-1-1_Mask_At\n",
      " AttnS3-1 (Add)                                                  tnS3-1[0][0]',                   \n",
      "                                                                  'ResUnit_L10_UpSamp-r-1-1_Mask_A\n",
      "                                                                 ttnS3-1[0][0]']                  \n",
      "                                                                                                  \n",
      " ResUnit_L3_Trunk-t-2-1_AttnS3-  (None, 8, 8, 128)   65536       ['ResUnit_L2_Trunk-t-2-1_AttnS3-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L1_UpSamp-r-1-2_Mask_A  (None, 8, 8, 512)   2048        ['ResUnit_L11_UpSamp-r-1-1_Mask_A\n",
      " ttnS3-1 (BatchNormalization)                                    ttnS3-1[0][0]']                  \n",
      "                                                                                                  \n",
      " ResUnit_L4_Trunk-t-2-1_AttnS3-  (None, 8, 8, 128)   512         ['ResUnit_L3_Trunk-t-2-1_AttnS3-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L2_UpSamp-r-1-2_Mask_A  (None, 8, 8, 512)   0           ['ResUnit_L1_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-1 (Activation)                                            tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L5_Trunk-t-2-1_AttnS3-  (None, 8, 8, 128)   0           ['ResUnit_L4_Trunk-t-2-1_AttnS3-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L3_UpSamp-r-1-2_Mask_A  (None, 8, 8, 128)   65536       ['ResUnit_L2_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-1 (Conv2D)                                                tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L6_Trunk-t-2-1_AttnS3-  (None, 8, 8, 128)   147456      ['ResUnit_L5_Trunk-t-2-1_AttnS3-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L4_UpSamp-r-1-2_Mask_A  (None, 8, 8, 128)   512         ['ResUnit_L3_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-1 (BatchNormalization)                                    tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L7_Trunk-t-2-1_AttnS3-  (None, 8, 8, 128)   512         ['ResUnit_L6_Trunk-t-2-1_AttnS3-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L5_UpSamp-r-1-2_Mask_A  (None, 8, 8, 128)   0           ['ResUnit_L4_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-1 (Activation)                                            tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L8_Trunk-t-2-1_AttnS3-  (None, 8, 8, 128)   0           ['ResUnit_L7_Trunk-t-2-1_AttnS3-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L6_UpSamp-r-1-2_Mask_A  (None, 8, 8, 128)   147456      ['ResUnit_L5_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-1 (Conv2D)                                                tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L9_Trunk-t-2-1_AttnS3-  (None, 8, 8, 512)   65536       ['ResUnit_L8_Trunk-t-2-1_AttnS3-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_Trunk-t-2-1_AttnS3  (None, 8, 8, 512)   262144      ['ResUnit_L2_Trunk-t-2-1_AttnS3-1\n",
      " -1 (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L7_UpSamp-r-1-2_Mask_A  (None, 8, 8, 128)   512         ['ResUnit_L6_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-1 (BatchNormalization)                                    tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L11_Trunk-t-2-1_AttnS3  (None, 8, 8, 512)   0           ['ResUnit_L9_Trunk-t-2-1_AttnS3-1\n",
      " -1 (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_Trunk-t-2-1_AttnS3-\n",
      "                                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L8_UpSamp-r-1-2_Mask_A  (None, 8, 8, 128)   0           ['ResUnit_L7_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-1 (Activation)                                            tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L1_Trunk-t-2-2_AttnS3-  (None, 8, 8, 512)   2048        ['ResUnit_L11_Trunk-t-2-1_AttnS3-\n",
      " 1 (BatchNormalization)                                          1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L9_UpSamp-r-1-2_Mask_A  (None, 8, 8, 512)   65536       ['ResUnit_L8_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-1 (Conv2D)                                                tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L10_UpSamp-r-1-2_Mask_  (None, 8, 8, 512)   262144      ['ResUnit_L2_UpSamp-r-1-2_Mask_At\n",
      " AttnS3-1 (Conv2D)                                               tnS3-1[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L2_Trunk-t-2-2_AttnS3-  (None, 8, 8, 512)   0           ['ResUnit_L1_Trunk-t-2-2_AttnS3-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L11_UpSamp-r-1-2_Mask_  (None, 8, 8, 512)   0           ['ResUnit_L9_UpSamp-r-1-2_Mask_At\n",
      " AttnS3-1 (Add)                                                  tnS3-1[0][0]',                   \n",
      "                                                                  'ResUnit_L10_UpSamp-r-1-2_Mask_A\n",
      "                                                                 ttnS3-1[0][0]']                  \n",
      "                                                                                                  \n",
      " ResUnit_L3_Trunk-t-2-2_AttnS3-  (None, 8, 8, 128)   65536       ['ResUnit_L2_Trunk-t-2-2_AttnS3-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L1_Attn_S3-1 (Bat  (None, 8, 8, 512)   2048        ['ResUnit_L11_UpSamp-r-1-2_Mask_A\n",
      " chNormalization)                                                ttnS3-1[0][0]']                  \n",
      "                                                                                                  \n",
      " ResUnit_L4_Trunk-t-2-2_AttnS3-  (None, 8, 8, 128)   512         ['ResUnit_L3_Trunk-t-2-2_AttnS3-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L2_Attn_S3-1 (Act  (None, 8, 8, 512)   0           ['SpcConv_Mask_L1_Attn_S3-1[0][0]\n",
      " ivation)                                                        ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L5_Trunk-t-2-2_AttnS3-  (None, 8, 8, 128)   0           ['ResUnit_L4_Trunk-t-2-2_AttnS3-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L3_Attn_S3-1 (Con  (None, 8, 8, 512)   262144      ['SpcConv_Mask_L2_Attn_S3-1[0][0]\n",
      " v2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L6_Trunk-t-2-2_AttnS3-  (None, 8, 8, 128)   147456      ['ResUnit_L5_Trunk-t-2-2_AttnS3-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L4_Attn_S3-1 (Bat  (None, 8, 8, 512)   2048        ['SpcConv_Mask_L3_Attn_S3-1[0][0]\n",
      " chNormalization)                                                ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L7_Trunk-t-2-2_AttnS3-  (None, 8, 8, 128)   512         ['ResUnit_L6_Trunk-t-2-2_AttnS3-1\n",
      " 1 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L5_Attn_S3-1 (Act  (None, 8, 8, 512)   0           ['SpcConv_Mask_L4_Attn_S3-1[0][0]\n",
      " ivation)                                                        ',                               \n",
      "                                                                  'SpcConv_Mask_L5_Attn_S3-1[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L8_Trunk-t-2-2_AttnS3-  (None, 8, 8, 128)   0           ['ResUnit_L7_Trunk-t-2-2_AttnS3-1\n",
      " 1 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L9_Trunk-t-2-2_AttnS3-  (None, 8, 8, 512)   65536       ['ResUnit_L8_Trunk-t-2-2_AttnS3-1\n",
      " 1 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_Trunk-t-2-2_AttnS3  (None, 8, 8, 512)   262144      ['ResUnit_L2_Trunk-t-2-2_AttnS3-1\n",
      " -1 (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L7_Attn_S3-1 (Act  (None, 8, 8, 512)   0           ['SpcConv_Mask_L5_Attn_S3-1[1][0]\n",
      " ivation)                                                        ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L11_Trunk-t-2-2_AttnS3  (None, 8, 8, 512)   0           ['ResUnit_L9_Trunk-t-2-2_AttnS3-1\n",
      " -1 (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_Trunk-t-2-2_AttnS3-\n",
      "                                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " Mult_L1_AttnS3-1 (Multiply)    (None, 8, 8, 512)    0           ['SpcConv_Mask_L7_Attn_S3-1[0][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'ResUnit_L11_Trunk-t-2-2_AttnS3-\n",
      "                                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " Add_L1_AttnS3-1 (Add)          (None, 8, 8, 512)    0           ['Mult_L1_AttnS3-1[0][0]',       \n",
      "                                                                  'ResUnit_L11_Trunk-t-2-2_AttnS3-\n",
      "                                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L1_Output-p-1-1_AttnS3  (None, 8, 8, 512)   2048        ['Add_L1_AttnS3-1[0][0]']        \n",
      " -1 (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " ResUnit_L2_Output-p-1-1_AttnS3  (None, 8, 8, 512)   0           ['ResUnit_L1_Output-p-1-1_AttnS3-\n",
      " -1 (Activation)                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L3_Output-p-1-1_AttnS3  (None, 8, 8, 128)   65536       ['ResUnit_L2_Output-p-1-1_AttnS3-\n",
      " -1 (Conv2D)                                                     1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L4_Output-p-1-1_AttnS3  (None, 8, 8, 128)   512         ['ResUnit_L3_Output-p-1-1_AttnS3-\n",
      " -1 (BatchNormalization)                                         1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L5_Output-p-1-1_AttnS3  (None, 8, 8, 128)   0           ['ResUnit_L4_Output-p-1-1_AttnS3-\n",
      " -1 (Activation)                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L6_Output-p-1-1_AttnS3  (None, 8, 8, 128)   147456      ['ResUnit_L5_Output-p-1-1_AttnS3-\n",
      " -1 (Conv2D)                                                     1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L7_Output-p-1-1_AttnS3  (None, 8, 8, 128)   512         ['ResUnit_L6_Output-p-1-1_AttnS3-\n",
      " -1 (BatchNormalization)                                         1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L8_Output-p-1-1_AttnS3  (None, 8, 8, 128)   0           ['ResUnit_L7_Output-p-1-1_AttnS3-\n",
      " -1 (Activation)                                                 1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L9_Output-p-1-1_AttnS3  (None, 8, 8, 512)   65536       ['ResUnit_L8_Output-p-1-1_AttnS3-\n",
      " -1 (Conv2D)                                                     1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L10_Output-p-1-1_AttnS  (None, 8, 8, 512)   262144      ['ResUnit_L2_Output-p-1-1_AttnS3-\n",
      " 3-1 (Conv2D)                                                    1[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L11_Output-p-1-1_AttnS  (None, 8, 8, 512)   0           ['ResUnit_L9_Output-p-1-1_AttnS3-\n",
      " 3-1 (Add)                                                       1[0][0]',                        \n",
      "                                                                  'ResUnit_L10_Output-p-1-1_AttnS3\n",
      "                                                                 -1[0][0]']                       \n",
      "                                                                                                  \n",
      " ResUnit_L1_Input-p-1-1_AttnS3-  (None, 8, 8, 512)   2048        ['ResUnit_L11_Output-p-1-1_AttnS3\n",
      " 2 (BatchNormalization)                                          -1[0][0]']                       \n",
      "                                                                                                  \n",
      " ResUnit_L2_Input-p-1-1_AttnS3-  (None, 8, 8, 512)   0           ['ResUnit_L1_Input-p-1-1_AttnS3-2\n",
      " 2 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L3_Input-p-1-1_AttnS3-  (None, 8, 8, 128)   65536       ['ResUnit_L2_Input-p-1-1_AttnS3-2\n",
      " 2 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L4_Input-p-1-1_AttnS3-  (None, 8, 8, 128)   512         ['ResUnit_L3_Input-p-1-1_AttnS3-2\n",
      " 2 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L5_Input-p-1-1_AttnS3-  (None, 8, 8, 128)   0           ['ResUnit_L4_Input-p-1-1_AttnS3-2\n",
      " 2 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L6_Input-p-1-1_AttnS3-  (None, 8, 8, 128)   147456      ['ResUnit_L5_Input-p-1-1_AttnS3-2\n",
      " 2 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L7_Input-p-1-1_AttnS3-  (None, 8, 8, 128)   512         ['ResUnit_L6_Input-p-1-1_AttnS3-2\n",
      " 2 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L8_Input-p-1-1_AttnS3-  (None, 8, 8, 128)   0           ['ResUnit_L7_Input-p-1-1_AttnS3-2\n",
      " 2 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L9_Input-p-1-1_AttnS3-  (None, 8, 8, 512)   65536       ['ResUnit_L8_Input-p-1-1_AttnS3-2\n",
      " 2 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_Input-p-1-1_AttnS3  (None, 8, 8, 512)   262144      ['ResUnit_L2_Input-p-1-1_AttnS3-2\n",
      " -2 (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L11_Input-p-1-1_AttnS3  (None, 8, 8, 512)   0           ['ResUnit_L9_Input-p-1-1_AttnS3-2\n",
      " -2 (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_Input-p-1-1_AttnS3-\n",
      "                                                                 2[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L1_UpSamp-r-1-1_Mask_A  (None, 8, 8, 512)   2048        ['ResUnit_L11_Input-p-1-1_AttnS3-\n",
      " ttnS3-2 (BatchNormalization)                                    2[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L2_UpSamp-r-1-1_Mask_A  (None, 8, 8, 512)   0           ['ResUnit_L1_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-2 (Activation)                                            tnS3-2[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L3_UpSamp-r-1-1_Mask_A  (None, 8, 8, 128)   65536       ['ResUnit_L2_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-2 (Conv2D)                                                tnS3-2[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L4_UpSamp-r-1-1_Mask_A  (None, 8, 8, 128)   512         ['ResUnit_L3_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-2 (BatchNormalization)                                    tnS3-2[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L5_UpSamp-r-1-1_Mask_A  (None, 8, 8, 128)   0           ['ResUnit_L4_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-2 (Activation)                                            tnS3-2[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L6_UpSamp-r-1-1_Mask_A  (None, 8, 8, 128)   147456      ['ResUnit_L5_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-2 (Conv2D)                                                tnS3-2[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L7_UpSamp-r-1-1_Mask_A  (None, 8, 8, 128)   512         ['ResUnit_L6_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-2 (BatchNormalization)                                    tnS3-2[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L8_UpSamp-r-1-1_Mask_A  (None, 8, 8, 128)   0           ['ResUnit_L7_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-2 (Activation)                                            tnS3-2[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L1_Trunk-t-2-1_AttnS3-  (None, 8, 8, 512)   2048        ['ResUnit_L11_Input-p-1-1_AttnS3-\n",
      " 2 (BatchNormalization)                                          2[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L9_UpSamp-r-1-1_Mask_A  (None, 8, 8, 512)   65536       ['ResUnit_L8_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-2 (Conv2D)                                                tnS3-2[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L10_UpSamp-r-1-1_Mask_  (None, 8, 8, 512)   262144      ['ResUnit_L2_UpSamp-r-1-1_Mask_At\n",
      " AttnS3-2 (Conv2D)                                               tnS3-2[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L2_Trunk-t-2-1_AttnS3-  (None, 8, 8, 512)   0           ['ResUnit_L1_Trunk-t-2-1_AttnS3-2\n",
      " 2 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L11_UpSamp-r-1-1_Mask_  (None, 8, 8, 512)   0           ['ResUnit_L9_UpSamp-r-1-1_Mask_At\n",
      " AttnS3-2 (Add)                                                  tnS3-2[0][0]',                   \n",
      "                                                                  'ResUnit_L10_UpSamp-r-1-1_Mask_A\n",
      "                                                                 ttnS3-2[0][0]']                  \n",
      "                                                                                                  \n",
      " ResUnit_L3_Trunk-t-2-1_AttnS3-  (None, 8, 8, 128)   65536       ['ResUnit_L2_Trunk-t-2-1_AttnS3-2\n",
      " 2 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L1_UpSamp-r-1-2_Mask_A  (None, 8, 8, 512)   2048        ['ResUnit_L11_UpSamp-r-1-1_Mask_A\n",
      " ttnS3-2 (BatchNormalization)                                    ttnS3-2[0][0]']                  \n",
      "                                                                                                  \n",
      " ResUnit_L4_Trunk-t-2-1_AttnS3-  (None, 8, 8, 128)   512         ['ResUnit_L3_Trunk-t-2-1_AttnS3-2\n",
      " 2 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L2_UpSamp-r-1-2_Mask_A  (None, 8, 8, 512)   0           ['ResUnit_L1_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-2 (Activation)                                            tnS3-2[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L5_Trunk-t-2-1_AttnS3-  (None, 8, 8, 128)   0           ['ResUnit_L4_Trunk-t-2-1_AttnS3-2\n",
      " 2 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L3_UpSamp-r-1-2_Mask_A  (None, 8, 8, 128)   65536       ['ResUnit_L2_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-2 (Conv2D)                                                tnS3-2[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L6_Trunk-t-2-1_AttnS3-  (None, 8, 8, 128)   147456      ['ResUnit_L5_Trunk-t-2-1_AttnS3-2\n",
      " 2 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L4_UpSamp-r-1-2_Mask_A  (None, 8, 8, 128)   512         ['ResUnit_L3_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-2 (BatchNormalization)                                    tnS3-2[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L7_Trunk-t-2-1_AttnS3-  (None, 8, 8, 128)   512         ['ResUnit_L6_Trunk-t-2-1_AttnS3-2\n",
      " 2 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L5_UpSamp-r-1-2_Mask_A  (None, 8, 8, 128)   0           ['ResUnit_L4_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-2 (Activation)                                            tnS3-2[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L8_Trunk-t-2-1_AttnS3-  (None, 8, 8, 128)   0           ['ResUnit_L7_Trunk-t-2-1_AttnS3-2\n",
      " 2 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L6_UpSamp-r-1-2_Mask_A  (None, 8, 8, 128)   147456      ['ResUnit_L5_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-2 (Conv2D)                                                tnS3-2[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L9_Trunk-t-2-1_AttnS3-  (None, 8, 8, 512)   65536       ['ResUnit_L8_Trunk-t-2-1_AttnS3-2\n",
      " 2 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_Trunk-t-2-1_AttnS3  (None, 8, 8, 512)   262144      ['ResUnit_L2_Trunk-t-2-1_AttnS3-2\n",
      " -2 (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L7_UpSamp-r-1-2_Mask_A  (None, 8, 8, 128)   512         ['ResUnit_L6_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-2 (BatchNormalization)                                    tnS3-2[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L11_Trunk-t-2-1_AttnS3  (None, 8, 8, 512)   0           ['ResUnit_L9_Trunk-t-2-1_AttnS3-2\n",
      " -2 (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_Trunk-t-2-1_AttnS3-\n",
      "                                                                 2[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L8_UpSamp-r-1-2_Mask_A  (None, 8, 8, 128)   0           ['ResUnit_L7_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-2 (Activation)                                            tnS3-2[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L1_Trunk-t-2-2_AttnS3-  (None, 8, 8, 512)   2048        ['ResUnit_L11_Trunk-t-2-1_AttnS3-\n",
      " 2 (BatchNormalization)                                          2[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L9_UpSamp-r-1-2_Mask_A  (None, 8, 8, 512)   65536       ['ResUnit_L8_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-2 (Conv2D)                                                tnS3-2[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L10_UpSamp-r-1-2_Mask_  (None, 8, 8, 512)   262144      ['ResUnit_L2_UpSamp-r-1-2_Mask_At\n",
      " AttnS3-2 (Conv2D)                                               tnS3-2[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L2_Trunk-t-2-2_AttnS3-  (None, 8, 8, 512)   0           ['ResUnit_L1_Trunk-t-2-2_AttnS3-2\n",
      " 2 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L11_UpSamp-r-1-2_Mask_  (None, 8, 8, 512)   0           ['ResUnit_L9_UpSamp-r-1-2_Mask_At\n",
      " AttnS3-2 (Add)                                                  tnS3-2[0][0]',                   \n",
      "                                                                  'ResUnit_L10_UpSamp-r-1-2_Mask_A\n",
      "                                                                 ttnS3-2[0][0]']                  \n",
      "                                                                                                  \n",
      " ResUnit_L3_Trunk-t-2-2_AttnS3-  (None, 8, 8, 128)   65536       ['ResUnit_L2_Trunk-t-2-2_AttnS3-2\n",
      " 2 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L1_Attn_S3-2 (Bat  (None, 8, 8, 512)   2048        ['ResUnit_L11_UpSamp-r-1-2_Mask_A\n",
      " chNormalization)                                                ttnS3-2[0][0]']                  \n",
      "                                                                                                  \n",
      " ResUnit_L4_Trunk-t-2-2_AttnS3-  (None, 8, 8, 128)   512         ['ResUnit_L3_Trunk-t-2-2_AttnS3-2\n",
      " 2 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L2_Attn_S3-2 (Act  (None, 8, 8, 512)   0           ['SpcConv_Mask_L1_Attn_S3-2[0][0]\n",
      " ivation)                                                        ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L5_Trunk-t-2-2_AttnS3-  (None, 8, 8, 128)   0           ['ResUnit_L4_Trunk-t-2-2_AttnS3-2\n",
      " 2 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L3_Attn_S3-2 (Con  (None, 8, 8, 512)   262144      ['SpcConv_Mask_L2_Attn_S3-2[0][0]\n",
      " v2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L6_Trunk-t-2-2_AttnS3-  (None, 8, 8, 128)   147456      ['ResUnit_L5_Trunk-t-2-2_AttnS3-2\n",
      " 2 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L4_Attn_S3-2 (Bat  (None, 8, 8, 512)   2048        ['SpcConv_Mask_L3_Attn_S3-2[0][0]\n",
      " chNormalization)                                                ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L7_Trunk-t-2-2_AttnS3-  (None, 8, 8, 128)   512         ['ResUnit_L6_Trunk-t-2-2_AttnS3-2\n",
      " 2 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L5_Attn_S3-2 (Act  (None, 8, 8, 512)   0           ['SpcConv_Mask_L4_Attn_S3-2[0][0]\n",
      " ivation)                                                        ',                               \n",
      "                                                                  'SpcConv_Mask_L5_Attn_S3-2[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L8_Trunk-t-2-2_AttnS3-  (None, 8, 8, 128)   0           ['ResUnit_L7_Trunk-t-2-2_AttnS3-2\n",
      " 2 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L9_Trunk-t-2-2_AttnS3-  (None, 8, 8, 512)   65536       ['ResUnit_L8_Trunk-t-2-2_AttnS3-2\n",
      " 2 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_Trunk-t-2-2_AttnS3  (None, 8, 8, 512)   262144      ['ResUnit_L2_Trunk-t-2-2_AttnS3-2\n",
      " -2 (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L7_Attn_S3-2 (Act  (None, 8, 8, 512)   0           ['SpcConv_Mask_L5_Attn_S3-2[1][0]\n",
      " ivation)                                                        ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L11_Trunk-t-2-2_AttnS3  (None, 8, 8, 512)   0           ['ResUnit_L9_Trunk-t-2-2_AttnS3-2\n",
      " -2 (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_Trunk-t-2-2_AttnS3-\n",
      "                                                                 2[0][0]']                        \n",
      "                                                                                                  \n",
      " Mult_L1_AttnS3-2 (Multiply)    (None, 8, 8, 512)    0           ['SpcConv_Mask_L7_Attn_S3-2[0][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'ResUnit_L11_Trunk-t-2-2_AttnS3-\n",
      "                                                                 2[0][0]']                        \n",
      "                                                                                                  \n",
      " Add_L1_AttnS3-2 (Add)          (None, 8, 8, 512)    0           ['Mult_L1_AttnS3-2[0][0]',       \n",
      "                                                                  'ResUnit_L11_Trunk-t-2-2_AttnS3-\n",
      "                                                                 2[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L1_Output-p-1-1_AttnS3  (None, 8, 8, 512)   2048        ['Add_L1_AttnS3-2[0][0]']        \n",
      " -2 (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " ResUnit_L2_Output-p-1-1_AttnS3  (None, 8, 8, 512)   0           ['ResUnit_L1_Output-p-1-1_AttnS3-\n",
      " -2 (Activation)                                                 2[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L3_Output-p-1-1_AttnS3  (None, 8, 8, 128)   65536       ['ResUnit_L2_Output-p-1-1_AttnS3-\n",
      " -2 (Conv2D)                                                     2[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L4_Output-p-1-1_AttnS3  (None, 8, 8, 128)   512         ['ResUnit_L3_Output-p-1-1_AttnS3-\n",
      " -2 (BatchNormalization)                                         2[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L5_Output-p-1-1_AttnS3  (None, 8, 8, 128)   0           ['ResUnit_L4_Output-p-1-1_AttnS3-\n",
      " -2 (Activation)                                                 2[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L6_Output-p-1-1_AttnS3  (None, 8, 8, 128)   147456      ['ResUnit_L5_Output-p-1-1_AttnS3-\n",
      " -2 (Conv2D)                                                     2[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L7_Output-p-1-1_AttnS3  (None, 8, 8, 128)   512         ['ResUnit_L6_Output-p-1-1_AttnS3-\n",
      " -2 (BatchNormalization)                                         2[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L8_Output-p-1-1_AttnS3  (None, 8, 8, 128)   0           ['ResUnit_L7_Output-p-1-1_AttnS3-\n",
      " -2 (Activation)                                                 2[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L9_Output-p-1-1_AttnS3  (None, 8, 8, 512)   65536       ['ResUnit_L8_Output-p-1-1_AttnS3-\n",
      " -2 (Conv2D)                                                     2[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L10_Output-p-1-1_AttnS  (None, 8, 8, 512)   262144      ['ResUnit_L2_Output-p-1-1_AttnS3-\n",
      " 3-2 (Conv2D)                                                    2[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L11_Output-p-1-1_AttnS  (None, 8, 8, 512)   0           ['ResUnit_L9_Output-p-1-1_AttnS3-\n",
      " 3-2 (Add)                                                       2[0][0]',                        \n",
      "                                                                  'ResUnit_L10_Output-p-1-1_AttnS3\n",
      "                                                                 -2[0][0]']                       \n",
      "                                                                                                  \n",
      " ResUnit_L1_Input-p-1-1_AttnS3-  (None, 8, 8, 512)   2048        ['ResUnit_L11_Output-p-1-1_AttnS3\n",
      " 3 (BatchNormalization)                                          -2[0][0]']                       \n",
      "                                                                                                  \n",
      " ResUnit_L2_Input-p-1-1_AttnS3-  (None, 8, 8, 512)   0           ['ResUnit_L1_Input-p-1-1_AttnS3-3\n",
      " 3 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L3_Input-p-1-1_AttnS3-  (None, 8, 8, 128)   65536       ['ResUnit_L2_Input-p-1-1_AttnS3-3\n",
      " 3 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L4_Input-p-1-1_AttnS3-  (None, 8, 8, 128)   512         ['ResUnit_L3_Input-p-1-1_AttnS3-3\n",
      " 3 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L5_Input-p-1-1_AttnS3-  (None, 8, 8, 128)   0           ['ResUnit_L4_Input-p-1-1_AttnS3-3\n",
      " 3 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L6_Input-p-1-1_AttnS3-  (None, 8, 8, 128)   147456      ['ResUnit_L5_Input-p-1-1_AttnS3-3\n",
      " 3 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L7_Input-p-1-1_AttnS3-  (None, 8, 8, 128)   512         ['ResUnit_L6_Input-p-1-1_AttnS3-3\n",
      " 3 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L8_Input-p-1-1_AttnS3-  (None, 8, 8, 128)   0           ['ResUnit_L7_Input-p-1-1_AttnS3-3\n",
      " 3 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L9_Input-p-1-1_AttnS3-  (None, 8, 8, 512)   65536       ['ResUnit_L8_Input-p-1-1_AttnS3-3\n",
      " 3 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_Input-p-1-1_AttnS3  (None, 8, 8, 512)   262144      ['ResUnit_L2_Input-p-1-1_AttnS3-3\n",
      " -3 (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L11_Input-p-1-1_AttnS3  (None, 8, 8, 512)   0           ['ResUnit_L9_Input-p-1-1_AttnS3-3\n",
      " -3 (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_Input-p-1-1_AttnS3-\n",
      "                                                                 3[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L1_UpSamp-r-1-1_Mask_A  (None, 8, 8, 512)   2048        ['ResUnit_L11_Input-p-1-1_AttnS3-\n",
      " ttnS3-3 (BatchNormalization)                                    3[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L2_UpSamp-r-1-1_Mask_A  (None, 8, 8, 512)   0           ['ResUnit_L1_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-3 (Activation)                                            tnS3-3[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L3_UpSamp-r-1-1_Mask_A  (None, 8, 8, 128)   65536       ['ResUnit_L2_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-3 (Conv2D)                                                tnS3-3[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L4_UpSamp-r-1-1_Mask_A  (None, 8, 8, 128)   512         ['ResUnit_L3_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-3 (BatchNormalization)                                    tnS3-3[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L5_UpSamp-r-1-1_Mask_A  (None, 8, 8, 128)   0           ['ResUnit_L4_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-3 (Activation)                                            tnS3-3[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L6_UpSamp-r-1-1_Mask_A  (None, 8, 8, 128)   147456      ['ResUnit_L5_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-3 (Conv2D)                                                tnS3-3[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L7_UpSamp-r-1-1_Mask_A  (None, 8, 8, 128)   512         ['ResUnit_L6_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-3 (BatchNormalization)                                    tnS3-3[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L8_UpSamp-r-1-1_Mask_A  (None, 8, 8, 128)   0           ['ResUnit_L7_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-3 (Activation)                                            tnS3-3[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L1_Trunk-t-2-1_AttnS3-  (None, 8, 8, 512)   2048        ['ResUnit_L11_Input-p-1-1_AttnS3-\n",
      " 3 (BatchNormalization)                                          3[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L9_UpSamp-r-1-1_Mask_A  (None, 8, 8, 512)   65536       ['ResUnit_L8_UpSamp-r-1-1_Mask_At\n",
      " ttnS3-3 (Conv2D)                                                tnS3-3[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L10_UpSamp-r-1-1_Mask_  (None, 8, 8, 512)   262144      ['ResUnit_L2_UpSamp-r-1-1_Mask_At\n",
      " AttnS3-3 (Conv2D)                                               tnS3-3[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L2_Trunk-t-2-1_AttnS3-  (None, 8, 8, 512)   0           ['ResUnit_L1_Trunk-t-2-1_AttnS3-3\n",
      " 3 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L11_UpSamp-r-1-1_Mask_  (None, 8, 8, 512)   0           ['ResUnit_L9_UpSamp-r-1-1_Mask_At\n",
      " AttnS3-3 (Add)                                                  tnS3-3[0][0]',                   \n",
      "                                                                  'ResUnit_L10_UpSamp-r-1-1_Mask_A\n",
      "                                                                 ttnS3-3[0][0]']                  \n",
      "                                                                                                  \n",
      " ResUnit_L3_Trunk-t-2-1_AttnS3-  (None, 8, 8, 128)   65536       ['ResUnit_L2_Trunk-t-2-1_AttnS3-3\n",
      " 3 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L1_UpSamp-r-1-2_Mask_A  (None, 8, 8, 512)   2048        ['ResUnit_L11_UpSamp-r-1-1_Mask_A\n",
      " ttnS3-3 (BatchNormalization)                                    ttnS3-3[0][0]']                  \n",
      "                                                                                                  \n",
      " ResUnit_L4_Trunk-t-2-1_AttnS3-  (None, 8, 8, 128)   512         ['ResUnit_L3_Trunk-t-2-1_AttnS3-3\n",
      " 3 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L2_UpSamp-r-1-2_Mask_A  (None, 8, 8, 512)   0           ['ResUnit_L1_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-3 (Activation)                                            tnS3-3[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L5_Trunk-t-2-1_AttnS3-  (None, 8, 8, 128)   0           ['ResUnit_L4_Trunk-t-2-1_AttnS3-3\n",
      " 3 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L3_UpSamp-r-1-2_Mask_A  (None, 8, 8, 128)   65536       ['ResUnit_L2_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-3 (Conv2D)                                                tnS3-3[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L6_Trunk-t-2-1_AttnS3-  (None, 8, 8, 128)   147456      ['ResUnit_L5_Trunk-t-2-1_AttnS3-3\n",
      " 3 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L4_UpSamp-r-1-2_Mask_A  (None, 8, 8, 128)   512         ['ResUnit_L3_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-3 (BatchNormalization)                                    tnS3-3[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L7_Trunk-t-2-1_AttnS3-  (None, 8, 8, 128)   512         ['ResUnit_L6_Trunk-t-2-1_AttnS3-3\n",
      " 3 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L5_UpSamp-r-1-2_Mask_A  (None, 8, 8, 128)   0           ['ResUnit_L4_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-3 (Activation)                                            tnS3-3[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L8_Trunk-t-2-1_AttnS3-  (None, 8, 8, 128)   0           ['ResUnit_L7_Trunk-t-2-1_AttnS3-3\n",
      " 3 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L6_UpSamp-r-1-2_Mask_A  (None, 8, 8, 128)   147456      ['ResUnit_L5_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-3 (Conv2D)                                                tnS3-3[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L9_Trunk-t-2-1_AttnS3-  (None, 8, 8, 512)   65536       ['ResUnit_L8_Trunk-t-2-1_AttnS3-3\n",
      " 3 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_Trunk-t-2-1_AttnS3  (None, 8, 8, 512)   262144      ['ResUnit_L2_Trunk-t-2-1_AttnS3-3\n",
      " -3 (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L7_UpSamp-r-1-2_Mask_A  (None, 8, 8, 128)   512         ['ResUnit_L6_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-3 (BatchNormalization)                                    tnS3-3[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L11_Trunk-t-2-1_AttnS3  (None, 8, 8, 512)   0           ['ResUnit_L9_Trunk-t-2-1_AttnS3-3\n",
      " -3 (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_Trunk-t-2-1_AttnS3-\n",
      "                                                                 3[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L8_UpSamp-r-1-2_Mask_A  (None, 8, 8, 128)   0           ['ResUnit_L7_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-3 (Activation)                                            tnS3-3[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L1_Trunk-t-2-2_AttnS3-  (None, 8, 8, 512)   2048        ['ResUnit_L11_Trunk-t-2-1_AttnS3-\n",
      " 3 (BatchNormalization)                                          3[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L9_UpSamp-r-1-2_Mask_A  (None, 8, 8, 512)   65536       ['ResUnit_L8_UpSamp-r-1-2_Mask_At\n",
      " ttnS3-3 (Conv2D)                                                tnS3-3[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L10_UpSamp-r-1-2_Mask_  (None, 8, 8, 512)   262144      ['ResUnit_L2_UpSamp-r-1-2_Mask_At\n",
      " AttnS3-3 (Conv2D)                                               tnS3-3[0][0]']                   \n",
      "                                                                                                  \n",
      " ResUnit_L2_Trunk-t-2-2_AttnS3-  (None, 8, 8, 512)   0           ['ResUnit_L1_Trunk-t-2-2_AttnS3-3\n",
      " 3 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L11_UpSamp-r-1-2_Mask_  (None, 8, 8, 512)   0           ['ResUnit_L9_UpSamp-r-1-2_Mask_At\n",
      " AttnS3-3 (Add)                                                  tnS3-3[0][0]',                   \n",
      "                                                                  'ResUnit_L10_UpSamp-r-1-2_Mask_A\n",
      "                                                                 ttnS3-3[0][0]']                  \n",
      "                                                                                                  \n",
      " ResUnit_L3_Trunk-t-2-2_AttnS3-  (None, 8, 8, 128)   65536       ['ResUnit_L2_Trunk-t-2-2_AttnS3-3\n",
      " 3 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L1_Attn_S3-3 (Bat  (None, 8, 8, 512)   2048        ['ResUnit_L11_UpSamp-r-1-2_Mask_A\n",
      " chNormalization)                                                ttnS3-3[0][0]']                  \n",
      "                                                                                                  \n",
      " ResUnit_L4_Trunk-t-2-2_AttnS3-  (None, 8, 8, 128)   512         ['ResUnit_L3_Trunk-t-2-2_AttnS3-3\n",
      " 3 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L2_Attn_S3-3 (Act  (None, 8, 8, 512)   0           ['SpcConv_Mask_L1_Attn_S3-3[0][0]\n",
      " ivation)                                                        ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L5_Trunk-t-2-2_AttnS3-  (None, 8, 8, 128)   0           ['ResUnit_L4_Trunk-t-2-2_AttnS3-3\n",
      " 3 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L3_Attn_S3-3 (Con  (None, 8, 8, 512)   262144      ['SpcConv_Mask_L2_Attn_S3-3[0][0]\n",
      " v2D)                                                            ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L6_Trunk-t-2-2_AttnS3-  (None, 8, 8, 128)   147456      ['ResUnit_L5_Trunk-t-2-2_AttnS3-3\n",
      " 3 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L4_Attn_S3-3 (Bat  (None, 8, 8, 512)   2048        ['SpcConv_Mask_L3_Attn_S3-3[0][0]\n",
      " chNormalization)                                                ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L7_Trunk-t-2-2_AttnS3-  (None, 8, 8, 128)   512         ['ResUnit_L6_Trunk-t-2-2_AttnS3-3\n",
      " 3 (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L5_Attn_S3-3 (Act  (None, 8, 8, 512)   0           ['SpcConv_Mask_L4_Attn_S3-3[0][0]\n",
      " ivation)                                                        ',                               \n",
      "                                                                  'SpcConv_Mask_L5_Attn_S3-3[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L8_Trunk-t-2-2_AttnS3-  (None, 8, 8, 128)   0           ['ResUnit_L7_Trunk-t-2-2_AttnS3-3\n",
      " 3 (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L9_Trunk-t-2-2_AttnS3-  (None, 8, 8, 512)   65536       ['ResUnit_L8_Trunk-t-2-2_AttnS3-3\n",
      " 3 (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_Trunk-t-2-2_AttnS3  (None, 8, 8, 512)   262144      ['ResUnit_L2_Trunk-t-2-2_AttnS3-3\n",
      " -3 (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " SpcConv_Mask_L7_Attn_S3-3 (Act  (None, 8, 8, 512)   0           ['SpcConv_Mask_L5_Attn_S3-3[1][0]\n",
      " ivation)                                                        ']                               \n",
      "                                                                                                  \n",
      " ResUnit_L11_Trunk-t-2-2_AttnS3  (None, 8, 8, 512)   0           ['ResUnit_L9_Trunk-t-2-2_AttnS3-3\n",
      " -3 (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_Trunk-t-2-2_AttnS3-\n",
      "                                                                 3[0][0]']                        \n",
      "                                                                                                  \n",
      " Mult_L1_AttnS3-3 (Multiply)    (None, 8, 8, 512)    0           ['SpcConv_Mask_L7_Attn_S3-3[0][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'ResUnit_L11_Trunk-t-2-2_AttnS3-\n",
      "                                                                 3[0][0]']                        \n",
      "                                                                                                  \n",
      " Add_L1_AttnS3-3 (Add)          (None, 8, 8, 512)    0           ['Mult_L1_AttnS3-3[0][0]',       \n",
      "                                                                  'ResUnit_L11_Trunk-t-2-2_AttnS3-\n",
      "                                                                 3[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L1_Output-p-1-1_AttnS3  (None, 8, 8, 512)   2048        ['Add_L1_AttnS3-3[0][0]']        \n",
      " -3 (BatchNormalization)                                                                          \n",
      "                                                                                                  \n",
      " ResUnit_L2_Output-p-1-1_AttnS3  (None, 8, 8, 512)   0           ['ResUnit_L1_Output-p-1-1_AttnS3-\n",
      " -3 (Activation)                                                 3[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L3_Output-p-1-1_AttnS3  (None, 8, 8, 128)   65536       ['ResUnit_L2_Output-p-1-1_AttnS3-\n",
      " -3 (Conv2D)                                                     3[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L4_Output-p-1-1_AttnS3  (None, 8, 8, 128)   512         ['ResUnit_L3_Output-p-1-1_AttnS3-\n",
      " -3 (BatchNormalization)                                         3[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L5_Output-p-1-1_AttnS3  (None, 8, 8, 128)   0           ['ResUnit_L4_Output-p-1-1_AttnS3-\n",
      " -3 (Activation)                                                 3[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L6_Output-p-1-1_AttnS3  (None, 8, 8, 128)   147456      ['ResUnit_L5_Output-p-1-1_AttnS3-\n",
      " -3 (Conv2D)                                                     3[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L7_Output-p-1-1_AttnS3  (None, 8, 8, 128)   512         ['ResUnit_L6_Output-p-1-1_AttnS3-\n",
      " -3 (BatchNormalization)                                         3[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L8_Output-p-1-1_AttnS3  (None, 8, 8, 128)   0           ['ResUnit_L7_Output-p-1-1_AttnS3-\n",
      " -3 (Activation)                                                 3[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L9_Output-p-1-1_AttnS3  (None, 8, 8, 512)   65536       ['ResUnit_L8_Output-p-1-1_AttnS3-\n",
      " -3 (Conv2D)                                                     3[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L10_Output-p-1-1_AttnS  (None, 8, 8, 512)   262144      ['ResUnit_L2_Output-p-1-1_AttnS3-\n",
      " 3-3 (Conv2D)                                                    3[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L11_Output-p-1-1_AttnS  (None, 8, 8, 512)   0           ['ResUnit_L9_Output-p-1-1_AttnS3-\n",
      " 3-3 (Add)                                                       3[0][0]',                        \n",
      "                                                                  'ResUnit_L10_Output-p-1-1_AttnS3\n",
      "                                                                 -3[0][0]']                       \n",
      "                                                                                                  \n",
      " ResUnit_L1_NotAttnModule_4_NoD  (None, 8, 8, 512)   2048        ['ResUnit_L11_Output-p-1-1_AttnS3\n",
      " S (BatchNormalization)                                          -3[0][0]']                       \n",
      "                                                                                                  \n",
      " ResUnit_L2_NotAttnModule_4_NoD  (None, 8, 8, 512)   0           ['ResUnit_L1_NotAttnModule_4_NoDS\n",
      " S (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L3_NotAttnModule_4_NoD  (None, 8, 8, 256)   131072      ['ResUnit_L2_NotAttnModule_4_NoDS\n",
      " S (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L4_NotAttnModule_4_NoD  (None, 8, 8, 256)   1024        ['ResUnit_L3_NotAttnModule_4_NoDS\n",
      " S (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L5_NotAttnModule_4_NoD  (None, 8, 8, 256)   0           ['ResUnit_L4_NotAttnModule_4_NoDS\n",
      " S (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L6_NotAttnModule_4_NoD  (None, 8, 8, 256)   589824      ['ResUnit_L5_NotAttnModule_4_NoDS\n",
      " S (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L7_NotAttnModule_4_NoD  (None, 8, 8, 256)   1024        ['ResUnit_L6_NotAttnModule_4_NoDS\n",
      " S (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L8_NotAttnModule_4_NoD  (None, 8, 8, 256)   0           ['ResUnit_L7_NotAttnModule_4_NoDS\n",
      " S (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L9_NotAttnModule_4_NoD  (None, 8, 8, 1024)  262144      ['ResUnit_L8_NotAttnModule_4_NoDS\n",
      " S (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_NotAttnModule_4_No  (None, 8, 8, 1024)  524288      ['ResUnit_L2_NotAttnModule_4_NoDS\n",
      " DS (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L11_NotAttnModule_4_No  (None, 8, 8, 1024)  0           ['ResUnit_L9_NotAttnModule_4_NoDS\n",
      " DS (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_NotAttnModule_4_NoD\n",
      "                                                                 S[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L1_NotAttnModule_5_NoD  (None, 8, 8, 1024)  4096        ['ResUnit_L11_NotAttnModule_4_NoD\n",
      " S (BatchNormalization)                                          S[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L2_NotAttnModule_5_NoD  (None, 8, 8, 1024)  0           ['ResUnit_L1_NotAttnModule_5_NoDS\n",
      " S (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L3_NotAttnModule_5_NoD  (None, 8, 8, 256)   262144      ['ResUnit_L2_NotAttnModule_5_NoDS\n",
      " S (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L4_NotAttnModule_5_NoD  (None, 8, 8, 256)   1024        ['ResUnit_L3_NotAttnModule_5_NoDS\n",
      " S (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L5_NotAttnModule_5_NoD  (None, 8, 8, 256)   0           ['ResUnit_L4_NotAttnModule_5_NoDS\n",
      " S (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L6_NotAttnModule_5_NoD  (None, 8, 8, 256)   589824      ['ResUnit_L5_NotAttnModule_5_NoDS\n",
      " S (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L7_NotAttnModule_5_NoD  (None, 8, 8, 256)   1024        ['ResUnit_L6_NotAttnModule_5_NoDS\n",
      " S (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L8_NotAttnModule_5_NoD  (None, 8, 8, 256)   0           ['ResUnit_L7_NotAttnModule_5_NoDS\n",
      " S (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L9_NotAttnModule_5_NoD  (None, 8, 8, 1024)  262144      ['ResUnit_L8_NotAttnModule_5_NoDS\n",
      " S (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_NotAttnModule_5_No  (None, 8, 8, 1024)  1048576     ['ResUnit_L2_NotAttnModule_5_NoDS\n",
      " DS (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L11_NotAttnModule_5_No  (None, 8, 8, 1024)  0           ['ResUnit_L9_NotAttnModule_5_NoDS\n",
      " DS (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_NotAttnModule_5_NoD\n",
      "                                                                 S[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L1_NotAttnModule_6_NoD  (None, 8, 8, 1024)  4096        ['ResUnit_L11_NotAttnModule_5_NoD\n",
      " S (BatchNormalization)                                          S[0][0]']                        \n",
      "                                                                                                  \n",
      " ResUnit_L2_NotAttnModule_6_NoD  (None, 8, 8, 1024)  0           ['ResUnit_L1_NotAttnModule_6_NoDS\n",
      " S (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L3_NotAttnModule_6_NoD  (None, 8, 8, 256)   262144      ['ResUnit_L2_NotAttnModule_6_NoDS\n",
      " S (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L4_NotAttnModule_6_NoD  (None, 8, 8, 256)   1024        ['ResUnit_L3_NotAttnModule_6_NoDS\n",
      " S (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L5_NotAttnModule_6_NoD  (None, 8, 8, 256)   0           ['ResUnit_L4_NotAttnModule_6_NoDS\n",
      " S (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L6_NotAttnModule_6_NoD  (None, 8, 8, 256)   589824      ['ResUnit_L5_NotAttnModule_6_NoDS\n",
      " S (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L7_NotAttnModule_6_NoD  (None, 8, 8, 256)   1024        ['ResUnit_L6_NotAttnModule_6_NoDS\n",
      " S (BatchNormalization)                                          [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L8_NotAttnModule_6_NoD  (None, 8, 8, 256)   0           ['ResUnit_L7_NotAttnModule_6_NoDS\n",
      " S (Activation)                                                  [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L9_NotAttnModule_6_NoD  (None, 8, 8, 1024)  262144      ['ResUnit_L8_NotAttnModule_6_NoDS\n",
      " S (Conv2D)                                                      [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L10_NotAttnModule_6_No  (None, 8, 8, 1024)  1048576     ['ResUnit_L2_NotAttnModule_6_NoDS\n",
      " DS (Conv2D)                                                     [0][0]']                         \n",
      "                                                                                                  \n",
      " ResUnit_L11_NotAttnModule_6_No  (None, 8, 8, 1024)  0           ['ResUnit_L9_NotAttnModule_6_NoDS\n",
      " DS (Add)                                                        [0][0]',                         \n",
      "                                                                  'ResUnit_L10_NotAttnModule_6_NoD\n",
      "                                                                 S[0][0]']                        \n",
      "                                                                                                  \n",
      " BN_Out (BatchNormalization)    (None, 8, 8, 1024)   4096        ['ResUnit_L11_NotAttnModule_6_NoD\n",
      "                                                                 S[0][0]']                        \n",
      "                                                                                                  \n",
      " ReLU_Out (Activation)          (None, 8, 8, 1024)   0           ['BN_Out[0][0]']                 \n",
      "                                                                                                  \n",
      " AvgPool_Out (AveragePooling2D)  (None, 1, 1, 1024)  0           ['ReLU_Out[0][0]']               \n",
      "                                                                                                  \n",
      " Flatten_Out (Flatten)          (None, 1024)         0           ['AvgPool_Out[0][0]']            \n",
      "                                                                                                  \n",
      " Final_Out (Dense)              (None, 10)           10250       ['Flatten_Out[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18,159,722\n",
      "Trainable params: 18,104,298\n",
      "Non-trainable params: 55,424\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ran92 = ResidualAttentionModel_92(input_shape, output_classes, learning_type='ARL')\n",
    "\n",
    "model = ran92.return_Model()\n",
    "\n",
    "model.compile(tf.keras.optimizers.Adam(), \n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8acd0fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/ran92_v2_arl/graphs/ran92_v2_arl_modelsummary.txt\n"
     ]
    }
   ],
   "source": [
    "global summary_filename \n",
    "summary_filename = graph_path + '/{}'.format(model_name[1:]) + '_modelsummary.txt'\n",
    "print(summary_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77cf099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(summary_filename, 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02166486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# dot_img_file = '/tmp/ran56.png'\n",
    "# tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)\n",
    "\n",
    "# earlyStopping_TrainAcc = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=10)\n",
    "# callbacks = list()\n",
    "# callbacks.append(earlyStopping_TrainAcc)\n",
    "\n",
    "callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, monitor='accuracy'),\n",
    "          tf.keras.callbacks.ReduceLROnPlateau(patience=5,  monitor='loss'), tf.keras.callbacks.ModelCheckpoint(saved_model_path + '/ran92_v2_ARL_training', monitor='loss', verbose=1, save_best_only=True, mode='min')]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ba7ae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30ba24d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 1.9451 - accuracy: 0.2639\n",
      "Epoch 00001: loss improved from inf to 1.94513, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 224s 318ms/step - loss: 1.9451 - accuracy: 0.2639 - val_loss: 2.0165 - val_accuracy: 0.2671 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 1.6856 - accuracy: 0.3747\n",
      "Epoch 00002: loss improved from 1.94513 to 1.68561, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 185s 297ms/step - loss: 1.6856 - accuracy: 0.3747 - val_loss: 1.9259 - val_accuracy: 0.3390 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 1.5466 - accuracy: 0.4311\n",
      "Epoch 00003: loss improved from 1.68561 to 1.54657, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 189s 302ms/step - loss: 1.5466 - accuracy: 0.4311 - val_loss: 1.7457 - val_accuracy: 0.3899 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 1.4381 - accuracy: 0.4735\n",
      "Epoch 00004: loss improved from 1.54657 to 1.43805, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 189s 302ms/step - loss: 1.4381 - accuracy: 0.4735 - val_loss: 1.8319 - val_accuracy: 0.4148 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 1.3291 - accuracy: 0.5176\n",
      "Epoch 00005: loss improved from 1.43805 to 1.32915, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 187s 300ms/step - loss: 1.3291 - accuracy: 0.5176 - val_loss: 1.5711 - val_accuracy: 0.4871 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 1.2452 - accuracy: 0.5502\n",
      "Epoch 00006: loss improved from 1.32915 to 1.24519, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 187s 300ms/step - loss: 1.2452 - accuracy: 0.5502 - val_loss: 1.5052 - val_accuracy: 0.4965 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 1.1757 - accuracy: 0.5776\n",
      "Epoch 00007: loss improved from 1.24519 to 1.17568, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 187s 299ms/step - loss: 1.1757 - accuracy: 0.5776 - val_loss: 1.5076 - val_accuracy: 0.4861 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 1.1214 - accuracy: 0.5981\n",
      "Epoch 00008: loss improved from 1.17568 to 1.12141, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 184s 295ms/step - loss: 1.1214 - accuracy: 0.5981 - val_loss: 1.4784 - val_accuracy: 0.5041 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 1.0663 - accuracy: 0.6183\n",
      "Epoch 00009: loss improved from 1.12141 to 1.06626, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 186s 298ms/step - loss: 1.0663 - accuracy: 0.6183 - val_loss: 1.3280 - val_accuracy: 0.5681 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 1.0083 - accuracy: 0.6409\n",
      "Epoch 00010: loss improved from 1.06626 to 1.00834, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 186s 298ms/step - loss: 1.0083 - accuracy: 0.6409 - val_loss: 1.3430 - val_accuracy: 0.5625 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.9759 - accuracy: 0.6554\n",
      "Epoch 00011: loss improved from 1.00834 to 0.97586, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 301ms/step - loss: 0.9759 - accuracy: 0.6554 - val_loss: 1.3728 - val_accuracy: 0.5306 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.9271 - accuracy: 0.6730\n",
      "Epoch 00012: loss improved from 0.97586 to 0.92714, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 187s 300ms/step - loss: 0.9271 - accuracy: 0.6730 - val_loss: 1.2554 - val_accuracy: 0.5912 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.8790 - accuracy: 0.6930\n",
      "Epoch 00013: loss improved from 0.92714 to 0.87898, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 186s 297ms/step - loss: 0.8790 - accuracy: 0.6930 - val_loss: 1.1764 - val_accuracy: 0.5885 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.8405 - accuracy: 0.7035\n",
      "Epoch 00014: loss improved from 0.87898 to 0.84052, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 184s 295ms/step - loss: 0.8405 - accuracy: 0.7035 - val_loss: 1.2516 - val_accuracy: 0.6136 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.7998 - accuracy: 0.7180\n",
      "Epoch 00015: loss improved from 0.84052 to 0.79981, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 185s 296ms/step - loss: 0.7998 - accuracy: 0.7180 - val_loss: 1.1765 - val_accuracy: 0.5970 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.7646 - accuracy: 0.7329\n",
      "Epoch 00016: loss improved from 0.79981 to 0.76458, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 185s 296ms/step - loss: 0.7646 - accuracy: 0.7329 - val_loss: 1.0273 - val_accuracy: 0.6454 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.7333 - accuracy: 0.7446\n",
      "Epoch 00017: loss improved from 0.76458 to 0.73326, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 184s 294ms/step - loss: 0.7333 - accuracy: 0.7446 - val_loss: 1.0937 - val_accuracy: 0.6276 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.7016 - accuracy: 0.7552\n",
      "Epoch 00018: loss improved from 0.73326 to 0.70159, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 185s 297ms/step - loss: 0.7016 - accuracy: 0.7552 - val_loss: 0.9756 - val_accuracy: 0.6523 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.6917 - accuracy: 0.7591\n",
      "Epoch 00019: loss improved from 0.70159 to 0.69174, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 186s 297ms/step - loss: 0.6917 - accuracy: 0.7591 - val_loss: 0.9555 - val_accuracy: 0.6878 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.6559 - accuracy: 0.7729\n",
      "Epoch 00020: loss improved from 0.69174 to 0.65593, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 185s 296ms/step - loss: 0.6559 - accuracy: 0.7729 - val_loss: 0.8526 - val_accuracy: 0.7030 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.6383 - accuracy: 0.7776\n",
      "Epoch 00021: loss improved from 0.65593 to 0.63828, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 185s 296ms/step - loss: 0.6383 - accuracy: 0.7776 - val_loss: 0.7903 - val_accuracy: 0.7217 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.6136 - accuracy: 0.7873\n",
      "Epoch 00022: loss improved from 0.63828 to 0.61362, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 185s 297ms/step - loss: 0.6136 - accuracy: 0.7873 - val_loss: 0.9562 - val_accuracy: 0.6822 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.5980 - accuracy: 0.7940\n",
      "Epoch 00023: loss improved from 0.61362 to 0.59804, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 184s 294ms/step - loss: 0.5980 - accuracy: 0.7940 - val_loss: 0.9152 - val_accuracy: 0.6965 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.5832 - accuracy: 0.7986\n",
      "Epoch 00024: loss improved from 0.59804 to 0.58323, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 183s 293ms/step - loss: 0.5832 - accuracy: 0.7986 - val_loss: 1.1901 - val_accuracy: 0.6463 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.5645 - accuracy: 0.8059\n",
      "Epoch 00025: loss improved from 0.58323 to 0.56445, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 183s 293ms/step - loss: 0.5645 - accuracy: 0.8059 - val_loss: 0.7875 - val_accuracy: 0.7348 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.5469 - accuracy: 0.8104\n",
      "Epoch 00026: loss improved from 0.56445 to 0.54691, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 183s 293ms/step - loss: 0.5469 - accuracy: 0.8104 - val_loss: 0.7925 - val_accuracy: 0.7298 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.5312 - accuracy: 0.8163\n",
      "Epoch 00027: loss improved from 0.54691 to 0.53119, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 183s 293ms/step - loss: 0.5312 - accuracy: 0.8163 - val_loss: 0.8843 - val_accuracy: 0.7114 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.5217 - accuracy: 0.8216\n",
      "Epoch 00028: loss improved from 0.53119 to 0.52174, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 183s 293ms/step - loss: 0.5217 - accuracy: 0.8216 - val_loss: 1.2924 - val_accuracy: 0.6398 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.5098 - accuracy: 0.8238\n",
      "Epoch 00029: loss improved from 0.52174 to 0.50977, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 191s 305ms/step - loss: 0.5098 - accuracy: 0.8238 - val_loss: 0.7783 - val_accuracy: 0.7290 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.4974 - accuracy: 0.8288\n",
      "Epoch 00030: loss improved from 0.50977 to 0.49743, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 194s 311ms/step - loss: 0.4974 - accuracy: 0.8288 - val_loss: 0.8056 - val_accuracy: 0.7252 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.4809 - accuracy: 0.8336\n",
      "Epoch 00031: loss improved from 0.49743 to 0.48087, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 187s 300ms/step - loss: 0.4809 - accuracy: 0.8336 - val_loss: 0.8011 - val_accuracy: 0.7357 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.4707 - accuracy: 0.8372\n",
      "Epoch 00032: loss improved from 0.48087 to 0.47068, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 187s 300ms/step - loss: 0.4707 - accuracy: 0.8372 - val_loss: 0.9409 - val_accuracy: 0.6955 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.4510 - accuracy: 0.8431\n",
      "Epoch 00033: loss improved from 0.47068 to 0.45097, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 302ms/step - loss: 0.4510 - accuracy: 0.8431 - val_loss: 1.0885 - val_accuracy: 0.6898 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.4477 - accuracy: 0.8445\n",
      "Epoch 00034: loss improved from 0.45097 to 0.44771, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 301ms/step - loss: 0.4477 - accuracy: 0.8445 - val_loss: 0.6497 - val_accuracy: 0.7690 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.4360 - accuracy: 0.8498\n",
      "Epoch 00035: loss improved from 0.44771 to 0.43597, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 187s 300ms/step - loss: 0.4360 - accuracy: 0.8498 - val_loss: 0.6979 - val_accuracy: 0.7673 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.4308 - accuracy: 0.8502\n",
      "Epoch 00036: loss improved from 0.43597 to 0.43078, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 301ms/step - loss: 0.4308 - accuracy: 0.8502 - val_loss: 0.7097 - val_accuracy: 0.7520 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.4197 - accuracy: 0.8565\n",
      "Epoch 00037: loss improved from 0.43078 to 0.41971, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 301ms/step - loss: 0.4197 - accuracy: 0.8565 - val_loss: 0.8039 - val_accuracy: 0.7418 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.4165 - accuracy: 0.8554\n",
      "Epoch 00038: loss improved from 0.41971 to 0.41646, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 300ms/step - loss: 0.4165 - accuracy: 0.8554 - val_loss: 0.6994 - val_accuracy: 0.7630 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.4119 - accuracy: 0.8571\n",
      "Epoch 00039: loss improved from 0.41646 to 0.41191, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 301ms/step - loss: 0.4119 - accuracy: 0.8571 - val_loss: 0.5805 - val_accuracy: 0.7994 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3979 - accuracy: 0.8645\n",
      "Epoch 00040: loss improved from 0.41191 to 0.39785, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 300ms/step - loss: 0.3979 - accuracy: 0.8645 - val_loss: 0.8645 - val_accuracy: 0.7488 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3944 - accuracy: 0.8625\n",
      "Epoch 00041: loss improved from 0.39785 to 0.39440, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 186s 297ms/step - loss: 0.3944 - accuracy: 0.8625 - val_loss: 0.6663 - val_accuracy: 0.7766 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3913 - accuracy: 0.8656\n",
      "Epoch 00042: loss improved from 0.39440 to 0.39130, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 187s 299ms/step - loss: 0.3913 - accuracy: 0.8656 - val_loss: 0.8369 - val_accuracy: 0.7432 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3736 - accuracy: 0.8709\n",
      "Epoch 00043: loss improved from 0.39130 to 0.37355, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 186s 297ms/step - loss: 0.3736 - accuracy: 0.8709 - val_loss: 0.6585 - val_accuracy: 0.7807 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3666 - accuracy: 0.8730\n",
      "Epoch 00044: loss improved from 0.37355 to 0.36658, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 186s 297ms/step - loss: 0.3666 - accuracy: 0.8730 - val_loss: 0.6979 - val_accuracy: 0.7756 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3620 - accuracy: 0.8730\n",
      "Epoch 00045: loss improved from 0.36658 to 0.36201, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 301ms/step - loss: 0.3620 - accuracy: 0.8730 - val_loss: 0.5444 - val_accuracy: 0.8172 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3554 - accuracy: 0.8765\n",
      "Epoch 00046: loss improved from 0.36201 to 0.35537, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 301ms/step - loss: 0.3554 - accuracy: 0.8765 - val_loss: 0.7081 - val_accuracy: 0.7793 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3467 - accuracy: 0.8799\n",
      "Epoch 00047: loss improved from 0.35537 to 0.34673, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 302ms/step - loss: 0.3467 - accuracy: 0.8799 - val_loss: 0.6568 - val_accuracy: 0.7817 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3380 - accuracy: 0.8815\n",
      "Epoch 00048: loss improved from 0.34673 to 0.33798, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 300ms/step - loss: 0.3380 - accuracy: 0.8815 - val_loss: 0.5217 - val_accuracy: 0.8246 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3366 - accuracy: 0.8836\n",
      "Epoch 00049: loss improved from 0.33798 to 0.33660, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 301ms/step - loss: 0.3366 - accuracy: 0.8836 - val_loss: 0.7343 - val_accuracy: 0.7561 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3337 - accuracy: 0.8829\n",
      "Epoch 00050: loss improved from 0.33660 to 0.33375, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 301ms/step - loss: 0.3337 - accuracy: 0.8829 - val_loss: 0.6146 - val_accuracy: 0.7980 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3257 - accuracy: 0.8872\n",
      "Epoch 00051: loss improved from 0.33375 to 0.32570, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 187s 300ms/step - loss: 0.3257 - accuracy: 0.8872 - val_loss: 0.6374 - val_accuracy: 0.7919 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3194 - accuracy: 0.8892\n",
      "Epoch 00052: loss improved from 0.32570 to 0.31943, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 301ms/step - loss: 0.3194 - accuracy: 0.8892 - val_loss: 0.8328 - val_accuracy: 0.7475 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3177 - accuracy: 0.8887\n",
      "Epoch 00053: loss improved from 0.31943 to 0.31774, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 301ms/step - loss: 0.3177 - accuracy: 0.8887 - val_loss: 0.7395 - val_accuracy: 0.7628 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3075 - accuracy: 0.8928\n",
      "Epoch 00054: loss improved from 0.31774 to 0.30755, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 189s 302ms/step - loss: 0.3075 - accuracy: 0.8928 - val_loss: 0.6393 - val_accuracy: 0.7913 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3114 - accuracy: 0.8920\n",
      "Epoch 00055: loss did not improve from 0.30755\n",
      "625/625 [==============================] - 151s 242ms/step - loss: 0.3114 - accuracy: 0.8920 - val_loss: 0.5768 - val_accuracy: 0.8033 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.3008 - accuracy: 0.8959\n",
      "Epoch 00056: loss improved from 0.30755 to 0.30076, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 301ms/step - loss: 0.3008 - accuracy: 0.8959 - val_loss: 0.5931 - val_accuracy: 0.8002 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2953 - accuracy: 0.8976\n",
      "Epoch 00057: loss improved from 0.30076 to 0.29534, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 189s 303ms/step - loss: 0.2953 - accuracy: 0.8976 - val_loss: 0.6213 - val_accuracy: 0.7981 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2917 - accuracy: 0.8981\n",
      "Epoch 00058: loss improved from 0.29534 to 0.29174, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 189s 302ms/step - loss: 0.2917 - accuracy: 0.8981 - val_loss: 0.4789 - val_accuracy: 0.8381 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2839 - accuracy: 0.9011\n",
      "Epoch 00059: loss improved from 0.29174 to 0.28389, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 301ms/step - loss: 0.2839 - accuracy: 0.9011 - val_loss: 0.5277 - val_accuracy: 0.8256 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2812 - accuracy: 0.9041\n",
      "Epoch 00060: loss improved from 0.28389 to 0.28119, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 301ms/step - loss: 0.2812 - accuracy: 0.9041 - val_loss: 0.5543 - val_accuracy: 0.8180 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2779 - accuracy: 0.9038\n",
      "Epoch 00061: loss improved from 0.28119 to 0.27790, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 186s 297ms/step - loss: 0.2779 - accuracy: 0.9038 - val_loss: 0.5764 - val_accuracy: 0.8114 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2731 - accuracy: 0.9057\n",
      "Epoch 00062: loss improved from 0.27790 to 0.27308, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 187s 299ms/step - loss: 0.2731 - accuracy: 0.9057 - val_loss: 0.6470 - val_accuracy: 0.7986 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2712 - accuracy: 0.9045\n",
      "Epoch 00063: loss improved from 0.27308 to 0.27117, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 186s 297ms/step - loss: 0.2712 - accuracy: 0.9045 - val_loss: 0.5992 - val_accuracy: 0.8094 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2674 - accuracy: 0.9053\n",
      "Epoch 00064: loss improved from 0.27117 to 0.26736, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 187s 300ms/step - loss: 0.2674 - accuracy: 0.9053 - val_loss: 0.5963 - val_accuracy: 0.8036 - lr: 0.0010\n",
      "Epoch 65/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2595 - accuracy: 0.9077\n",
      "Epoch 00065: loss improved from 0.26736 to 0.25952, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 186s 298ms/step - loss: 0.2595 - accuracy: 0.9077 - val_loss: 0.6391 - val_accuracy: 0.7955 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2570 - accuracy: 0.9109\n",
      "Epoch 00066: loss improved from 0.25952 to 0.25699, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 187s 299ms/step - loss: 0.2570 - accuracy: 0.9109 - val_loss: 0.4739 - val_accuracy: 0.8435 - lr: 0.0010\n",
      "Epoch 67/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2568 - accuracy: 0.9117\n",
      "Epoch 00067: loss improved from 0.25699 to 0.25678, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 186s 298ms/step - loss: 0.2568 - accuracy: 0.9117 - val_loss: 0.5505 - val_accuracy: 0.8200 - lr: 0.0010\n",
      "Epoch 68/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2449 - accuracy: 0.9130\n",
      "Epoch 00068: loss improved from 0.25678 to 0.24492, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 187s 300ms/step - loss: 0.2449 - accuracy: 0.9130 - val_loss: 0.5973 - val_accuracy: 0.8140 - lr: 0.0010\n",
      "Epoch 69/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2485 - accuracy: 0.9134\n",
      "Epoch 00069: loss did not improve from 0.24492\n",
      "625/625 [==============================] - 150s 240ms/step - loss: 0.2485 - accuracy: 0.9134 - val_loss: 0.6453 - val_accuracy: 0.7998 - lr: 0.0010\n",
      "Epoch 70/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2499 - accuracy: 0.9134\n",
      "Epoch 00070: loss did not improve from 0.24492\n",
      "625/625 [==============================] - 151s 242ms/step - loss: 0.2499 - accuracy: 0.9134 - val_loss: 0.5585 - val_accuracy: 0.8191 - lr: 0.0010\n",
      "Epoch 71/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2416 - accuracy: 0.9156\n",
      "Epoch 00071: loss improved from 0.24492 to 0.24161, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 300ms/step - loss: 0.2416 - accuracy: 0.9156 - val_loss: 0.6274 - val_accuracy: 0.8073 - lr: 0.0010\n",
      "Epoch 72/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2409 - accuracy: 0.9161\n",
      "Epoch 00072: loss improved from 0.24161 to 0.24091, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 301ms/step - loss: 0.2409 - accuracy: 0.9161 - val_loss: 0.5963 - val_accuracy: 0.8078 - lr: 0.0010\n",
      "Epoch 73/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2325 - accuracy: 0.9191\n",
      "Epoch 00073: loss improved from 0.24091 to 0.23246, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 300ms/step - loss: 0.2325 - accuracy: 0.9191 - val_loss: 0.5506 - val_accuracy: 0.8267 - lr: 0.0010\n",
      "Epoch 74/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2368 - accuracy: 0.9180\n",
      "Epoch 00074: loss did not improve from 0.23246\n",
      "625/625 [==============================] - 151s 242ms/step - loss: 0.2368 - accuracy: 0.9180 - val_loss: 0.4849 - val_accuracy: 0.8431 - lr: 0.0010\n",
      "Epoch 75/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2324 - accuracy: 0.9191\n",
      "Epoch 00075: loss improved from 0.23246 to 0.23239, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 301ms/step - loss: 0.2324 - accuracy: 0.9191 - val_loss: 0.5647 - val_accuracy: 0.8234 - lr: 0.0010\n",
      "Epoch 76/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2242 - accuracy: 0.9226\n",
      "Epoch 00076: loss improved from 0.23239 to 0.22424, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 190s 304ms/step - loss: 0.2242 - accuracy: 0.9226 - val_loss: 0.5106 - val_accuracy: 0.8330 - lr: 0.0010\n",
      "Epoch 77/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2207 - accuracy: 0.9233\n",
      "Epoch 00077: loss improved from 0.22424 to 0.22071, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 301ms/step - loss: 0.2207 - accuracy: 0.9233 - val_loss: 0.4925 - val_accuracy: 0.8408 - lr: 0.0010\n",
      "Epoch 78/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2218 - accuracy: 0.9226\n",
      "Epoch 00078: loss did not improve from 0.22071\n",
      "625/625 [==============================] - 151s 241ms/step - loss: 0.2218 - accuracy: 0.9226 - val_loss: 0.5399 - val_accuracy: 0.8275 - lr: 0.0010\n",
      "Epoch 79/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2162 - accuracy: 0.9250\n",
      "Epoch 00079: loss improved from 0.22071 to 0.21618, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 189s 302ms/step - loss: 0.2162 - accuracy: 0.9250 - val_loss: 0.4744 - val_accuracy: 0.8515 - lr: 0.0010\n",
      "Epoch 80/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2141 - accuracy: 0.9257\n",
      "Epoch 00080: loss improved from 0.21618 to 0.21408, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 300ms/step - loss: 0.2141 - accuracy: 0.9257 - val_loss: 0.5960 - val_accuracy: 0.8256 - lr: 0.0010\n",
      "Epoch 81/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2133 - accuracy: 0.9250\n",
      "Epoch 00081: loss improved from 0.21408 to 0.21327, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 300ms/step - loss: 0.2133 - accuracy: 0.9250 - val_loss: 0.5096 - val_accuracy: 0.8364 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2036 - accuracy: 0.9287\n",
      "Epoch 00082: loss improved from 0.21327 to 0.20364, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 300ms/step - loss: 0.2036 - accuracy: 0.9287 - val_loss: 0.5848 - val_accuracy: 0.8195 - lr: 0.0010\n",
      "Epoch 83/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2070 - accuracy: 0.9279\n",
      "Epoch 00083: loss did not improve from 0.20364\n",
      "625/625 [==============================] - 151s 242ms/step - loss: 0.2070 - accuracy: 0.9279 - val_loss: 0.5629 - val_accuracy: 0.8282 - lr: 0.0010\n",
      "Epoch 84/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2043 - accuracy: 0.9292\n",
      "Epoch 00084: loss did not improve from 0.20364\n",
      "625/625 [==============================] - 151s 242ms/step - loss: 0.2043 - accuracy: 0.9292 - val_loss: 0.5681 - val_accuracy: 0.8191 - lr: 0.0010\n",
      "Epoch 85/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2048 - accuracy: 0.9292\n",
      "Epoch 00085: loss did not improve from 0.20364\n",
      "625/625 [==============================] - 151s 242ms/step - loss: 0.2048 - accuracy: 0.9292 - val_loss: 0.6243 - val_accuracy: 0.8174 - lr: 0.0010\n",
      "Epoch 86/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1986 - accuracy: 0.9313\n",
      "Epoch 00086: loss improved from 0.20364 to 0.19862, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 301ms/step - loss: 0.1986 - accuracy: 0.9313 - val_loss: 0.7944 - val_accuracy: 0.7750 - lr: 0.0010\n",
      "Epoch 87/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1914 - accuracy: 0.9327\n",
      "Epoch 00087: loss improved from 0.19862 to 0.19141, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 189s 302ms/step - loss: 0.1914 - accuracy: 0.9327 - val_loss: 0.5954 - val_accuracy: 0.8240 - lr: 0.0010\n",
      "Epoch 88/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.2016 - accuracy: 0.9294\n",
      "Epoch 00088: loss did not improve from 0.19141\n",
      "625/625 [==============================] - 151s 242ms/step - loss: 0.2016 - accuracy: 0.9294 - val_loss: 0.5009 - val_accuracy: 0.8439 - lr: 0.0010\n",
      "Epoch 89/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1868 - accuracy: 0.9355\n",
      "Epoch 00089: loss improved from 0.19141 to 0.18679, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 188s 301ms/step - loss: 0.1868 - accuracy: 0.9355 - val_loss: 0.5189 - val_accuracy: 0.8368 - lr: 0.0010\n",
      "Epoch 90/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1883 - accuracy: 0.9340\n",
      "Epoch 00090: loss did not improve from 0.18679\n",
      "625/625 [==============================] - 155s 247ms/step - loss: 0.1883 - accuracy: 0.9340 - val_loss: 0.5817 - val_accuracy: 0.8240 - lr: 0.0010\n",
      "Epoch 91/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1918 - accuracy: 0.9342\n",
      "Epoch 00091: loss did not improve from 0.18679\n",
      "625/625 [==============================] - 153s 245ms/step - loss: 0.1918 - accuracy: 0.9342 - val_loss: 0.5153 - val_accuracy: 0.8410 - lr: 0.0010\n",
      "Epoch 92/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1820 - accuracy: 0.9368\n",
      "Epoch 00092: loss improved from 0.18679 to 0.18204, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 191s 306ms/step - loss: 0.1820 - accuracy: 0.9368 - val_loss: 0.6251 - val_accuracy: 0.8072 - lr: 0.0010\n",
      "Epoch 93/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1848 - accuracy: 0.9344\n",
      "Epoch 00093: loss did not improve from 0.18204\n",
      "625/625 [==============================] - 154s 246ms/step - loss: 0.1848 - accuracy: 0.9344 - val_loss: 0.5031 - val_accuracy: 0.8509 - lr: 0.0010\n",
      "Epoch 94/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1796 - accuracy: 0.9369\n",
      "Epoch 00094: loss improved from 0.18204 to 0.17959, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 200s 321ms/step - loss: 0.1796 - accuracy: 0.9369 - val_loss: 0.5387 - val_accuracy: 0.8365 - lr: 0.0010\n",
      "Epoch 95/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1781 - accuracy: 0.9379\n",
      "Epoch 00095: loss improved from 0.17959 to 0.17813, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 190s 304ms/step - loss: 0.1781 - accuracy: 0.9379 - val_loss: 0.6957 - val_accuracy: 0.8064 - lr: 0.0010\n",
      "Epoch 96/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1792 - accuracy: 0.9364\n",
      "Epoch 00096: loss did not improve from 0.17813\n",
      "625/625 [==============================] - 156s 249ms/step - loss: 0.1792 - accuracy: 0.9364 - val_loss: 0.4196 - val_accuracy: 0.8671 - lr: 0.0010\n",
      "Epoch 97/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1752 - accuracy: 0.9391\n",
      "Epoch 00097: loss improved from 0.17813 to 0.17520, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 243s 389ms/step - loss: 0.1752 - accuracy: 0.9391 - val_loss: 0.5277 - val_accuracy: 0.8382 - lr: 0.0010\n",
      "Epoch 98/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1722 - accuracy: 0.9393\n",
      "Epoch 00098: loss improved from 0.17520 to 0.17225, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 199s 318ms/step - loss: 0.1722 - accuracy: 0.9393 - val_loss: 0.5462 - val_accuracy: 0.8303 - lr: 0.0010\n",
      "Epoch 99/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1691 - accuracy: 0.9399\n",
      "Epoch 00099: loss improved from 0.17225 to 0.16911, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 190s 303ms/step - loss: 0.1691 - accuracy: 0.9399 - val_loss: 0.4597 - val_accuracy: 0.8508 - lr: 0.0010\n",
      "Epoch 100/100\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.1637 - accuracy: 0.9428\n",
      "Epoch 00100: loss improved from 0.16911 to 0.16371, saving model to ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models\\ran92_v2_ARL_training\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 187s 299ms/step - loss: 0.1637 - accuracy: 0.9428 - val_loss: 0.4724 - val_accuracy: 0.8536 - lr: 0.0010\n",
      "took 18376.023104667664 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "st = time.time()\n",
    "ran92_v2_history = model.fit(datagen.flow(X_train, y_train, batch_size=64, subset='training'), validation_data=datagen.flow(X_train, y_train, batch_size=64, subset='validation'),\n",
    "                    epochs=100, callbacks=callbacks)\n",
    "\n",
    "ed = time.time()\n",
    "print(f\"took {ed-st} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a0106c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "054bef46",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)\n",
    "preds = np.argmax(preds, axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eef36417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90      1000\n",
      "           1       0.89      0.97      0.93      1000\n",
      "           2       0.92      0.77      0.84      1000\n",
      "           3       0.80      0.75      0.78      1000\n",
      "           4       0.87      0.86      0.86      1000\n",
      "           5       0.88      0.76      0.82      1000\n",
      "           6       0.83      0.95      0.88      1000\n",
      "           7       0.79      0.96      0.86      1000\n",
      "           8       0.94      0.92      0.93      1000\n",
      "           9       0.94      0.90      0.92      1000\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.88      0.87      0.87     10000\n",
      "weighted avg       0.88      0.87      0.87     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_true, preds)\n",
    "cr=  classification_report(y_true, preds)\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(cr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36c97add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/ran92_v2_arl/graphs/ran92_v2_Loss.png\n",
      "./models/ran92_v2_arl/graphs/ran92_v2_Accuracy.png\n"
     ]
    }
   ],
   "source": [
    "plot_loss_filename = graph_path + '/ran92_v2_Loss.png'\n",
    "print(plot_loss_filename)\n",
    "plot_acc_filename = graph_path + '/ran92_v2_Accuracy.png'\n",
    "print(plot_acc_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa9f67ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "plt.title(\"Attention 92, v2: Training Loss vs. Validation Loss\", fontsize=18)\n",
    "plt.plot(ran92_v2_history.history['loss'], label='training loss', color='red')\n",
    "plt.plot(ran92_v2_history.history['val_loss'], label = 'validation loss', color='blue')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.savefig(plot_loss_filename)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "635e8da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAALQCAYAAABCCScvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAADiGElEQVR4nOzdd3hUVfrA8e+ZmfTee0ILkNB7ERu4YhdRrKjY66prL7tr7733ggUVRfGnaxdRFKR3CCWQDunJpGfK/f1xZ2IIKZOQZJLwfp5nnkluPTP3zsx97znnPUrTNIQQQgghhBBCiN7E4O4CCCGEEEIIIYQQ7SXBrBBCCCGEEEKIXkeCWSGEEEIIIYQQvY4Es0IIIYQQQggheh0JZoUQQgghhBBC9DoSzAohhBBCCCGE6HUkmBVCuI1SaqlSKsPd5RDuo5TKUEotPYT15ymlNKXUMZ1WKCE6WXPneXu+/5RSxzjO83ldULZ+jm3f19nbFkKIribBrBC9hFIqRClV47jouLCFZUYrpe5TSvVrz7yupJS6qSsuwDqTUmqsUuorpVSxUqpWKbXVUW5jk+VClFI3KqV+VEplO47HDqXUG0qphG4u71NKqXVKqVLHY7VS6lqllMchbHep4/xy5TGvE19Sn6KUetzxHu1yd1mEa5RS1zmO2U1tLDffsdzUbipap3AErPcppUa7uyyuUEp96niff3F3WYQQPZvSNM3dZRBCuEApdT3wApABZGqadmwzy8wD3gWO1TRtqavzupKj5iFD07Rjmpnnif49VNdd5WmmDEcBPwLlwCtAIfAPYBbwpqZpVzZa9gTgG+AXYAlQBAwHrgLqgamapm3rhjJ/AhwHLAbWAkbgFGCm47WcoHXgy10p9Q8gqtGkcOBZYBnwRpPFl2uatqfdhT94n16ApmlafQfXNwIeQL2mafZDLc+hUkqZgGygChgIHKNp2m/uLZVoi1IqGNgH7NQ0bVQLywQA+4EsTdNS2rn9DJp8D7bn+8/R8uBX4BJN095rz77bWl8ppQAvwKppmrW92+5sSqkwIA/9czQAGKBpWoZbCyWE6LFM7i6AEMJll6FfjHwFPKeUGtAZwYQ7dTSA6WQvAHZgSqP38xWl1OvAlUqp9zVN+8MxPQ0YomlaeuMNKKX+B/wEPACc1Q1lfhGYp2labaNpLymlPgQuAE5GD7rbRdO0nxr/76jFfxbYo2nah62tq5TyASztvRg+1BsZmqbZANuhbKOTnQxEAzOAj4FLgR4fzCqlAjRNq3B3OdxF07QypdQXwPlKqbGapq1rZrGzAV/gnU7aZ0/4/sNx46u2zQW7z1z0G1TnACuAS4B73VoiFxzunyEh3EWaGQvRCyilxgKjgfnAAsCKfpHceJn70GteAX5t1Bz0vdbmNVrfSyl1t6OJba1Sqkwp9bVSakyT/TT03VJKXeJYvk4plamUur3JshqQBBzdpIlqP8f8ZvuMKaWOUkr9pJQqdzTlXaeUuqyZ5ZYqvS9arFLqY0dz22ql1A9KqcEuvK8hwCjg92ZuDDjfm0ucEzRNy2gayDqm/wyUoNfStptSKtjxnn/RwvxHHe/baMf+/mwSyDp96ng+oBxKqXCl1FClVFBHytdMed5zlCdCKfWOUiofvSYy3jH/WqU3xc5VStUrpfYppT5UzTd/b64vYYbj2A5VSv1PKVXhOBc+V0pFN1n2oD6zjaZNV0rdqpRKd5yjO5VSFzdTBqNS6j+Oc7hWKbVJKXWO0ptlas2VuxWXAXvQbzx9BJyllAps4X0co5T6TCmV7yhftuM8HthkuWMd74OzGfwepdTbSqlwx/wW+1M6j1WTac7PzQDHe1oCmB3zDEqpe5RSvyul9juOX5ZS6lWl15g19zrOdGyzzPH526GUekEp5el4jZpS6uEW1v2fUsqslPJr6Q1VSq10vEcH3YBXSs1UjZoHO8p/k+MYVji2vcPxfrXVBP9tx/OlLcy/FP27933Hvlw+z1t4XS19/52ulFrvONbZSqkH0YO7pssFKKUecrw/RY5zaLdS6jGllG+j5eahn48A76q/v4eXOuY322dWKWVSSt2hlNrmKEuxUupLpdSIJss1rK+UOkXpXR5qHe/Hk80dtzZcBizVNG0t+k25eUqpZq9X2/psNFquxXPU+R6pFvreN3ec1N/fUWOU/ntTDmxyzHPpuDTallJKXeFYvtLx2KyUesAx/wxH2a5o4T3Y6ti+avOdFaIPkppZIXqHy4BKYJGmaVVKqW+Ai5VS/23UtPILIAa4EngE2O6Yno4eaLQ0D8dF3vfAVOAD4CUgCLgC+FMpdZSmaWualOlq9CapbwNl6HfTH1dK5WiatsCxzIXoNXtFQOOL2cKWXqhS6lTgS/TmfE8DFcC5wFtKr42+p8kqfsDvwF/A3UB/4EbgK6XUcEfNXUu8HM/VzcxzTpvcyvrOMgcBAcCWtpZtjqNW6P+A05VSoZqmlTTatgG9tnWTpmkb2thUvOM5v8n069FrNi7h7yC9M/yEfpweRD8OlY7pt6Ifjxf4O8i/HJiulBqhaVqxC9uOA5ainwu3od90uAoIBI53sXyPAD7A60AdcA3wnlJqt6ZpfzZa7iX08/lX4CkgAr3J+V4X9wOA0gPtE4GHNE1z3iz6F/r5+0aTZU8BFqF/Nt8CdqPX6M5Ef7+cn82rgFeBXMdzJpAInIp+vIvaU8ZG/NFrjP8E7gEiHdM90d/vReitQKqACejfQdOUUuMa1ygqPUi9G9iG/lnfh968+kzgv5qmrVdKreXv7ytbo3XjHK/3HU3Tqlop63zgZcDZzL+xi9ADTOd3zj3oLSS+Bl5Dr7XvD5yG/nm3tLKfX9GP+flKqVsatxpQ+s2xqcBXmqY5P1+dcZ4fQCl1Bvp7n+F4HVb0z+3JzSwe59jfIv6+yXk0cDswBv29Bf378RH04/QGercBOPh7oqmP0Gujf0I/96KB64AVSqkjNU1b32T5k4Br0d/3d4DT0d+jUsf+26SUmgCMAOY5Jr0HnIHereLHJsu69Nlo6xxF7yLSEYno3U0+Qz8G/o7prh4Xpw/Qv+NXov9OlgFD0Vv5/Bf9XN6PfjPlzSbvwWQgFbinI11LhOgTNE2Thzzk0YMfgDf6xcB7jaadDmjAiU2WneeYfkwz22lt3r8c82Y2mR4IZKHfJXdOO8axbB4Q1Gi6L3qQuqLJNjIar99k3lL0fmTO/43oFyRlQGyj6Z7oF902ILnJ+hpwe5Pt3tbc62lm/8pR5jzAp8m8mxzbMLtwjJ5wLHvpIRznkx3buLbJ9BmO6Te3sb4/eo1gGRDaZN59jm3Ma2eZ+jnWe6/J9Pcc0z9sYT2/ZqY5X0fTY3XQ+eGYpgFnN5n+smP6kNbO60bT1gOejabHoQe1HzeaNsyx7PeAodH0EY7zTQP6ufh+3YHeZL1/o2nrgZVNlnN+VgqAuGa2Y3A8xzvKuw0IbmW5Y1o6vs5j1cznTkMPupv7TPg0M/2ypscEmOiYtgTwbmY7zrwcVzqWO6nJMvc4pk9s430NdbwPC5tMD0APtv+v0bR1wLb2fv4arf+fFs69Rx3TT+vE83wpB3//ZaEHYeGNpgehfy8ecIzRvxc9minDg03f1zbOkX6Oefc1mvYPx7RPncfRMX0UenC2rJn1q2j0WXGcA1uAfe14/19Fvynm7/jfA/1z8mmT5Vz9bLh6js6j5d/HA45To+OpAZc3s3x7jsvZjmkf0Oj7p/FrcPz9iGO51CbLvOk4HrFN9ycPeRwuD2lmLETPNxsIRq+dcPoW/WK4peZw7TUXvT/oWqU3SQ13NNPyRL8rP03pfSIbe1fTtHLnP5qmVaPXUiQfQjnGod/tfkfTtLxG265HDxgN6IF8Y3b0mpHGljieWy2Lpmka+p36GOALpdQEpVR/R3Ou+9EvEg5qFtaYUuos9NqH7/m7KXdH/IBeU3JRk+nOmqePWimDEfgQvQbqGq1RzS6Apmn3aZqmtA4kjmnDU81N1By1bEpv8hnkOJc2oifZmuTitvM0TVvYZJpLx7WRV7RGtYiapuUCO5usf4rj+XmtUQIpTdM2ox+T9rgU/SJ/b6Np7wETlVLDGk2biZ5c62lHmQ7QqBxz0D+D92uaVtbKch110PHTdDXQ0Pw62HH8nO994+N3geP5Lq1Js3fHdjTHvwvQA5SGrgKOJpGXAps1TVvVWiEd5/PXwKlKT9TkdBb657Pxd2M5EKeUmtbaNlvxHvp3SkP3Asfn6yL02rFvG5WrM87zxsYBCejfrQ017o7v2deaLqxpWr2maRZHGUxKz7YeDvzsWKQjZXA6w/H8cKPjiKZpG9GPxTSlVESTdRZrjRI1Odb7FYhWSvnTBsdvzHnoLZAqHduwoH/3na6UCm20uKufDVfP0Y4ooZnv/HYeF2f5bm36eW7y/5vowWzjz5Afer/i7xr/XgpxuJFgVoie7zL0wDVHKTVIKTUIvR/qj8BpTfsGdVAKerOmwmYel6LXGDTdT3PJp4qBZvvVuai/43lrM/Oc0wY0mZ7X9CLFUQ5cLMtj6E27jgFWob+uZ/i7eZy5pRWVUiehX2itBc45lAsjTU+c9BEwydGk0XmxMhv4Ufu7aWPTMhj4u0nfPZqmfdzRMnTAzhbKNF3p/fGq0GuKnedSEBDi4rZbOr/A9XPMlXPUec7taGbZ5qY1Syl1JDAY+Nn5OXV8VleiB0eN+3w7g+n1bWzW1eU6orC5IABAKXW2UmolUIP+GSjk7/ey8fFLRr/A3tjajhyBycfowagzADoG/bP8dkvrNTEfvZXK2Y2mXeQo39eNpt2NnsxomdL7sn6klDrf2TeyLZqmZaN/tx7vaAYN+s2HWOB9rVGCs046zxtzfrelNTOv2SzpSu+3uwm9lrLEsf+ljtkdKYNTf/Tzdnsz87Y2WqaxQ/3MnoX+3v3W5DP0O3oT8bmNlm3PZ6jNc7SD0rUWurG047gko9dct9rk23GD7GfgQvV33++z0VsnvNXhVyBEHyDBrBA9mFKqP3Aseh++ncCuRo8L0O9Mz21xA+3YFbAZvWlZS4+m/Vx7SgbZ1srRZkIMTdPsmqb9Gz1Yn4LeLy4K/eI7nOYvLFH6MD1foF/YHa9pWotBbzu873h21s7ORm8+PL+5hR2B7FuO5e/XNM2lfmmdxVEb37RME9CDgWjgTvQg+3j0c6gY1393Dum4trGNrkiU4gxWH+DAz+kK9Nc8Vx3CGMBtaO0mSku5MZrrJ45SajZ/JxK7Eb3/4T/Q+6vCwcdPa2P/Tm+gNxl1ntuXoV/of+DCugDfoX8HXeQoZyJ6P8RPmtS+r0DvD3kWen/r0eg3iTY0qdlrzTvor/Nix/+XNJqOY/+ddZ53mFLqZvSm9/vQ+5Of7Nj/PMci3X2Nd6ifWedn6G0O/Aw5E+N1tCWSK+doZ36Guuq4vIF+LXCa4//L0FsL/K+D2xOiT5AEUEL0bJegXwRcgX7nv6mH0H/gn3P839oPcmvzdqH/SC7phKaL7dlvU847+8OamZfaZJlO5Wgy+Jfzf0fzYUWjZoWN5p2APsZrGnCcpmmlnVSGjUqpjeiBz3/QL9zLgP9rpgzOQPYS9L6P93VGGTrB+eg1+Sc2bm7rqGU+lJqirpLheB7CwefWEFc2oPTxR89Cb5LfdDxegJHofTFPQ08K46zRHk2TpDZNNF6u2VpwB2ez8uaCtaYtGdpyIXrN5rGNb1YopYa2UL4T0ftRttVUeI1Saj1wmVLqbfTkO4ubNolvZX2rUmoBcKNSagB6c1RFMzd6HDXBixwPlFLXogcXlwFPurC7r9AD0nlKH6LrNOBPTdMa19R3xXnuPP+ae69Tm5l2Ifr5e2Lj723H91NT7W01sgc96ErBkaW3mbLspZMoPYP3Ueg3HhY3s8gM4GpHArK1uP7ZcPUcbe0z1J/WE4c11Z7jshO9CXVUW7Wz6OdlAfpnaAtwBPC41gPGBhbCnaRmVogeyhGszEPvU/aWpmmfN32g1x6OcNQSwN/ZZJv7QW5t3vvoNQw3t1CWqI6+Dsd+Xa0RWYeeAOUS1WgIFkeNljOp01eHUBaXKH0IkkfQE7G81mTe8eg1PjuAGa5ejLfDfPRm5OcD09ETnxzQjNrR3/BN9ED2EU3T/tPaBlUnD83TBmftTNOamLvpmb85ziaqN6pGw38offiRpllHW3Iuejbn11r4nD6GXovjrFn6Ef3cukUpFdN0Y47jC/A5eqbVe1Uzw/s0Wm4ver/q45rMn4oL2bibcCa9avxeKODfzSzrzCD8SHPNeBuVz+lN9ODoRfQmw+1tHukMXC9CDxh2aJq2ssk+m+t24Rwz1qXvIUdN7wfoTUBfRW8B07Q5dFec52uBHPTvv4bX4Tj2VzezvPNYqUbLmtBriptq7fu/OYsdz3c1Po5KqeHowf0fmqa1mJW+Ay5Ffx3PtPAZerzRcuD6Z8PVc9QZEDf9DJ2H3sS8PdpzXJy5EJ5QTYYfavr5cfTDfQ/9e+lex2RXm+kL0WdJzawQPdfx6MlAWvuxWoSeqfYyYLXjYQfuUfoYqlXAXscFX2vznkdvBvWkUmo6erIXM3oyphk4amo6+Dr+Qr+T/CB6/ys78LXWzFAcmqbZlFLXoweLq5VSb6APzXMO+kX5I5qm7epgOZrl6Pd6G38PM5OEPqxCCHrm0qJGy45HD6YVeuKPE5ter2ua9mGj5fuhBxq/aZp2jItF+gg92dUr6BfFzTUxfhL9om4jsF0p1bSpebqjuaVTVw3N05wv0bNjf+s4fvXo59ZIOj6MTJfRNG2ro5xXovd3/RK9lcJ16P3xxtF2rdZl6MHq9y3so1op9R0wSykVp2lartLHTf4c2KKUcg7NE4F+ofoM+hAwOUofP/VlYLNS6n30rLZx6M1aLwU2aJpWqfRhgC5XSn2M3jcvGf14b0KvlXLV5+i1pksc+/MAZtFMIjRN01YppR5Hz+K8Tin1KfpnqD96TfVEDmxR8hH6uTsX/XPxSzvKhaYP87MZ/fwKRA8cm9qulPoLva9yHn8PSVYPfNKO3b2NntF8Dnog2DQZWaef547vv3859rVKKeXMVHspek1xYpNVPkfPsvyd0seoDkS/CdZcLeI29O/Sa5VS1ejHpUDTtCXNLIumaT8ppRai36gJUfpwcM6heWqBGzryGpuj9ARb89AzBq9rbhlN0zKUPsSTc9gkVz8bLp2jmqbtUEr9DFzlCCI3oNf6noH+2WxPFwGXj4umaZ85ynQRkKz0IdpK0fvfO4fpauxN9N+r89B/Vzr191CIXknrASmV5SEPeRz8QB+7TgNGtLHcDvQLEx/H/xejX7jU02RYlTbmmdAvUFajB7pV6M2PP0LvE+pc7hjaNwxIJHrQXYIeyGo4hm+gmSEPHNOPRg8uzegXTuuBy5pZrqX1+9FkqIlW3r9U9P54+xzvSx56rcyQZpadx9/9r5p9NFl+hGP6R+089l871tvZwvylbZTjvSbL39fSMWujHP1a2N5Bx7nJ/FnotUxV6Bf2n6BfiGfQ/DA8bU5r6dyj9aF5jmlmGwedM+jNRe9FbxVQhx4Ano2e7VcDIlt5rc6hfRa18V6e51ju7kbTJqLXgBU59puF/nkb0GTd49E/D+Xon4c96Be1YY2W8Uev6SxGD6yXoff/PuhYNfceNJl/Bfr3RC365+IN9Bq9g86FRq/tT/RgqQq9+f1zNBoWqdGybzu285/2nIuN1r/Fsb4NSGhm/p3oCYMKHO9pNvp36dgO7GulY19vd9F53uxxQO8rv6FR+R/k76FyGp/7RuAu9GCrDj2YewK99vug7z/0cWDXOY6r5iwPLXxfov8m3IF+E9KZyGgxTX6TWlrfMe8+Gn3nt/A+Oocle7qN43GXY7nz2/PZcPUcRQ/WP0P/3alE/11Iae44NXc8D+G4GNBvEqxD/+xWoH8H3dvC9n9xbOfCjnyG5CGPvvZwjq8lhBCikymlbkAPiIZrmtZavy7RAymlvkZv6h2otZC1VLSPUuoV9JrSfpqm5bi7PEL0Nkqpb9GTFcZqjmG0hDic9cT+S0II0VfMBF6XQLZnUwePoYxSaiR64pglEsh2Dkef7bno42JKICtEOyl9qKKZwIcSyAqhk5pZIYQQhzWl1NXofdb+hz78y1D02kMDcISmaevdWLxez5E0aAx6N4fp6O/pitbXEkI4KaUmoTdTvsHxnKJpWoZbCyVEDyEJoIQQQhzu1qEnerkBvW9oBXoStPslkO0UZ6H3Sc4FrpVAVoh2uwb9htse4AIJZIX4m9TMCiGEEEIIIYTodXp1zWx4eLjWr18/dxdDCCGEEEIIIUQXWLt2bZGmaRHNzevVwWy/fv1Ys2aNu4shhBBCCCGEEKILKKUyW5on2YyFEEIIIYQQQvQ6EswKIYQQQgghhOh1JJgVQgghhBBCCNHrSDArhBBCCCGEEKLX6dUJoFpit9vJycmhqqrK3UURhxkPDw8iIyMJDAx0d1GEEEIIIYTo0/pkMFtUVIRSiiFDhmAwSOWz6B6aplFTU0Nubi6ABLRCCCGEEEJ0oT4Z6ZWVlREVFSWBrOhWSil8fX2Ji4ujoKDA3cURQgghhBCiT+uT0Z7NZsPDw8PdxRCHKR8fHywWi7uLIYQQQgghRJ/WJ4NZ0GvJhHAHOfeEEEIIIYToen02mBVCCCGEEEII0XdJMNsLXX311Tz44IOdvqwQQgghhBBC9BZ9MptxT9avXz/eeustjjvuuA5v47XXXuuSZYUQQgghhBCit5Ca2R7GarW6uwi9grxPQgghhBBCHN4kmO1GF154IVlZWZx66qn4+/vzxBNPkJGRgVKKt99+m8TERKZPnw7AnDlziI6OJigoiKOOOoqtW7c2bGfevHn8+9//BmDp0qXEx8fz9NNPExkZSUxMDO+++26Hli0uLubUU08lMDCQCRMm8O9//5tp06a1+HpaK2NNTQ233HILSUlJBAUFMW3aNGpqagD4448/mDp1KsHBwSQkJPDee+8BcMwxx/DWW281bOO99947YP9KKV5++WWSk5NJTk4G4MYbbyQhIYHAwEDGjRvHsmXLGpa32Ww88sgjDBw4kICAAMaNG0d2djbXXXcdt9xyywGv5bTTTuPZZ59t7fAJIYQQQgghepDDopnxTd/fxIb9G7p0H6OjR/PcCc+1uswHH3zAsmXLDmhmnJGRAcBvv/3G9u3bG8bGPfHEE3nnnXfw9PTkjjvu4IILLmDDhg3Nbnf//v2Ul5eTm5vLTz/9xFlnncWsWbMICQlp17LXXXcdfn5+7N+/n4yMDGbOnElSUlKLr6e1Mt56661s3bqV5cuXEx0dzcqVKzEYDGRmZnLiiSfyxhtvcNZZZ2E2m8nOzm79zW1k8eLFrFy5Eh8fHwAmTJjAf//7X4KCgnj++eeZM2cOGRkZeHt788wzz/Dxxx/z7bffMnjwYDZt2oSvry8XX3wxs2bN4sknn8RgMFBUVMTPP//Mm2++6XI5hBBCCCGEEO4lNbM9xH333Yefn19DkHbppZcSEBCAl5cX9913Hxs3bqS8vLzZdT08PPjvf/+Lh4cHJ510Ev7+/uzYsaNdy9psNhYtWsT999+Pr68vqampXHzxxa2WuaUy2u123nnnHZ5//nni4uIwGo1MnToVLy8vFixYwHHHHcd5552Hh4cHYWFhjB492uX36a677iI0NLThfZo7dy5hYWGYTCZuueUW6urqGl77W2+9xUMPPcSQIUNQSjFq1CjCwsKYOHEiQUFB/PLLLwB88sknHHPMMURFRblcDiGEEEIIIYR7HRY1s23VmPYECQkJDX/bbDbuuecePvvsMwoLCxtqa4uKiggKCjpoXWcw5+Tr60tlZWWz+2lp2cLCQqxW6wHlaPx3U62Vsa6ujtraWgYOHHjQetnZ2c1Od1XTMj311FO8/fbb5OXloZTCbDZTVFTU5r4uvvhiPvzwQ/7xj3/w4YcfcuONN3a4TEIIIYQQQojuJzWz3Uwp1eb0BQsW8NVXX/Hzzz9TXl7e0BRZ07QuK1dERAQmk4mcnJyGaa01/22tjOHh4Xh7e5Oenn7QegkJCc1OB/Dz86O6urrh//379x+0TOP3admyZTzxxBMsXLiQ0tJSysrKCAoKanifWtvX3Llz+eqrr9i4cSPbt29n1qxZLb5WIYQQQgghRM8jwWw3i4qKYs+ePa0uU1FRgZeXF2FhYVRXV3P33Xd3ebmMRiOzZ8/mvvvuo7q6mrS0NN5///0OldFgMHDppZdy8803k5eXh81mY8WKFdTV1XHBBRfw888/s3DhQqxWK8XFxQ39bEePHs0XX3xBdXU1u3fv5u233261zBUVFZhMJiIiIrBarTzwwAOYzeaG+Zdffjn/+c9/2LVrF5qmsWnTJoqLiwGIj49nwoQJXHjhhZx55pkNzZaFEEIIIYQQvYMEs93srrvu4qGHHiI4OJinnnqq2WUuuugikpKSiIuLIzU1lcmTJ3dL2V566SXKy8uJjo7mwgsv5LzzzsPLy6tDZXzqqacYMWIEEyZMIDQ0lDvuuAO73U5iYiLffvstTz/9NKGhoYwePZqNGzcC8K9//QtPT0+ioqK4+OKLueCCC1ot78yZMznhhBMYPHgwSUlJeHt7H9AM+eabb+bss8/m+OOPJzAwkMsuu6whozLoTY03b97MhRde2NG3TAghhBBCCOEmqiubrna18ePHa2vWrDlo+vbt20lJSXFDifqWO+64g/379zN//nx3F6VL/P7778ydO5fMzMwWm393lJyDQgghhBBCHDql1FpN08Y3N09qZkWDtLQ0Nm3ahKZprFq1irfffpszzjjD3cXqEhaLheeff57LL7+80wNZIYQQQgghRNeTYFY0qKioYPbs2fj5+XHOOedwyy23cPrpp7u7WJ1u+/btBAcHs2/fPm666SZ3F0cIIYQQQgjRAYfF0DzCNRMmTGD37t3uLkaXS0lJoaqqyt3FEEIIIYQQQhwCqZkVQgghhBBCCNHrSDArhBBCCCGEEKLXkWBWCCGEEEIIIUSvI8GsEEIIIYQQQhxGcsw5vLL6FeZ+MZfePFSrJIASQgghhBBCiD5M0zQ25m/kq7Sv+L+d/8e6fesAGBQ6iPyqfKL9o91cwo6RmtleYunSpcTHxzf8P2zYMJYuXerSsu119dVX8+CDD3Z4fSGEEEIIIYT7WO1WiquL+Sn9J/757T/p93w/xrw+hvt/ux9vkzePzXiM7ddtZ+f1O3ttIAtSM9trbd26tVO289577/HWW2/xxx9/NEx77bXXOmXbQgghhBBCiPbLLMvkl72/UFpTisVuwWq3YrFZsNgtWGyO/+0WKusrKa0tpay2jLLaMkpr9L8r6isatuVj8uH4gcdz79H3cnLyyUT5R7nxlXUuCWbFYcNqtWIyySkvhBBCCCE6n6ZplNSUkFuRS645lypLFcmhyQwJH4K3ybvVdS02C8uzl/Ptrm/5367/sbWw+YorD4MHJoMJD6MHHgYP/D39CfYOJtg7mAEhAwiOCSbYK5gQn5CGadP7T8fXw7crXrLbyZV9N3r88cdZvXo1n3/+ecO0G2+8EU3TeOGFF3j33Xd54oknyMnJISIigjvuuIOrrrqq2W3169ePt956i+OOO46amhquueYavvrqK2JiYrjkkksOWPaxxx7jzTffpKCggISEBB5++GHOOOMMtm/fztVXX43FYsHf3x+TyURZWRnz5s0jPj6ehx56CIA333yTxx9/nJKSEqZNm8Zrr71GbGwsAEopXn31VZ5++mkKCwu54IILeOmll1BKHVTmVatWceONN7J9+3Z8fHw488wzeeaZZ/D09AT02uabbrqJtWvX4uHhwY033sjdd9+NzWbj8ccf5+2336agoIDBgwezePFibDYb/fv3x2KxNASpxxxzDHPnzuXyyy/nvffe480332TixIm8//77XHPNNVxyySVcccUVbNy4EaUUM2fO5OWXXyY4OBiA7OxsbrzxRpYtW4bdbue8887jmWeeITo6mt9++40RI0YAUFBQQL9+/cjMzCQiIuIQzgohhBBCCNGdMssy+T3zd5KCk5gcPxlPo2e71s8x5/BT+k9sLtjcELjmVeSRV5FHna3uoOUViv4h/UkJT9EfEfpztH80v2X+xre7vuXH9B8pryvHw+DBUUlHcemYSzlh0AnEB8bjYfDAw+iBURmbvcY+nB0WwexNu3axobKyS/cx2t+f55KTW13m3HPP5f7776eiooKAgABsNhsLFy7kyy+/BCAyMpJvvvmGAQMG8Pvvv3PiiScyYcIExo4d2+p277//ftLT00lPT6eqqooTTzzxgPkDBw5k2bJlREdH89lnnzF37lx2795NSkoKr7322kHNjBtbsmQJd911Fz/++CPDhg3j1ltv5dxzz+X3339vWOabb75h9erVmM1mxo0bx6mnnsoJJ5xw0LaMRiPPPvss48ePJycnhxNPPJFXXnmFm266iYqKCo477jhuvfVWvv76aywWC9u2bQPgmWee4eOPP+bbb79l8ODBbNq0CV9fXyoqKg7aR1MrV67k3HPPJT8/H4vFQm5uLnfddRdHHXUUZrOZM888k/vuu4/nnnsOm83GKaecwvTp0/nggw8wGo2sWbMGT09Pzj33XD788EMef/xxAD7++GNmzJghgawQQgghRCfbX7mfHUU7SIlIIdIv8pC3V1VfxW+Zv/HD7h/4If0HdhTvaJjn6+HLtMRpzOg/gxn9ZzA6ejRGg7HZ9X9M/5Gf9vzEtsJtDevGB8YTGxDL1ISpxAXEERsQS1yg/uxj8mFn8U62F23XH4Xb+XnPzwcFvLEBscxJncNJyScxY8AMAr0CD/k1Hy4Oi2C2p0hKSmLs2LF8+eWXXHTRRSxZsgRfX18mT54MwMknn9yw7NFHH83xxx/PsmXL2gxmFy5cyCuvvEJoaCihoaHccMMNPPDAAw3z58yZ0/D3Oeecw6OPPsqqVas4/fTT2yzzRx99xKWXXtpQhkcffZSQkBAyMjLo168fAHfeeSfBwcEEBwdz7LHHsmHDhmaD2XHjxjX83a9fP6666ip+++03brrpJr755huio6O55ZZbAPD29mbSpEkAvPXWWzzxxBMMGTIEgFGjRgG4FMzGxsbyz3/+EwCTycSgQYMYNGgQABEREdx8883cf//9gF5znJeXx5NPPtlQ0ztt2jQALr74YubMmcNjjz2GUooPPviA22+/vc39CyGEEEII12iaxpvr3uTWH29t6PMZ4RvB8MjhDIsYpj9HDmNYxDBCfEIa1rPZbdTZ6qiz1lFrraXOVkdxdTFL9i7hh/QfWJa1jHpbPd4mb47pdwxXjbuKY/sfS0ZZBr/s+YUlGUu44+c7AAjxDuHY/scyvd90zHVmftzzI39m/YnFbsHb5M1RSUdxyehLOH7g8YyIHNFmTemYmDEH/G+z29hbtpfthdvJrchlcvxkRkWNkhrXDjosgtm2aky70/nnn8/HH3/MRRddxIIFCzj//PMb5n333Xfcf//97Ny5E7vdTnV1dUOz1tbk5eWRkJDQ8H9SUtIB899//32eeeYZMjIyAKisrKSoqMil8ubl5R0QTPv7+xMWFkZubm5DMBsd/XcGNF9fXypbqAXfuXMnN998M2vWrKG6uhqr1doQ4GZnZzNw4MBm12ttXlsavy8A+fn5Dc2IKyoqsNvthISENOwnKSmp2X61kyZNwtfXl6VLlxITE8Pu3bs57bTTOlQmIYQQQghxoL2le7n868tZsncJ0/tP56ZJN5Fems6Wgi1sLdzKexvfo7L+72vMYO9grHYrtdZarHZri9sdHjmcf078JzMHzuTIpCMP6Ls6Ono0s4bOAmBfxT6W7F3CL3t/4Ze9v/DF9i8alrlp8k0cP/B4jkg4Ah8Pn0N6nUaDkUGhgxgUOuiQtiN0h0Uw25PMmTOHW265hZycHL788ktWrFgBQF1dHWeeeSbvv/8+p59+Oh4eHsyaNculQYxjYmLIzs5m2LBhAGRlZTXMy8zM5IorruCXX35hypQpGI1GRo8e3bDdtu4CxcbGkpmZ2fB/VVUVxcXFxMXFtfu1X3PNNYwZM4aPP/6YgIAAnnvuuYb+wwkJCXzyySfNrpeQkEB6ejrDhw8/YLqfnx8A1dXVBAbqzTH2799/wDJNX9/dd9+NUorNmzcTGhrK4sWLuf766xv2k5WV1WKiqIsvvpgPP/yQ6OhozjrrLLy9W+/IL4QQQgjR15XXlrOjeAdpRWmkFaWxvWg76SXpjIkZw9wRc5nef/pBzXYbs2t2Xl71Mnf+cidGZeT1U17nirFXHHQNp2kaWeVZbC3cypaCLWSVZ+Fp9MTb5I2X0Ut/Nnk1/O/v6a83/Q107Zo1JiCGC0ZewAUjL0DTNDLKMvD18O1TmX/7Iglmu1lERATHHHMMl1xyCf379yclJQWA+vp66urqiIiIwGQy8d133/Hjjz8eFMA15+yzz+bRRx9l0qRJVFVV8eKLLzbMq6qqQinV0Lfz3XffZcuWLQ3zo6KiyMnJob6+viERU2PnnXce5513Hueffz4pKSncfffdTJo0qaFWtj0qKioIDAzE39+ftLQ0Xn311YZynXLKKdx8880899xzXHPNNdTX17Nt2zYmTZrE5Zdfzn/+8x9SU1MZNGgQmzdvJi4ujoiICOLi4vjwww+56qqrmD9/Punp6W2WISgoiKCgIHJzc3nyyScb5k2cOJGYmBjuvPNO7r//foxGI2vXruWII44AYO7cuYwaNYqAgAA++OCDdr9+IYQQQojeyq7Z2VW8i79y/mJ13mq2FW4jrSiNfZX7GpYxGUwkhyaTFJzE4rTFvL/xfWL8Yzh/xPnMHTn3oOa0O4t3ctn/XcYfWX9w4qATef2U10kISmhu9yilSApOIik4iZOST+rS16qUnrBJ9HwGdxfgcHT++efz888/H9DEOCAggBdeeIGzzz6bkJAQFixY4HIz1nvvvZekpCT69+/P8ccfz4UXXtgwLzU1lVtuuYUpU6YQFRXF5s2bG4IzgOnTpzNs2DCio6MJDw8/aNvHHXccDz74IGeeeSYxMTGkp6e3WIPalqeeeooFCxYQEBDAFVdcwTnnnHPA6//pp5/4+uuviY6OJjk5mV9//RWAm2++mbPPPpvjjz+ewMBALrvsMmpqagA90/KTTz5JWFgYW7duZerUqW2+V+vWrSMoKIiTTz6Z2bNnN8wzGo18/fXX7N69m8TEROLj4/n0008b5ickJDB27FiUUhx55JEdeg+EEEIIIXqD0ppSftj9A/cvvZ8TPzqR8CfCGfryUOZ9NY/3N75PtaWamYNm8tiMx1h8zmLSrkuj+u5qtl23je8u+I78W/P5bM5nTIybyAsrX2DM62MY8eoIHvvjMfaW7uWp5U8x6rVRbCnYwnunv8f/zv9fi4GsEC1RrjRj7anGjx+vrVmz5qDp27dvb6jxFKIzXXrppcTGxjYMW9QSOQeFEEII0dnqrHX8tOcnAKL9o4nxjyHSLxIPo0ezy9s1OznmHHYV72Jn8U52lejPRdWt504prS1lZ/FOQB9WZnjkcCbHT254DA0fikG5XidWXF3MZ9s+48NNH/Jn9p8N008fcjqvnvwqMQExLm9LHH6UUms1TRvf3DxpZiyEizIyMvjiiy9Yv369u4sihBBCiMPIruJdvLH2Dd7b+N5BgahCEe4brge3ATFE+0dTWV/JzuKd7C7ZTa21tmFZH5MPyWHJRPtHo2g5b0psQCzzRs1jcvxkxseOJ8Ar4JDKH+YbxtXjr+bq8Vezp3QPi7YtYlDoIGYNnSVZfMUhkWBWCBf85z//4dlnn+Wuu+6if3/pQyGEEEKIrlVnrWNx2mJeX/s6v2b8ilEZOX3o6Vw+5nLCfcPZV7mP/ZX72VfheK7cx77KfaQVpeFj8mFw2GBmDpxJcmgyg8MGkxyWTGxAbLtqVLvCgJAB3HbEbW4tg+g7JJgVwgUPPvggDz74oLuLIYQQQogeTNM0iqqLKK4ppri6+IC/nc/V1mqCvIII9Qk94BHiHUKoTyg2zcYHGz9oqIXtF9yPh6c/zCWjL5HmuEI0IcGsEEIIIYQQHWDX7GzK38Tvmb/zW+Zv/J75e4v9UT0MHoT5huHn4Ud5XTklNSXYNXuzyzprYa8ceyX/GPgPt9emCtFT9dlgVtM0aYMv3MJub/6HSQghhBDuZdfslNaUUlRd1PAorin+++/qYrxN3oT5hhHqE0qYj+PZ8X+oTyh7S/c2BK/LspZRVlsGQL/gfpyUfBJjo8cS4RdBmE8Y4b7hhPmGEeYThr+n/wHXpnbNTkVdBSU1JZTUlFBaW0pJTYmeJXjgTKmFFcIFfTKY9fb2pri4mLCwMAloRbfRNA2LxUJ+fj5+fn7uLo4QQgghAIvNwg/pPzB/43y+3vE1dba6ZpfzMnoR5htGrbWW0ppSNFof8SM5NJmzUs7iqKSjOLrf0SQGJbarXAZlIMg7iCDvIBnTVIgO6pPBbHx8PDk5ORQWFrq7KOIwYzKZCAoKanbMXiGEEEJ0nw37NzB/w3wWbFlAQVUBEb4RXD72cgaHDSbcN7zh4axB9fXwbagEsWt2ymrLKKkpobi6uKH2tLimmEi/SI5KOorYgFg3v0IhRJ8MZj08PCTjrBBCCCHEYWZ/5X4WbF7A/I3z2ZS/CQ+DB6cOOZWLR13MiYNObHE81qYMytDQrHhQ6KAuLrUQoqP6ZDArhBBCCCF6Pk3T2FKwhS+2f8HiHYuprK8kMShRfwQm/v13UCIJQQl4GDzINmeTWZZJRlkGmeWZZJY7/i7T/7ZrdibGTeTlk17mnGHnEOYb5u6XKYToIhLMCiGEEEKIbqNpGmvy1rBo+yK+2P4Fu0p2oVAckXgEQ8KGkG3O5uc9P5NXkXdQtl+FOqAvq0IRExBDv+B+TI6fzMWjLubsYWeTEpHS3S9LCOEGEswKIYQQQohOo2ka9bZ6KusrqaivoLK+ksr6SkpqSvgx/Ue+2P4F2eZsjMrI9P7TuXnKzcwaOoto/+gDtmOxWciryCOrPKvhUWutJSk4iaSgJPoF9yMhKAFPo6ebXqkQwt0kmBVCCCGEEO1ms9vYXLCZP7L+YFnWMlbnrqa0tpTK+kqsdmuz63gZvZg5aCYPHvsgpw45lVCf0Ba372H00APX4KSueglCiF5OglkhhBBCCNGmWmstq3NXNwSvy7OXU15XDkB8YDxTE6YS5ReFv6c//p7+BHgG/P23l/73qKhRBHgFuPmVCCH6CglmhRBCCCH6mKr6KtJL09ldsrvhUVxTTLWlmmpLNTWWGv3ZWtMwzWKzAKCUQqEO+FspRY2lBotdXyY1IpVzhp3DkUlHcmTikVJ7KoRwCwlmhRBCCCF6CU3TqKivoKCqoOFRWFVIflU+e0v3srtUD1zzKvIOWC/CN4JIv0j8PP3wMfkQ7huOj4cPvh6++Jj0Zw+DPmyNM8GSpmloaGia/r+Phw+T4iZxROIRhPvKeOpCCPeTYFYIIYQQoofaVbyLT7d+yjc7vyG3IpeCqgLqbfXNLhvtH82g0EEcP/B4BoUMYlDoIJLDkhkYMpAg76BuLrkQQnQ9CWaFEEIIIXqQjLIMPt3yKZ9u/ZT1+9cDMCV+CscNOI5I30gi/PRaVucjwjeCCL8IvE3ebi65EEJ0LwlmhRBCCCHcLMecw2dbP+PTrZ+yMnclAJPiJvHM8c8wZ9gc4gPj3VxCIYToeSSYFUIIIYToZlX1VSzLWsYve37h570/s2H/BgDGRI/hsRmPcfaws+kf0t+9hRRCiB5OglkhhBBCiBbY7Db2lO7B18OXmIAYDMrQoe1Y7VZW567m5z0/8/Pen1mRvQKL3YKn0ZOpCVN5ePrDnJV6FoPDBnfyKxBCiL5LglkhhBBCCMBis7CtcBvr9q3TH/vXsXH/RqosVQB4GDxICEogKSiJfsH9SApKIik4iaSgJDyMHhRWFVJUXURhtf7c+O8dRTuoqK9AoRgTM4Z/Tf4XMwbMYFriNHw9fN38yoUQoneSYFYIIYQQfU6ttZYle5fw5fYvWZm7EpPBhJfJC2+TN15Gx7Pjf4CtBVvZXLC5IVOwn4cfY2LGcNmYyxgVPYp6Wz0ZZRlklmeSWZbJ97u/Z1/lvhb37+fhR4RfBOG+4UT4RjBh5ASm95/Osf2OJcw3rFveAyGE6Ou6LZhVSp0APA8Ygbc0TXusyfwk4B0gAigB5mqaltNd5RNCCCFE71ZeW863u75l8Y7FfLvrWyrrKwnwDODIpCMxKiO11lrqbHWU1pZSZ61r+N9qtzIkbAg3TrqRsTFjGRszlkGhg9psUlxnrSPbnE1GWQZ2zU6Erx68OsdwFUII0bW6JZhVShmBl4F/ADnAaqXU/2matq3RYk8B72uaNl8pNR14FLiwO8onhBBCiN5pf+V+vkr7ii/TvmTJ3iVY7Bai/KI4f/j5nJFyBsf2OxYvk1eX7NvL5MWgUH08VyGEEN2vu2pmJwK7NU3bA6CU+gQ4HWgczKYCNzv+/hVY3E1lE0IIIUQvklWexRfbv2DR9kX8mfUnGhqDQgdx0+SbmDV0FpPjJ3c4UZMQQojeo7uC2Tggu9H/OcCkJstsBGajN0U+AwhQSoVpmlbceCGl1JXAlQCJiYldVmAhhBBC9By7S3azaNsiFm1fxOq81QCMjBrJfcfcx+yU2QyLGIZSys2lFEII0Z16UgKoW4GXlFLzgN+BXMDWdCFN094A3gAYP3681p0FFEIIIUTnsdlt7C3bS2FVIRX1FVTUVRz0bK4z82f2n2zM3wjA+NjxPDbjMWanzCY5LNnNr0AIIYQ7dVcwmwskNPo/3jGtgaZpeeg1syil/IEzNU0r66byCSGEEKILldWWsSl/E5vyN7Fx/0Y2FWxiS8EWqi3VLa5jMpgI8AwgNSKVZ45/htkps0kKTurGUgshhOjJuiuYXQ0kK6X6owex5wLnN15AKRUOlGiaZgfuQs9sLIQQQoheyGq38vWOr3l/0/us27eOrPKshnmhPqGMihrFlWOvZETUCGL8YwjwCiDAM+CAZy+jlzQdFkII0aJuCWY1TbMqpa4HfkAfmucdTdO2KqUeANZomvZ/wDHAo0opDb2Z8XXdUTYhhBBCdJ7CqkLeWvcWr655lWxzNnEBcRzd72hGRo5kZNRIRkWPIsY/RoJUIYQQh0xpWu/tdjp+/HhtzZo17i6GEEIIcdhblbuKl1e/zCdbPqHeVs+M/jO4fuL1nDL4FEyGnpSiQwghRG+ilFqradr45ubJr4sQQgghDmDX7Hy36zteWPUC6/etJ9w3nEi/yIZHhG9Ew9/ldeW8tuY1Vuetxt/TnyvGXsG1E64lNSLV3S9DCCFEHyfBrBBCCCEAMNeZeXf9u7y0+iV2l+wmNiCW04acRlltGQVVBWwu2ExBVQElNSUHrDc0fCgvnfgSF466kECvQDeVXgghxOFGglkhhBDiMLereBcvrnqRdze8S2V9JVPip/DQsQ8xO2U2HkaPg5a32CwU1xRTUFWA1W5lTPQY6QMrhBCi20kwK4QQQvQRmqaxt2wvq3NXsyp3FWv3rcVqt+Lv6d/wCPAMaPjb18OXn/f+zLe7vsXD4ME5w8/hhok3MCFuQqv78TB6EO0fTbR/dDe9MiGEEOJgEswKIYQQvVRRdRGrclcd8CiuKQbA2+TN6OjR+Hn4UVZbRrY5m8r6SirrK6moq8BitwAQ5RfFvUffy9Xjr5bgVAghRK8iwawQQgjRy6zOXc2Ty59k0fZF2DU7BmUgNSKV04eczsS4iUyMm8jwyOHNNhF2qrfVU1FXQaBXYKvLCSGEED2VBLNCCCFEL6BpGt/t/o4nlz/J0oylBHkFceuUWzl58MmMjRmLv6d/u7bnafQkzDesi0orhBBCdD0JZoUQQogerN5Wz8ebP+apFU+xpWAL8YHxPH3801w+9nLJHCyEEOKwJsGsEEII0Q00TSO9NJ3l2csbHrkVuYT6hBLuG97wCPMJa/i7qLqIl1a9RG5FLiMiR/D+rPc5Z/g5eBo93f1yhBBCCLeTYFYIIYToAtWWatbtW3dA8FpYXQhAoFcgU+KnMC1xGqW1pRRXF5NrzmXj/o0UVhdSa61t2M70/tN567S3mDlwpgx/I4QQQjQiwawQQghxCKx2K7uKd7G5YDNbCrawpWALmws2k16SjoYGQHJoMicln8TUhKlMTZhKakQqBmVocZvVlmqKq4uxa3aSgpO666UIIYQQvYoEs0IIIUQ72Ow2luxdwqdbP2VN3hq2F22n3lYPgEEZSA5NZlTUKOaOmMuYmDFMiZ9ChF9Eu/bh6+GLb5BvVxRfCCGE6DMkmBVCCCHaoGka6/at46PNH/Hxlo/ZX7mfQK9ApiVOY+bAmQyPHM6IqBEMDR+Kt8nb3cUVQgghDgsSzAohhBAt2FO6hwWbF/DR5o9IK0rD0+jJScknMXfEXE4efLIErkIIIYQbSTArhBBCNFJWW8bCrQuZv3E+y7OXA3BU0lHcPPlmzko9ixCfEDeXUAghhBAgwawQQgiBzW7jpz0/MX/jfL7c/iV1tjpSI1J5bMZjnDfiPBKDEt1dRCGEEEI0IcGsEEKIw9a2wm3M3zCfDzZ9wL7KfYT6hHLF2Cu4ePTFjIsZJ0PhCCGEED2YBLNCCCH6jP2V+1mZs5KVuSvZW7YXu2ZH0zQ0tIP+zjHnsG7fOozKyEnJJzFv9DxOTj4ZL5OXu1+GEEIIIVwgwawQQoheqcZSw/r96/kr5y9W5q5kZc5KMsszATAZTCQFJWEymFBKYVAGFOqAv/09/Xnm+Gc4f8T5RPlHufnVCCGEEKK9JJgVQgjRq2wt2ModP9/BD+k/YLVbAUgMSmRS3CT+OfGfTI6fzNiYsfh4+Li5pEIIIYToShLMCiGE6BUKqwq5d+m9vLH2DQK8AvjX5H9xRMIRTIqfRLR/tLuLJ4QQQohuJsGsEEKIHq3OWseLq17kod8forK+kmvGX8N9x9xHmG+Yu4smhBBCCDeSYFYIIUSPpGkai9MWc9tPt5Fems5JySfx1D+eIiUixd1FE0IIIQ5Jvd3OO/v2cUlMDF4Gg7uL02tJMCuEEKJH0TSNNXlruO2n2/gt8zdSI1L5/oLvmTlopruLJoQQQnSKH0pKuGbXLrwMBi6JiXF3cXotCWaFEEJ0Kqvdyqb8TQwKHUSgV6DL620p2MLCrQtZuHUhO4p3EO4bzisnvcIV467AZJCfKyGEEH1HWnU1AIsKCyWYPQRydSCEEKLT5Ffmc/bnZ/N75u8oFKkRqUyOn9zwSAlPwWgwNiy/rXAbn239jIXbFrKtcBsGZeDopKO5afJNnDv8XIK9g933YoQQQogu4gxmfyotxWy1EmiSsKwj5F0TQgjRKVbnrmb2wtkUVxfz9PFPU1VfxV+5f/Fl2pe8vf5tAAI8A5gYN5GU8BSWZi5lS8EWFIqjko7i5ZNeZnbKbMlMLIQQos9Lq64m2GSizGrlm+Jizo+S8c47QoJZIYQQh+zd9e9yzf+uISYghuWXLWd09OiGeZqmsbtkN3/l/KU/cv/ijXVvMCluEi+e+CJnppxJTIA0sRJCCHH42FFdzVkREXxTXMyiwkIJZjtIglkhhBAdVm+r51/f/4tX1rzCcQOO45MzPzloyBylFMlhySSHJXPhqAsBPcBVSrmjyEIIIYRbFdXXU2y1kurri6dSvLt/P1U2G35GY9sriwNIHmghhBAdsr9yP9PnT+eVNa9w29Tb+O6C71we+1UCWSGEEIerHTU1AAz19eXMiAhq7Ha+Lylxc6l6J6mZFUII0W4rsldw5sIzKa8r55MzP+Gc4ee4u0hCCCFEr+BM/jTE15dELy/CTCYWFRZyZkSEm0vW+0gwK4QQh5ndJbuprK8kITCBUJ/QNmtJNU0jqzyLLQVb9EfhFj7d8ikJQQn8MPcHRkSN6KaSCyGEEL3fjupqvJQiydsbo1LMCg9nYWEhdXY7XgZpONseEswKIcRhotZay39//S9Pr3gau2YHwMfkQ3xgPAlBCfpzYAIJgQlUW6rZWriVLQVb2Fq4lcr6yobtxAfGc87wc3j+hOcJ9Ql118sRQggheqW06mqSfX0xOm4mnxkRwdv79/NTSQmnhIe7uXS9iwSzQghxGFidu5qLF1/M9qLtXDH2CmYOnEm2OZvs8mxyKnLILs9myd4l5FXkNQS6kX6RDIsYxiWjL2F45HCGRQxjWOQwGftVCCGEOARp1dWM8vdv+H9GSAhBRiOLiookmG0nCWaFEKIPq7PW8cBvD/D4n48TExDDD3N/4PiBx7e4vNVuZX/lfjyNnkT6RXZjSYUQQoi+r95uZ09NDWc36h/raTBwWng4XxUVYbHb8ejipsY2TWOV2czXxcWsMJv5ZdQoDL00MaMEs0II0Uet37eeixdfzOaCzVwy+hKemflMm7WqJoOJ+MD47imgEEIIcZhJr6nBhp7JuLEzIyL4ID+fX8vKOD6087vwmK1Wfiwp4eviYr4tKaHIYsEIHBkcTJHFQqSnZ6fvsztIMCuEEH2MxWbhkWWP8NCyhwj3Defr877mlMGnuLtYQgjR572Yk8PqigreT0lxd1HEIdpSWUmQyUSCt3enbneHI5Nx02D2+JAQ/AwGFhUWdlowW2Kx8EF+Pt8UF/NbWRkWTSPEZOKk0FBOCQvjhNBQgj08OmVf7iLBrBBC9CKlNaV8teMrymvLqbJUUVVfdeCzpYodRTvYUbyDC0ZcwAsnviBJmoQQohvU2+08lJlJgcXC3YmJDPXzc3eRxCE4efNmfAwGNowfj7fR2GnbdQ7LM7hJMOtjNHJyWBiLi4p4ZfDghuRQh+LsrVv5payMFF9f/hUfzylhYUwJDMTUhzImSzArhBC9QL2tnldWv8IDvz1AaW1pw3SjMuLn6Yefh1/Dc5R/FI/MeITZKbPdWGIhhDi8fFNcTIHFAsAH+fk8PGCAm0skOiq3ro6sujoA7s/M5NFOPJZp1dXEenoSaDo4DDszIoKFhYX8UV7O0cHBh7SfNWYzv5SV8diAAdyRmHhI2+rJJJgVQogeTNM0Fqct5vafb2d3yW6OG3AcD09/mEGhg/Dz8MPT6NnmOLFCCCG63lv79hHn6Umqnx8f5ufzYP/+vTapzuFupdkMwISAAJ7MymJORARjAwI6Zds7amoY0qRW1umk0FC8HU2NDzWYfTI7m0CjkWtiYw9pOz1d36ljFkKIPmZN3hqOmX8MsxfOxsPgwf/O/x8/zv2RiXETCfUJxcvkJYGsEEL0ANm1tXxfUsKlMTFcHB1NVl0df5SXu7tYooNWms14KMXXI0YQ6enJpWlpWOz2Q96upmmkVVcf1F/Wyd9k4oTQUL4oLMSuaR3ez56aGj4vLOTq2Nhma4D7EglmhRCih8kqz2LuF3OZ8OYEthdu59WTX2XTNZs4KfkkCV6FEKIHemf/fgAujY5mVng4fgYDH+Tnu7lUoqNWms2M9vcnytOTVwcPZmNVFU9kZx/ydgstFsqs1hZrZgHODA8nt76eVY7a4Y54Jjsbo1LcGN/3Ryfo26G6EEL0YJqmUVhdyI6iHaQVpbGjWH/+Ze8vaJrGXdPu4s5pdxLoFejuogohhGiBTdN4Z98+jgsJoZ+PD6D3ffysoIAXBw3q1ORBfUV+fT3eBgNBPbDW0KZprKmo4JKYGABODw/nnIgIHsjI4IzwcFIPIbFXWguZjBs7JSwMD6VYVFTE5KCgdu+jqL6ed/bvZ25UFLFeXh0ua2/R884gIYToozRN4/Ntn/Pt7m8bAtjGyZy8jF4MDhvMhSMv5J4j7yEpOMmNpRVC9BT59fWcsnkz7w4ZwnB/f3cXx21Wm83sqa3lnMhIdxflAD+XlpJVV8eTAwc2TLswKor38/P5uriYOT2svO5WZ7czYe1a6u12FqSmMj0kxN1FOsDWqiqq7HYmNeoj+0JyMj+XlnLZjh38MWZMhzMNtzQsT2PBHh4cFxLCosJCnhgwoN0tsl7Jy6PGbufWhIQOlbG3kWBWCCG6wa7iXVz77bX8vOdnIv0iSY1I5exhZzM0fChDw4cyJGwIiUGJGA1yB18IcaBfS0tZU1HBMzk5vDN0qLuL4xY1Nhtztm4lp66OiQEB9HfUgPYEb+3bR5jJxOnh4Q3Tjg0JIdbTkw/y8yWYbeKD/fvJrqsj1tOTf2zcyH39+nFPUlKPSZblTP40KfDvVlGRnp48n5zM3O3beTEnh5s6GCimVVfjYzCQ0EaN6ZkREVy+YwfrKyvblXiqxmbjxdxcTg4NPaQa5N5E+swKIUQXqrPW8cBvDzDi1RGsyl3Fyye9TN7Nefx68a+8dspr3DT5Jk4YdAL9Q/pLICuEaNa6ykoAPikooNxqdXNp3OPZnBwyHUOlPNkJfRebY7HbeTk3lz01NS6vU1Bfz1dFRVwUHY1Xo7E7jUpxflQU35WUUFRf3xXF7ZVsmsYT2dmM9fdnx8SJnBcZyX8zMjhx0yYKO/F9yq+v59K0tA699yvNZkJNJgY1uWFyfmQkJ4eGcs/eve06RxpLq65msI9Pm4H76WFhGIFFhYXt2v57+/dTZLFwWx8eiqcpCWaFEKKL/Lr3V0a+NpJ7l97LrKGzSLsujWsnXCtBqxCiXdZWVBBqMlFjt/PRYZhUKK+ujkcyMzkjPJxLY2J4Z98+9jkC285SYrFw4qZNXL9rF6dv2UKtzebSeh/k52PRNC539K9s7MKoKKyaxqftDEj6skWFheyqqeGuxET8TSY+SEnhjcGD+a2sjNFr1rCsrKxT9nPPnj28u38/Czvw3q+sqGBiYOBBzXuVUrw2eDAmpbhixw60DmQb3lFd3WryJ6dwT0+OCQ5mUWGhy/uxaRpPZ2czMSCAozrQ17a3kmBWCCE6WWFVIRd9eRHT35+O1W7l+wu+55OzPiEm4OCLHSFE68xWK1UuBhZ9kaZprKus5KyICMb6+/N6Xl6HLqJ7s3v27sWiaTw5cCC3JyRg0TSezcnptO2nVVUxad06lpWXc0NcHFuqqrhzz54219M0jbf27WNqYGCzTTpH+vsz0s+PDxyZjg93mqbxaFYWg318OCMiAtADxCtiY/lr7Fh8jUaO3bCBJ7KyDmlYms2VlQ3Zpb8vKWnXuhVWK1urqg7oL9tYvLc3Tw4cyJKyMt7at69d266z29lbW9tqf9nGzoyIYEdNDdsc/WzbsrioiPTaWm5LSDisRj6QYFYIITpJZX0lr6x+hSEvDeGTLZ9wz5H3sOWaLcwcNNPdRROi1zpl82aOWLeOmsM0oM2oraXMamVsQABXxsayqaqKVRUV7i5Wt1ljNvPe/v3cFB/PQB8fBvn6ck5kJK/m5VFisRzy9n8sKWHyunWUW60sGT2a55OT+WdcHM/n5vJjG4HQcrOZtOrqZmtlnS6MimJlRQU7XQxI+rIfS0vZUFnJHYmJByVQGh0QwNpx45gdEcEde/Zw+pYtHT6+t+/ZQ5DJxDkREfxaVkZ9O8aHXVNRgcaB/WWbujwmhmOCg7k1PZ2c2lqXt727pgY7uFQzC3BGeDgeSjEvLa3NlgiapvFEVhYDvb0bbhQcLiSYFUKIQ6BpGsuzl3PZV5cR/VQ01317HSOiRrDx6o08NP0hfDx6TpISIXqbSquV5eXlbKyq4sbdu91dHLdw9pcd6+/PeZGR+BkMvJGX5+ZSdQ9N07hp924iPTy4J+nv7O53JiZSabPxUm7uIW37hZwcTty0iSRvb1aPG8cRjqaZjw8YQKqvL/Pa6HP51r59BBiNzGkleDgvKgoFfOhi8/Dcujr+uWtXpzej7gkezcwkztOTuVFRzc4PNJn4NDWVFwcN4oeSEo5Yv57KdvYR/6mkhO9LSvh3UhLnRUVRabOxvLzc5fWdyZ8mthLMGpTirSFDsGhau76XXBmWp7FoLy8WDRvG9qoqJq5bx/pWbmItKy9nVUUFNyckdDjTcm8lwawQQnRAQVUBTy1/imGvDOOId47g062fcs6wc/jjkj9YevFSUiJS3F1EIXq9lRUV2IAjg4J4c9++w7K/6LqKCozACD8/Ak0mzo+KOmwSQS0sLORPs5mH+/cnsNF4pCP9/Tk1LIznc3LaHeyAnujp6p07uXH3bk4NC+PPMWNI8vZumO9jNPJRSgpFFgtX7tzZbLPucquVTwsKOC8yEv9WxkqN8/JiRkgIH+bnt9k83Gy1ctKmTbyUm8sdLjRz7k1WlJfzW3k5tyQk4GloOfxQSnF9fDzfjRzJzupqrt+1y+V92DSN29LT6eftzfVxcRwbHIxJKX4oLW17ZYeVFRUM8vEhzMOj1eUG+vhwQ1wcXxUVUexiDbJzWJ7B7cjEfWp4OH+OHYsCpq1fz+IW+gA/mZ1NuIcH86KjXd52XyHBrBBCuEjTNL7b9R2zP51N3DNx3PbTbQR7B/PWqW+x75Z9vH362xyReMRh1VdFiK70R3k5BmDx8OEcGRTEVTt2NFwQHi7WVVYyzM8Pb6OeOO7KmBiqD4NEUDU2G7enpzPKz49LmmnGe3diIiVWK2+0s99iscXC8Zs28ca+fdyZmMgXw4c3G4yODgjgkf79+bKoiHeb6fP6cX4+NXZ7q02MnS6MimJvbS3LHbV+zbHY7Zy9dStbq6qYGRLCB/n5rOtDzckfzcoi1GTiChfeL4AZISH8JymJ+fn5fOhin+MP8/PZWFXFo/3742UwEGgyMTUwkB9c7DeraRorzeYW+8s2dWZEBDbgf8XFLi2fVl1NvJdXqzc/mjPK359VY8cy3M+P2Vu38kRW1gE3RrZVVfFNcTHXx8Xhazz8EkxKMCuEEG3QNI1vdn7DuDfGcdKCk/gj6w9unHQjW6/dyvLLlnPZ2MsI8HJ9HDghhGv+KC9npL8/oR4efJyaio/RyJytW6k+TPrPaprG2oqKA8aZHBcQwJjDIBHU09nZZNXV8dygQc02m5wcFMSxwcE8lZ1NnYt9IvfW1DBp7VpWlJfzwdChPDpgQKtDpNyckMCxwcHcsGsXu5vcRHlr3z5G+vkx3oXAZ3Z4OL4GQ4uJoDRN49pdu/ihtJTXhwzh02HDCDOZuCU9vU8c4y2VlXxdXMwN8fHtCuT+nZTEkUFBXLNrF7vauIlVbbNxz549TAgI4JxG4/rODA1lfWUl+S4M0ZNTV8e++vpW+8s2Ni4ggDhPTxYXFbm0fFp1tctNjJuK9vJi6ejRzHH0Kb50x46GvsBPZ2fjYzBwXWxsh7bd20kwK4QQLdA0jR/Tf2TK21M49eNTKa8r573T3yPn5hyeOv4pUiNS3V1EIfosq93OivJypjn6McZ5efFhSgqbD6P+s3n19RRaLIzz92+YppTiypgYNlVVsboP1dw1lldXx6NZWcwOD+eYkJAWl7s7MZF99fXMd6HmLqu2lmM3bKDEauXX0aOZ60JzTINSzB86FA+Dgbnbt2N1BA/rKypYW1nJ5TExLrXE8TeZmBUezsLCwmYD78eysnhr3z7uSUzkspgYgkwm7uvXj6VlZS7X+vVkj2dn42cwcH1cXLvWMxkMfJSSgqdSnLttW6s3LZ7LySG3vp6nBg484JjMDA0F9L60bXH2l3U1mDUoxenh4XxfUtLmDTZN0/RhedrRxLgpH6ORT1JTuTcpiff27+cfGzeyubKSD/LzuSQ6mnBPzw5vuzeTYFYIIZqxNGMpR713FDM/nEleRR5vnPIGadelcfHoi/E0Hp4/GEJ0p41VVVTZ7Q3BLOgXpncnJvLWvn0uNz3szZzNTMc2qf07PyqqTyeCunvPHqyOoXhaMyMkhAkBATyeldUQaDYnt66OYzdsoMxq5adRo5jSjjE4E7y9eW3wYFZWVPBQZiYAb+/bh5dSXNBCIqPmXBgVRanVelBw+nF+Pnfv3cv5kZE82L9/w/SrYmMZ7OPDbXv2tPraerq9NTV8nJ/PlbGxbfZDbU6CtzfvDh3KusrKFodLKqiv57GsLE4PC+Oo4OAD5o3x9yfCw8OlfrMrKyrwVIpRjW4etWVWeDg1djs/t7H9/fX1mG22DtfMOimluK9/fxakpLDSbGbs2rXYNI2bExIOabu9mQSzQgjRyPLs5cx4fwbHzj+WPaV7ePmkl9n1z11cMe4KPIzt/yEWQnTMsrIyAI5oUktyf79+HBUUxNU7d5JWVeWGknWfdZWVKDjo4jrQZOK8qCg+7oOJoFabzczPz+df8fEMaKMWSynF3YmJ7KmtZWELiXH21dUxfcMGCi0Wfhg1inEu9ods7JzISC6MiuLBzEyWlJbyYX4+Z0ZEENqO4Oy4kBCiPDwOyGq8rKyMeWlpHBUUxDtDhx5Qo+hhMPDEwIGkVVe3ezzTnuSp7GwMSnFzfHyHt3FaeDj/jIvjuZwcvmmmSe/9GRlU22w83szND4NS/CMkhB9LStocu3al2cwYf3+8WklQ1dTRwcEEGY181UZTY2dff1eH5WnLeVFRLB09mjCTiblRUQw8hBrf3k6CWSGEADbu38gpC07hiHeOYEvBFp6d+Sy7/7mbaydci5fJy93FE+Kw80d5Of28vYlvlGUW9KaHH6em4ms0Mmfbtj7df3ZdRQVDfX3xayapizMR1II+lAjKORRPlIcHdzcaiqc1p4WHk+rry6NZWQcFKwX19czYuJHcujq+HznS5eajzXkpOZlEb29O3ryZcpvN5URGTiaDgfOjovimuJgSi4Ud1dWcvmUL/b29+XL48GYDqNPCwjgqKIh7MzIwt+OmxecFBfzuuBnkTvn19byzfz8XRUUd9DlurycGDGC0vz/z0tLIbTRs0Y7qal7Py+Oq2NgWA8WZoaEUWCxsdAxz1Ryr3c7aiop2nyOeBgMnh4Xxf8XF2FoJlts7LI8rJgcFkT1lCm8PGdJp2+yNJJgVQhzW0kvSueCLCxjz+hj+zP6TR2c8yp4b9nDT5JtkjFgh3ETTNP5o1F+2qVhH/9mtVVXc0I6hO3qbdZWVjG2hyeP4gABG97FEUJ8WFLDcbObhAQMOGIqnNQaluCsxkS2OjK5ORfX1HLdxIxm1tXw7ciRT29G0uDmBJhMfDB1Kvd3OIB8fjm7SnNUVc6OisGgaL+fmctKmTXgoxXcjR7ZYw6uU4qmBAymwWHg8K6vN7Wuaxn179zJn2zaO27iRL1qore4uz+fkUGe3c3ti4iFvy9vRX7TWbueCbdsaAsc79+zB12jk3n79Wlz3eEe/69ayGm+pqqLabu/QDY/Tw8MpslhaHc82rboaP4OBOK/OvTnuYTBgakdNcl90eL96IcRha1/FPq7937UMfXkoX27/kjun3cmeG/Zw57Q78fP0c3fxhDispdfUkG+xtBjMAhzv6D/79v79LWaJ7c0K6uvJqas7qL+skzMR1MaqKtb0gURQFrudu/bu1Wvf2jlW5rmRkfTz9ubhzEw0TaPEYuEfmzaxq6aGr0eMOKgfZUdNCw7my+HD+aBJk2BXjfH3J9XXl/9mZLCvvp6vR4ygfxvNQycEBnJ+ZCTP5OSQXVvb4nJ2TePG3bu5PzOTi6KiGB8QwNlbt/KJm2ruy61WXs7N5ayICAZ3Um3kEF9fXh48mN/Ky3kkM5NlZWUsLirizsREIltJfhTt5cUoPz++byWYXen4DHUkmD0hNBRPpVrNaryjpobBvr6tZs8WHSPBrBDisFJWW8bdv9zNwBcG8ua6N7li7BWk35DOIzMeIcSn5ayZQrTXjupq0mtq3F2MXukPRw1Ha8EswH39+nF0UBCX7djR55IhrXc0iWypZhbggqgofA0GXu8Dr/39/Hwyamt5uH//ZofiaY3JYOCOhARWVVTwZVERx2/cyLaqKhYPH86MVrIhd8Rp4eFM7mAtr1JKz4AMfJSSwkQXA6dHBgxA0zT+vXdvs/MtdjsXp6XxYm4uN8fH8+7QofwwciTTgoK4YPt2l7I9d7ZXc3Mx22zc2Qm1so1dFBXF3Kgo7svI4JK0NOI8PbnJhf64M0ND+dNspqKF5torzWbCPTwY0IHm0IEmEzNCQlhcVNRiK4lDGZZHtE6CWSFEn5ddns1Hmz7i6m+uZsDzA3j0j0eZNXQW26/bzisnv0JMQPv6PgnhinO2buXKHTvcXYxe6Y/yckJMJlLauPgzGQwNActVO3dyzc6dDWMv9nbOTMajWwlmA00mzouM5OOCgnb1qexpLHY7D2dmMj4ggBMdQ6m017zoaKI9PTlr61Y2VVXxxfDhDcOy9CQ3xceTO2UKZ0REuLxOkrc3N8XH80F+fsN54VRjszF761Y+zM/n4f79eWrgQAxKEWAy8e3IkcwICeGStLRuvdljtdt5LieH40NCWmxZ0FFKKV5JTmaAjw/ptbU81L8/vs30KW/qhNBQrJrGry30JV5pNjMxIKBDNe6gZzXeU1vLlmaS0tXYbGTW1nZa8idxIAlmhRB9iqZppBWl8ebaN7nwywvp91w/Ep9LZO6Xc1mweQHH9j+W9VetZ8GZCxgUOsjdxRV9lNlqZVNVVUPSD9E+f5SXc0RQkEtN8oI9PPhmxAhuT0jgtbw8jtu4kfz6+m4oZddaV1nJQG9vgtvImHtlbGyvTwT1QX4+e2truTcpqcPBhLfRyD2JiZiUYmFqKieHhXVyKTuHUoqYDvSbvCspiVCTiVvT0xtq/8qtVk7YtIn/FRfzSnIydzd5/3yNRv5v+HBODA3lqp07eTEnp9NeR2vSqqvJt1iY246hi9ojwGTi6+HDebR/fy50sUn6EUFB+BkMzfabNVutbK+udrmmvDmnhYWhoNmsxrtqatDo3ORP4m+u9a4XQogeLr8yn/t/u5/Pt31OYbWe9CLCN4Kjko7iX5P/xVFJRzEyaiRGQ9t3cIU4VKsrKtCAvPp6amw2fFyoORC6wvp6dtTUcEk7ssUaleLxgQMZ7e/PpTt2MH7tWhYPH96hYVh6inUVFS6Vf0JAAKP8/Hh93z6uio3tcDDoLs5a2XH+/occgF4fH8+86Gj8XUwe1ZsEmUzc168f/9y9m29LSpgQEMAJmzaxuaqKBSkpnNtC4OhtNPLl8OGcu20bN+zeTZ3dzq2d3PS3qYYm8l34+Rvq58edfq7nt/A0GDg2JKTZYNb5fT3pEMob7eXF5MBAFhcV8e8myah2dEEmY/G3vvdpF0IcVmqttTz313M8suwRaqw1zEmdw/T+0zky8UgGhw3udRd2om/4y2xu+HtPbS3D2nHRdbj709Ff9sgO9Es8LyqKIb6+nLFlC9PWr+ftIUM4v4tqh7pSqcXCntpal4Z/UUpxVWws1+7axUqzucP9Od3lo/x89tTW8tXw4Z3yfd0XA1mnq2JjeSE3l5t37wYgu65Or3lt4yaAp8HAp6mpXLh9O7ft2UOt3X5QwNWZ1ldW4m0wMKSHjX06MySEb4qLSa+pOWBc1pWO7+tDqZkFPavxnXv2kF1bS0KjvrfOFjrJPez96CukmbEQolfSNI1Pt3zK0JeGctcvd3Fs/2PZeu1WFpy5gMvHXs6Q8CESyAq3+ctsxuQ4/yQJVPv8UV6Ol1IdrlUdGxDA6nHjmBgQwAXbt3Nbenqr4z/2RBvaWbN1flQUISYTJ2zaxBt5eQeNt9oZcuvqeCY7G0sn9km22u08lJnJGH9/Tu2hzYJ7Eg+DgScGDGBnTQ359fX8NGpUm4Fs43U/Sk3loqgo/pORwbzt21mQn8+WyspOPaagB7Mj/fx63JAxzj7UTWtnV5rNJPv4tDhEkqtmhYcDBzc1TquuJsnLy6W+vaL9+u7tKyFEn7UyZyX/+uFfrMhZwaioUbxz+jtM7z/d3cUSAtBvtPxlNnNiaChfO2oBhOv+KC9nYmAgXodwIRzp6cnPo0Zx0+7dPJWdzabKSj5ISWl1+I6eZJ0jmB3TSvKnxoJMJlaOHcuVO3dy1c6dfJSfzxtDhnRqwpmbd+9mYWEhGbW1vJCc3CnbXFBQQHptLYs7qVb2cHB6eDivDx7MtKAgUtvZ4sOoFO8OHUqQycTreXnMd/Sz9lSKVD8/Rvr5MdLfn5F+fowLCOhQcKdpGhsqKzmnHQmuussgHx/6e3vzQ0kJ18bFAXp5V5rN/KMTkoUN8fVlqK8vi4uKuL5RhuUd1dWS/KkL9axbJkII0Yqs8izOX3Q+k9+ezN6yvbx92tusvXKtBLKi3VaZzYxbs4ZSi6XTt72ntpYii4WTw8IINBolmG2HKpuNtZWVbQ7J4woPg4GXBw/mzcGD+a2sjBGrV/O/4uJOKGXXW1dRQYKXFxHtCL6TfX1ZMmoUbw0ZwqaqKkatXs3DmZmdkt05raqKzwoLSfTy4sXcXN7vhKFenLWyo/39OU1qZV2mlOLK2Nh2B7JOBqV4ITmZyiOPZPP48XyUksJN8fFEe3ryc2kpt6anc/ymTSSuWEF5BzJkZ9TWUma1MqYH9ldXSjEzNJQlZWUNn4usujryLZZD6i/b2KzwcH4rL2/4bdE0jR01NdJftgtJMCuE6PEsNgtP/PkEQ18aypdpX3LPkfew8/qdXDrmUknoJDrk88JC1lVWsqSFYRoOhbO/7JTAQAY6ho8QrlllNmPVtE4JZp0uj41lzbhxRHt6csrmzVy7cyfVNlunbb8rrK2oaHV82ZYopbgsJobtEyZwWng4/967l/Fr17KqUR/ujngkKwsfg4G/xo7lmOBgrtq586AhYtrr44ICdtXU8N9DyGAsOs7DYGC4vz/nR0Xx+MCBfDdyJLlTp1I4dSqvJCdTZbc39CVtj/XtbFXQ3WaGhFBps7HC8dqcr3HSIfaXdZoVHo5V0/jW0ZQ5r76eSptNama7kASzQogebVXuKsa/OZ47fr6Dfwz8B2nXpfHQ9IcI8Op5d31F77HckWRoaRcEsyvNZvwMBob5+enBrNTMuuyP8nIU+o2AzjTc359V48Zxq2P4nrFr1rDmEAO8rlJhtbKzpuaQMsFGe3mxcNgwvho+nBKLhcnr1nHTrl1UdqCmLb2mhgX5+VwdG0uMlxcLU1OJ8PDgjC1bKOrgEEg2TeOhzExG+vlxuqOfoegZwj09mRsVhYKGgK891ldWYgRG9NCkd9NDQjAp1dBvdqXZjJdSjOqk4HtCQAAxnp4sdvSbTZNMxl1OglkhRI9krjPzz2//yeS3JlNUXcQXZ3/BV+d+RVJwkruLJnq5OrudNY5apd+6qGZ2YmAgRqUY6O1NRm1tr0tA5C5/lJcz3M+PkENMxNIcL4OBJwcO5OdRo6iy25myfj2PZGb2uGOzsbISDTplWKHTwsPZNnEi18TG8nxuLidv3tzu5FCPZWVhUopbExIAiPD05Mvhw8mvr+ecbduwdqAZ8ycFBeysqeG//fq5NJaw6F4BJhPD/fxY4bjp1x7rKyoY6uvbY4cjCzSZmBIYyPeNgtkxAQF4dlKyKoNSnBYWxnfFxdTabBLMdgMJZoUQPc6X278k9eVUXl79MtdNuI7t123njJQz3F0s0Uesr6igTtMY6+/P5qoqijux32yNzcb6ykomO2oWB/n4YNE0sqWpcZusdjvLzeZObWLcnOkhIWwaP54zw8O5Z+9ejl6/nr09qPbcmfypI82MmxNoMvHy4MG8PWQIv5eX83JursvrZtXWMn//fi6PiSHGy6th+riAAF4bPJglZWXcuWdPu8pj0zQezMhghJ8fZ0itbI81JTCQlRUV7b75sb6yskf2l21sZmgo6ysrya2rY21lZaf1l3WaFR5Old3OL2Vl7Kiuxt9oJKaXJJ/rjSSYFUL0GNnl2cz6ZBazF84mzDeMFZet4MWTXiTQq3ObHIrDm7Pp3J2JiQD83om1s+srK7FqWkMw6xzLUPrNtm1zVRWVNluXB7MAIR4efJyayocpKWyuqmLUmjX81YFaqK6wrqKCaE/PA4LHznBJdDQnhoZy5549Ljd9fyIrC4DbHZ+VxubFxHB9XBxP5+TwiSMrrisWFhSww9FXVmple64pgYGUWa3scNQsuqKgvp68+voe21/WaWZICADPZGdTa7d3Wn9Zp2NDQggwGllcVERadTVDfX2lX3gXkmBWCOF2+yv3c/tPt5Pycgo/pv/I48c9zpor1jApfpK7iyb6oOVmM/28vTktPBwfg6FTmxr/1SSZSEMw24Nq/nqqPxzBZHcEs6AnS7ogKopNEyYQ7uHBudu2dTi7dZ3d3qHmts1ZV1nZabWyjSmleGPwYExKcfmOHW3WuO2rq+Otffu4ODqaRG/vZpd5ZuBApgUFcemOHWx01Ci3xqZpPJiZyXA/P2b3wKFbxN+cN+Ta02+2pyd/chobEEC4hwev5uUBnZf8ycnLYOCk0FD+r6iI7dXVDHH8DoiuIcGsEMJtcsw53PDdDfR/vj9Pr3ia04acxpZrt3D7EbfjYez8PnNCaJrG8vJypjrGMZ0SGNipSaD+Mpvp7+1NlKNJWZyXF55KsVuC2Tb9UV5OgpdXi4FTV0ny9uaT1FRy6+u5YscOtHY2qyyqr2fU6tUkr1p1yEP/1NhsbKuqOqTkT62J9/bm6YEDWVpWxuuOC/mWPJWdjVXTGlowNMfDYOCz1FRCTCbO2LKFkjZuBnxWUMD26mr+I7WyPd5gX19CTKaGG3SuWO/IRTC6hwezBqU4PiSEGrudcA8P+nfBd86s8HAKLBZy6uqkv2wXM7m7AEKIw8+e0j08/sfjvLvhXTQ0Lhx5IXdOu5PBYYPdXTTRx2XV1ZFXX89UR+3fMcHB3JuRQanF0ilJh/5q0ufTqBT9vb2lZrYNmqbxR3k5RwcHu2X/EwMDeaR/f27fs4fX8/K4Oi7OpfVqbTZO37KFjNpa+nl7c8rmzcwOD+f5QYOI78AF8uaqKmx0Xn/Z5lwWE8PCwkJuS0/nxNBQ+jVTa1RYX89reXmcHxXV0LqgJdFeXiwaNoyjNmzg3G3buDwmBrPVSoXNhtlmw2y1YrbZqLBa+b28nFRfX86SWtkez6AUkwMD210z28/bu0sSuHW2maGhLCgoYFJAQJc0AT4xLAwPpbBomgzL08UkmBVCdJu0ojQe/eNRPtr0EUaDkcvHXs7tR9xOv+B+7i6aOEw4s3M6h345OjgYDVhWXs5ph5iMJreujuy6uobmeU4yPE/bMmpryauv77Ymxs25JSGBX0pL+Vd6OkcEBTGijYDSrmlcnJbGcrOZhampnB4ezjPZ2TyQmcmPq1fzQL9+/DMuDlM7sqQ6x27tqppZ0JsbvzVkCMNWr+aKnTv5ceTIgy7mn8vJocZu5+5WamUbmxwUxMvJyVy5cyc/lZYeMM/PYCDAZCLQaCTRy4snBw6UWtleYnJgIN9nZFButRJkajtkWFdZ2eObGDsd7xii58guuoEWZDJxbHAwP5aWSs1sF5NgVgjR5Wx2G/f/dj8P/f4Q3iZvbph0A7dOvZXYgFh3F00cZpabzfgaDIx0jIE4MSAAL6VYWlZ2yMHsSkcNRnPB7O/l5WiaJklAWtDd/WWbY1CK+SkpjFq9mnO2bWPNuHH4tjK8yF179rCwsJAnBwxgTmQkAHcmJXFOZCTX7drFzenpvJ+fz+uDBzPRxT556yorCTWZSOzk5E9NJXp78+SAAVyzaxdv7dvHFbF/fxeXWiy8mJvLnIgIhrZjrNArYmM5NjiYOk0j0GgkwGjE32hsVzAvepYpgYFowGqzmeNCQ1td1my1srumhouiorqncIco2suLjePHM6ALuzVcERNDRm0tgyWY7VLyDSOE6FJF1UWctOAkHvz9QS4adREZN2XwzMxnJJAVbrG8vJxJgYENF9jeRiNTgoI6JQnUX2YzXkod1F9soI8PlTYbhZ04BFBfs6y8nCCjkWHtCJ66QpSnJx+mpJBWXc1Nu3e3uNxrubk8kZ3NNbGx3OIYf9Wpv48P/xsxgs+HDaOgvp7J69Zx7c6dlLlw/NdVVDC2i5o9NnWlI/i8JT2drEbZtl/MzaXCZuOepPaP6T3I15dhfn4keHsT7OEhgWwvNzEwEIVrSaA29pLkT42l+vnh3YXj4Z4VGcmOSZPwks9Bl5J3VwjRZVblrmLs62NZmrGUN055g3dPf5dIv0h3F0scpqpsNjZUVjK1SS3Z0UFBrK+sdCnYaM1fZjNjAwLwbHLhMtBx578vNjX+s7ycEzZu5MmsrEMaq/WP8nKOCArC2ANqro8LDeXOxETe3LePTwsKDpr/bXEx1+3axcmhobwwaFCzgadSijMjItg+cSI3xMXxel4eI9asaTXjb73dzuaqqi7tL9uYwdHc2KZpXOlIfGW2WnkuJ4fTwsIY2YuCEtE1gkwmUn19XQpmGzIZ9/AxZkXf023BrFLqBKXUDqXUbqXUnc3MT1RK/aqUWq+U2qSUOqm7yiaE6FyapvHq6leZ9s40DMrAn5f+yRXjrpAmlsKt1lRUYAOmNGnKeoyj3+wfhzDOqMVuZ01FxUFNjKHvDs+TW1fH7C1b+KO8nNv37GHAypWMX7OGx7Oy2vVai+rr2V5d7dYmxk3d368fkwMDuXLHjgOC9PUVFZy9dSuj/f35JDW1zZrHQJOJ55KT+WvsWDRNY9r69XzXQsbjbVVV1Gtal/aXbWqAjw+PDxjAD6WlvLd/P6/m5VFqtfLvDtTKir5pSlAQf5nNbQ7ltL6ykggPD2IdmdyF6C7dEswqpYzAy8CJQCpwnlIqtcli/wYWapo2BjgXeKU7yiaE6FzVlmouXnwx1357LTMGzGDtlWsZHzve3cUSguWOYLVpwDkpMBBPpfjtEILZzVVV1NjtzQaz/b29UUB6o6acvV293c7ZW7dSZbOxatw49kyaxBMDBmBUijv37GHQypWMXbOGRzIz2Vld3epwN8sdtT49KZj1MBj4OCUFBZy7bRsWu52s2lpO3ryZUA8PvhkxAn8XEuI4TQgMZOW4cQzy8eHUzZubHRZnnaNmq7tqZp2ujYvjqKAg/rV7N09lZzMzJIQJnTzupui9JgcGUmq1squNG1TrKyoY4+8vN61Ft+uumtmJwG5N0/ZomlYPfAKc3mQZDXB+ewYBrQ+AJoTocXYV72LyW5P5cNOH3H/M/fzv/P8R5hvm7mKJTlZUX89aR9bV3mS52cxQX1/Cmgwb4WM0MukQx5v9q4XkT6D3y43z8upTNbO3pqez3GzmnaFDSfXzo7+PD7clJrJy3DgyJk/m6YED8TIYuGfvXoasWkX8ihXM2bqVZ7KzWVFeTp3d3rCtP8rL8VSKCT2seWI/Hx/eGjKEVRUV/Gv3bk7evJkqm41vR4wgpgMJmuK8vPh99GhmhoZy9c6d3JaefkBt17qKCgKMxjaHwulsBqV4e8gQ6jWNIouF//Tr1637Fz2bM/P7ilZu9tXZ7Wytru7WVgVCOHVXNuM4ILvR/znApCbL3Af8qJT6J+AHHNfchpRSVwJXAiS6mDJeCNG16qx1vLfhPW7/+XZMBhPfXvAtJww6wd3FEl3kzj17+KSggLJp03pNghdN01hRXs7pLWQsPiY4mIczMzFbrQS2o8bN6S+zmRhPTxJaCHIGdnCs2Y6Wpyt9uH8/L+bmcnN8PGdHHtwHPsnbm5sTErg5IYHs2lr+r7iYP8vLWWE283lhIQCeSjEuIIApgYF8W1LC+ICALk3E0lFnRUZyVWkpL+flYVKK70eOZPgh1JwGmEx8NXw4NzpqQffW1PBBSgo+RmPDsCbuGLZmkK8v84cOZUNlJUf0oBpy4X5DfX0JMhpZYTYzLyam2WW2VlVh1bRelfxJ9B096SrkPOA9TdPigZOAD5RSB5VP07Q3NE0br2na+AgZdFsIt6q2VPPcX88x8IWBXP2/qxkROYK1V66VQLYP0zSNn0pLqbLb2dmLahp31dRQbLUytYUL9aODg7HT8X6zf5nNTA4MbLGJ3aAOjDX7ZWEhQX/8wfU7d1JhtXaoXJ1tU2UlV+7cyVFBQTw2YECbyyd4e3NdXBwLUlPZO3kyeVOm8MWwYdwQH48BeDk3l7TqaqaHhHR94Tvo2UGDODcykg9TUpjRCeU0GQy8lJzM0wMH8kVREcdu2MC+ujo2VFa6tWZrTmQkD7twTMXhxaAUkwIDG1qfNGd9L8xkLPqO7rrdmws0zl0f75jW2GXACQCapq1QSnkD4cDBqQSFEG5lrjPz8qqXefavZymsLuTopKN5b9Z7zOg/Q/rL9HF7a2vJqqsDYENlJaluHkrFVc7+slNa6As4JTAQD6X4rayMk8La1zS+2GJhV00Nl7dQawF6Eqh8i4VKq9Xlvpbfl5TgoRSv5OXxdXExbwwZwsw2xnrsSmUWC7O3bCHEZOLT1FQ8OlArH+PlxRkREZzhuBldb7ezvbqawd3ctLY9fIxGPk5tmubj0CiluDkhgX7e3szdvp1Ra9ZQY7d3e39ZIVwxJTCQBzMzqbBaCWjm+2u9m5rICwHdVzO7GkhWSvVXSnmiJ3j6vybLZAEzAJRSKYA3UNhN5RNCuKC4upj//vpfkp5L4u4ldzMudhzLLlnG0nlLOW7AcRLIHgaWlJY2/N3aMCM9zXKzmWCTiaEtDF7vazQyMSCgQ+PNrmylv6yT8yJvTzuSQC03m5kREsKyMWPwNRo5YdMm5m3fTokbxqu1axoXpqWRWVfHZ8OGEd2BPqPN8TQYGOXvj08PbGLcHWZHRLB09Gic35zjpM+h6IGmBAVhB1a1kCthfWUlo9zURF6IbglmNU2zAtcDPwDb0bMWb1VKPaCUOs2x2C3AFUqpjcDHwDyttfSHQohuY7FZuH/p/SQ9l8SDvz/Isf2OZc0Va/jugu+YljjN3cUT3WhJWRnRnp6M9vdnQ28KZsvLmRIY2OrF1tHBwaypqGh3k96/zGaMtB6IOIPZ3S42NS63WtlaVcWUwECOCApi/bhx3JOYyIf5+aSuWsWiwu691/tIZibfFBfz7MCBLTbVFh0zMTCQVePG8WFKCikt3GwRwp0mOr7bmmtqbNM0Njr6ewvhDt2WVULTtG+Bb5tM+2+jv7cBR3RXeYQQrkkvSeeCLy5gZe5K5qTO4b9H/5fhkcPdXSzhBpqmsaS0lBkhIXgaDC2Ol9nTlFksbK2u5txmkhU1dkxwMI9kZbHcbG5Xc96/zGZG+vvj10rt4kBvb8D1sWZXmc1o/N0s2tto5KEBAzgrIoJLd+zgrK1bmR0ezsvJyZ1WS9qSH0pK+G9GBhdERnJdXFyX7utwleTtTZLjHBGipwnx8CDF17fZjMa7a2qostslmBVu05MSQAkhehBN05i/YT6jXx/NjuIdfHrWpyycs1AC2cPY9upq8i0WpoeEMNrfn3yLhf2O/rM92UpH07gpbdQoTg0KwuToN+squ6ax0pH8qTXBHh6EmkwuB7PLzWYU+hi4jY0OCGDV2LE8NmAA/ysuJnX1anZWV7tc3vbKqKnh/G3bGO7nx+tDhkhXAiEOU1McSaCaNppc7/h+lWBWuIsEs0KIg5TVlnHeovOY99U8xsaMZePVGzl72NnuLpZwM2d/2enBwYxyJH7aWFXlziK5ZHl5OQb+birXEj+jkQkBAe0abzatuhqzzdZmMAt6U+N0F/vMrigvZ7ifX7PD8pgMBu5ITGTt+PGUWq0sLipyubzt9Z+MDOo1jS+GDWu15lkI0bdNDgyk2Go9qKvE+spKPJTqNckARd8jwawQ4gC/Z/7OqNdGsWj7Ih6e/jBLLlpCYpCM6Sz0/rL9vL3p7+PDKMdd+N7Qb3a5oxlwc1k4mzo6OJjVFRVU2WwubfsvF5I/OQ10cXgeu6bxl9ncYuZlp2F+fgz09mZVK0NmHIo6u52vioo4JyKCQdKXU4jDmvP7aEWT75v1lZUM9/PDs5eMOS76HjnzhBCAnuTp30v+zbHzj8XT6Mmfl/7J3UfejdEgtTFCT/KxtKyM6cHBgN6HKtHLq8dnNLY5AsOpLgSboPebtWpaw1A+bfnLbCbEZCLZhSEpBnp7k1Vbi8Vub3W57dXVlNtsLiVamhgY2NCMurP9WFJChc3GWTKmuxCHvVQ/PwKNxgOCWU3TWC/Jn4SbSTArhMBcZ+bY+cfy8LKHmTdqHuuvWs/EuInuLpboQTZWVlJqtTI9JKRhWm/IaLy1qopKm63NWk6nqYGBGMHlfrN/OfrLutKXdKCPDzYgs42mxivaGBO3sYkBAeTU1ZHXBX2XPy8sJMRkYkajYy6EODwZlGKio9+sU25dHUUWiwSzwq0kmBXiMFdVX8VJH53EytyVLJi9gLdPfxt/T/lhEgdy9pc91lEzCzDK358d1dXUuNgk1x2cNayuDicTYDIxLiCA31yoma2wWtlSVeVSE2P4e3ietvrNrjCbCXOxtneiY9+rO7l2tt7RxPj08HA8pPmgEAL9BtumykoqHcOXrXfczBwj4yMLN5JfKCEOYzWWGk775DRW5KxgwewFnDfiPHcXSfRQS8rKGOrrS2yjYWBG+/tjB7b04CRQy81mojw86N+OYU+OCQ5mpdlMdRtB+uqKCjRc6y8LjYLZNvrNLjebmRIU5FJt7xh/f0xKdXq/2Z9LSymXJsZCiEamBAZi5++bZ+srK1HQkBBQCHeQYFaIw1SdtY4zF57Jr3t/Zf6s+cwZNsfdRRI9lMVu5/dG/WWdnEmgenK/2eXl5Ux1MTB0Ojo4GIujr21rnPPbypLsFOPpibfB0GowW2KxkFZd7XKzaB+jkZF+fqzq5JrZzwsLCTQaOU6aGAshHJxDhTm/+9ZXVpLs44O/C8n1hOgqEswKcRiy2Cyct+g8vtv9Ha+f8jpzR851d5FED7a6ooIqu/2A/rIA/b29CTAae2y/2YL6etJra10ODJ2mBQVhgDaH6PnLbCbF15dgDw+XtmtQioHe3q0GsysdF4ntKfPEwEBWm83Ym4z/2FEWu53FjibGXtLEWAjhEOrhwRAfn4YkUOsrKqS/rHA7+ZUS4jBjs9u4ePHFfJn2Jc+f8DxXjLvC3UUSPZyzv+wxTWpmDUox0s+vx44167zgcrW/rFOgycTYgIBmk0Dl1Nbywf79XJqWxs+lpQ01Fa5qa6zZ5WYzRmBCO/qgTQwIoNxmY5cLw/64YklZGaVWqzQxFkIcZEpQECvMZkosFjLr6qS/rHA7aRcgxGHErtm54usr+HjLxzw24zFumHSDu4skeoElZWWM9vcnrJkayNH+/ryfn49d0zC0oynvoTp/2zbWVVTwYP/+nBUR0Wwz4uXl5XgoxbgO1BwcHRTES7m5ZNbWsqK8nF/Lyvi1rKwhYAw1mTgxNJSb4+Pbtd2BPj78XFqKpmnNlnlFeTkj/f3b1WzPmQRqldnMkE4YD/bzwkICjEaOlybGQogmJgcG8t7+/SwqLASQmlnhdhLMCnGY0DSNf377T97d8C73Hn0vd0y7w91FEr1Ajc3G8vJyrouLa3b+KH9/KvLyyKitZYAL2Xc7Q52jGaxd0zh72zYmBQTwxMCBHNWk5ni52cy4gAC8je0fK/mY4GCezsmh319/ARBoNHJ0cDDXxMYyPSSEEX5+HQreB/r4UG23s7++nphGybRAHxN3ZUUFF0VFtWubQ3198TcaWVVRwYXR0e0uU2NWu50vCws5NSysQ++bEKJvc3aBeDUvD5BgVrifBLNCHAasdit3/HQHr6x5hdum3sa9R9/r7iKJXmKF2Uydph3UX9ZptONCZkNlZbcFs6vNZmrsdhYNG0a51cp/9u7l6A0bOCUsjMcGDGCYnx/1djtrKiq4Jja2Q/s4LiSEa2NjSfT2ZnpwsJ41uBP6jw50ZFXeXVNzUDC7xTEmbnubRRuVYnxAQEN/20OxtKyMYmliLIRowTA/P/yNRtZXVhLn6UmEp6e7iyQOc9JnVog+zGq38v7G90l5OYVn/nqG6ydcz+PHPd6uzK7i8LaktBQjcGQLAdZwPz8MtC+jsaZpLMjPb3Pom5b8WlaGQq89vSQmhl2TJvHYgAEsKytj5OrVXJaWxjfFxdTa7UxtZ59WJ2+jkZcHD+aOxEQmBAZ2SiALrQ/Ps8Ixtm17E1aB3m92Q2UldXb7IZXv88JC/AwGTggNPaTtCCH6JqNSDRncpb+s6AkkmBWiD7LZbXy46UOGvTKMixdfjJ+HH1+e8yUvnPiCBLKiXZaUlTEhMJDAFvpw+hiNDPH1bVdG4x9LS7lg+3be2revQ2VaWlbGKH9/Qh19eH2MRu5ITCR98mRuio/nw/x8zty6FWh/8qeuluTtjQGaTQK13Gwmsp1j4jpNDAzEommHNEySTdP4oqiIU8LC8JEmxkKIFjhvuEkTY9ETSDArRB9is9tYsHkBw14ZxoVfXoiX0YtFZy9i3VXrmDV0lgSyol0qrFZWmc0HjS/b1Ch//3YFUZ8WFADwfUlJu8tUZ7ez3Gw+KLMyQJiHB08PGsSOiRO5MCqKM8PDiW3SlNfdPA0GElsYnmeF2dzuMXGdnDUlqw6hqfHvZWUUWizSxFgI0aojHDcJx0nNrOgBpM+sEH2Apmks3LqQ+3+7n+1F2xkeOZzP5nzG7JTZGJTcsxIds6y8HBu02F/WabS/P58UFFBqsRDSxpir9XY7XxYVodBrWGtttnYlGlplNlNrtzcbzDr18/Hh/ZQUl7fZ3Zoba7awvp7dNTVcERPToW3Ge3kR4+nJqoqKDpfr88JCfAwGTgwL6/A2hBB938zQUBYNG8Yp8l0hegC5yhWiD3hq+VOcu+hcDMrAwrMWsvHqjZyVepYEsuKQLCktxVOpNvudjvLzA2CTC+PN/lxaSpnVyjWxsdTY7Sxz9BN11VJHf9mW+vD2BgN9fA4KZp1j4nakvyyAcvRj62jNrLOJ8UmhofhJE2MhRCsMSjE7IgKjtPYSPYBc6QrRy20p2MK/f/03Zww9g03XbGLOsDkSxIpOsaSsjKlBQW32n2yc0bgtnxYUEGwy8XD//ngp1e6mxk37y/ZGA318KLZaKbdaG6atMJsxObISd9TEwEB21NRQZrG0e90/y8vZX1/PnMjIDu9fCCGE6G5yxStEL1Zvq+eiLy8iyCuI1095XYJY0WmKLRY2VFa22V8WINrLi0gPjzb7zTrHhz0jPJxgDw+OCg5uVzDbWn/Z3qS5jMYryssZ4+9/SImXnP1m13SgqfHnhYV4GwycJFmMhRBC9CJy5StEL/bQ7w+xfv963jj1DSL8JGlLX/B1URHT1q3j8rQ0XszJ4beyMko7UNN2qH4rK0Oj7f6yTqP9/dusmf2xpASzzcbZjgRDJ4SGsq26mqxmMvs2x5X+sr2Bc6xZZzBrsdtZVVHR4SbGTs5a3fb2m7VrGosKCzkhNJSAFrJWCyGEED2R/GoJ0Uutzl3NI8se4aJRFzFr6Cx3F0d0kkWFhayuqCCtupq39+9vmJ7g5cUof39G+vlxZFAQM0NDuzQ79ZLSUvwMBia42Ox1lL8/z+fkYLHb8WhhTNZPCwoINZmY4QiQTwgN5Zb0dH4oKeGK2Ng29+HsL3tUL+4vCwfXzG6qqqLGbj/kYYSCPTwY4uPDynb2m11hNpNXX88cyWIshBCil5GaWSF6oRpLDRctvoiYgBieP+F5dxdHdKKsujrGBwRQeMQR5E6ZwncjRvDYgAEcGRRERm0tT2Rnc+LmzXxWWNil5VhSVsaRwcF4thCYNjXa3596TSOturrZ+TU2G18VFzM7IqIh2E3x9SXBy8vlpsZLy8oY7e/fZsbkni7AZCLSw6NhrNkVjiRYh1ozC3q/2ZVmM5qmubzO54WFeColmUmFEEL0OlIzK0QvdM+Se0grSuPHuT8S7B3s7uKITpRZW8ukwECUUsR6eRHr5cUJjYKMWpuNI9av56bduzkhNJTALmgWuq+uju3V1VwSHe3yOqMcSaA2VlYywvF3Y9+XlFDZqIkx6Bl4TwgN5dOCglZrdOHv/rLXuFCD2xs0zmi83Gwm1tOThE4YE3diQAAf5OeTU1dHgqM5c2vsmsbnhYXM7KJzSQghhOhKUjMrRC/zW8ZvPPfXc1w7/lr+MfAf7i6O6ER2TSO7ro7EVoIab6OR1wYPZn99Pf/du7dLyvFrWRngen9ZgCE+Pngp1WK/2YWFhYR7eHBsk/6uJ4SGYrbZ+KuNprEr+0h/WafGwewKs5mpQUGd0mx8oqN219V+s6vMZnLq6qSJsRBCiF5JglkhepGKugrmfTWPASEDeOIfT7i7OKKT5dfXY9E0EtuoUZsQGMjVsbG8mJvL+g5krm3LktJSgk2mhiF3XGEyGBju58fGZsaarbbZ+LqoiDPDwzE1qX2dERKCEdpsatwXxpdtbKC3N9l1dWTU1JBRW9spTYxBryH3VMrl8WY/LyzEQylOlSbGQggheiEJZoXoRW758RYyyzKZP2s+fp5+7i6O6GSZjj6USS40D32kf3/CPTy4ZudO7O3oH9mWSquVRUVFnBAairGdNYXOjMZN+2t+W1xMld3OOc2MYRpkMjE1KMilYLYv9Jd1GujjgwZ8XFAAdE5/WQAvg4HR/v4u1cwW1Nfzzv79nBgaSnAfeV+FEEIcXiSYFaKX+HbXt7y57k1um3obRyQe4e7iiC6QVVcH0GozY6dgDw+eHjiQlRUVvLlvX6eVYX5+PmVWKzfExbV73VH+/hRZLOyrrz9g+sLCQiId48o254TQUNZVVpLfZD2nWpuNFX1gfNnGnBmNP8jPx1MpxrqYNdoVEwMDWVNRga2Nmxy3p6dTabPx2IABnbZvIYQQojtJMCtEL1BcXczl/3c5wyOH88CxD7i7OKKLOMdbbauZsdMFUVEcGxzMnXv2UNBCINgedk3juZwcJgUEMKUDzXmdzZIb95uttFr5priYsyIiWqzpnRkaCujj0DZnVUVFn+ovC38Hs9urqxkXEICXi1mjXTExIIBKm63FzNIAv5eVMT8/n1sTEkjxk1YeQggheicJZoXowXaX7OaWH24h+cVkCqsLeX/W+3iZDj3jqeiZMuvqCDIaCXIxq6xSileSk6my2bgtPf2Q9/9NcTG7a2q4OSGhQ+uPbJTR2Ol/JSXUtNDE2GmMvz8RHh4tNjXua/1lASI9PPBzBLCd1cTYqSEJVAv9Zuvtdq7ZuZN+3t78OympU/cthBBCdCcJZoXoYWx2G/+34/844cMTSH4xmRdWvcBxA45j2SXLGBMzxt3FE10oq7bW5VpZp6F+ftyWkMD7+fn85shC3FHP5uSQ6OXF7PDwDq0fZDLR39v7gJrZhQUFxHh6ckQrgahBKWaGhvJjaWmz/X/7Wn9Z0G9EOGtnp3ZykJ7s40OQ0cjKFoLZZ3Ny2FZdzYuDBuFrNHbqvoUQQojuJMGsED1EQVUBjy57lAEvDOD0T05nc8Fm7j/mfjJvymThnIVMjp/s7iKKLpbVxrA8LbknKYn+3t5cs3Mn9XZ7h/a9vqKCpWVl/DMu7qCMw+0xyt+/oWa2wmrl25IS5rTSxNjphNBQiiwW1jVJXNQX+8s6OYPZzq6ZNSjFhMDAZpNAZdbW8kBGBrPCwzmlgzcthBBCiJ5Cglkh3EzTNP6z5D8kPJvA3UvuZlDoID6f8zkZN2bw36P/S2xArLuLKLpJZm2tS5mMm/I1GnkpOZnt1dU8k53doX0/m5ODv9HI5TExHVrfabS/Pztraqiy2fi6uJhau52zW2li7HR8SAiKg4fo6Yv9ZZ1OCQvj1LAwYjtwA6MtEwMC2FRZSY3NdsD0G3btAuD5QYM6fZ9CCCFEd5NgVgg3e2r5Uzy07CHOTDmTbddu45eLfuHM1DPxMPadJpWibRVWK6VWa7ubGTudFBbG7PBwHsjMJKOmpl3r5tXV8UlBAZdGRx/yEC2j/PzQgC1VVSwsKCDO09OlmscIT0/GBQQcFMw6+8se1Yf6yzpdGhPD/40Y0SXbnhgYiA1Y36jJ9/8VFfF/xcXc169fh88zIYQQoieRYFYIN1qweQG3/3w75ww7hw9nf0hKRIq7iyTcJLsdw/K05LlBgzAAN+ze3a71Xs7Nxapp3BAf3+F9OzkzGv9eVsZ3JSWcHRmJwcXxak8IDWWF2UypxdIwbWlZGWP8/WUc1Haa6Bjqx5kEqspm45+7djHcz4+bOuE4CyGEED2BBLNCuMmSvUuYt3geRycdzfxZ8zEo+TgezjIdw/J0pJmxU4K3N/f378/XxcW84+LYs9U2G6/l5XF6eHhDH85DkeTtTZDRyFPZ2dRrGmdHRLi87gmhodiBX0pLAb2/7PLy8j7ZxLirxXh5keDl1dBv9sGMDLLq6ng1ORmPThwGSAghhHAn+UUTwg0252/mjE/PYHDYYBafu1iG2xFkdULNLMANcXEcFxLClTt28HVRUZvLf5CfT4nVys2dVFunlGKUvz8FFguJXl5Makdyo0kBAQQZjQ1NjVdWVFCnaRLMdtDEgABWmc1srari6ZwcLo2OZpq8l0IIIfoQCWaF6GbZ5dmc+NGJ+Hv6890F3xHsHezuIokeIKu2FpNSxBxiMOthMPDlsGGMDQjg7G3b+L2V4Xrsmsaz2dmM8/dnWif2SR3laGp8dmQkysUmxgAmg4F/hIbyfUkJmqb1yfFlu9PEwEDSa/+/vTuPj7Ms9z/+vWcmk0z2Nk3apumSQAu0tGyllM0FRNkEFD2CK/pT3FDQg4B69CgeFZejooLKUQHXgoiK0goHBA9LF0op0L2la9KmSdvss8/cvz8yqWmbZZLMzDMz+bxfr75onnkyc7Udx3573/d1BfWBjRtV7nbrWw0NTpcEAEBKEWaBDGoPtuuS316irnCXlr1nmaZXTHe6JGSJXcGg6goLhx1hk4xSj0dL58/XrKIivfXVV7V2gBEtUm/n4M2BgD4zffqIQudw+s5rXpNEF+OjXTxxoprCYa3v6eG87Bj1/Tm82N2tbx93nCZ5vQ5XBABAahFmgQwJRUN62wNv05aDW/Snd/1JCyYvcLokZJHRzpgdzCSvV48vWKAKj0dveeUVbfP7j7nn+42Nmub16p0jONeajGtqarT6jDN0RiJMjcRbJkyQJP35wAEt57zsmJxRVia3pHPKy/XBKVOcLgcAgJQjzAIZELdxXfeX6/T0zqd131X36YL6C5wuCVlmdzCY8nEp04uK9PiCBYpZq4teeUV7E+dyJemV7m490damG6ZNkzfFDYE8Lteogqwk1RUV6eSSEn2/sZHzsmNU5vHor/Pn68F585LuKA0AQC4hzAIZcNsTt2nJuiW648I79O7573a6HGSZaDyuxlBIM1O4MtvnxJISLVuwQAciEb3llVcOj735QWOjil0uXV9bm/LXHKuLJ07UoWiU87IpcElVlaal4X0FAEA2IMwCafarl3+l7zz/HX1i4Sd0y7m3OF0OstC+cFgxKeUrs33OLC/Xn08+WVv8fl3+6qvaHgjot/v367opUzQxC8+jXjxxoiRxXhYAAAyJMAuk0eq9q3X9X6/XG2e9UT+4+AcpbbKD/JGqsTxDuXDCBP1u7lyt6OzUmS++qLC1ujFF43hS7byKClV5PLokEWoBAAAG4nG6ACBf7e/er7c98DZNKZ2iB97xgArcrDBhYLuCQUnSzDStzPa5urpaP50zR9dv2aLLq6o0p7g4ra83WoUulzYuWqQKD/8XBQAABsffFIA0CMfCeucf3qmD/oN67kPPqboktd1ikV92J8Ls9AycbfxIba2O8/k0v6Qk7a81FtWMkQEAAMMgzAJp8NnHPqtndj+j3739dzpt6mlOl4MstzsU0kSPR6UZWom8IDH+BgAAIJdxZhZIsV+s+YXueuEu3Xz2zbp2/rVOl4McsCsYTPsWYwAAgHxDmAVSaEXjCn1i6Sd0UcNF+uabvul0OcgRu0OhtDZ/AgAAyEeEWSBF9nXt09sfeLvqyuu05B1L5HGxiz/ftITDet/Gjdrm96f0eXcHg2kbywMAAJCvCLNACoSiIV394NXqCHXoz+/6syb6GClytFe6uzVn5Up9Y9cu9cRiTpczYt3RqC579VX9Zv9+/b6lJWXP2x6JqDMWY5sxAADACBFmgRT41LJPaXnjct135X2aP3m+0+VkpWc7OrQ1ENAXd+zQ8StX6idNTYrE406XlZRIPK53rF+vl7q6VOXx6NmOjpQ9dyZmzAIAAOQjwiwwRn/Z9Bf9z5r/0W3n3qZ3znun0+VkraZQSG5Jz5x6qmb7fPrE1q06adUqLdm/X3FrnS5vUNZafXjzZj3W1qafzpmjf6up0fLOTsVSVHPfWB62GQMAAIwMYRYYg65Ql25YdoPm18zX7W+83elyslpTKKSphYU6r7JS/zz1VD06f75K3G5du3GjznjxRf394EHZLAy1/7Fjh361f7++OmuWPlxbq/MqKtQVi+nV7u6UPP+uxMrsTFZmAQAARoQwC4zBl576kpo6m3TPW+9RgbvA6XKyWmMopGleryTJGKNLq6r00sKF+u1JJ6kjGtUlr76qC15+WXsT4S4b3N3UpG/s3q3rp07Vl2bOlCSdV1EhSSnbarw7GJTXGNUkfm8AAACQHMIsMEqr967Wj1b9SB9f+HEtrlvsdDlZrykcVt1Rq48uY/TuyZO1adEi/Xj2bK3o7NTnt29PWw0Pt7bqnDVr9KPGRrVHIsPee8PWrbqiqkp3zZ4tY4yk3u3AdYWFqQuzoZCmFxbKlXh+AAAAJIcwC4xCNB7V9X+9XpNLJusbF37D6XJyQlMopGmDbKX1ulz65LRp+mRtrX6zf7829fSkpYZHDx7U8s5OfXrbNtUuX64PbdqkVZ2dx2xvfqa9Xe/esEGLy8v1+7lz5XEd+VF5XkWFnunoSMm26F3BIJ2MAQAARoEwC4zCD1f+UC81v6QfXvJDVRRVOF1O1uuKRtUViw0aZvvcMmOGfC6Xbt+1Ky11NIVCWlhWptVnnKH3Tp6sB1tadNaaNTr9xRf1s7171RWNakNPj65Yt06zior01/nzVex2H/M851VUaG84rF2J5k1jwYxZAACA0SHMAiO0q32XvvTUl3TZ7Mt09UlXO11OTmhKnIMdLszWeL36VF2dlrS0aF2KGiwdUUc4rGler84oK9M9J5ygveeco7tnz1bcWn1syxbVLl+uN6xdqyKXS39fsEBVBQOfg+47N/tcZ+eY6onE49obDjOWBwAAYBQIs8AIWGt1w7IbJEl3XXrX4XOUGFpTOCxJhxtADeXm6dNV6nbrq2lYnT16q3O5x6OPT5umtQsXavlpp+nqSZM0wePRsvnzNcvnG/R5Ti4pUbnbPeZzs42hkKzENmMAAIBR8DhdAJBLHt74sP625W/67kXf1czKmU6XkzOSXZmVpKqCAt1UV6ev7dqltV1dOrWsLCU1BGIxtUWjA9ZgjNHiigotrkhuy7jbGJ1dXj7mMLs78fvCyiwAAMDIsTILJKkj2KFPLfuUTp1yqm5cfKPT5YxIzFr9fO/eYTv4pkvjCMKsJH22rk4Vbre+snNnymoYSaBOxnkVFVrX06O2Mfye9p255cwsAADAyBFmgSR98R9f1P6e/brn8nvkceXWpoYHWlr0kS1b9PN9+xx5/aZQSBM8ngGbKQ2ksqBA/z59uv5y8KBWj/Fc6uEaRrDVORl952aXj6G+3YkwO52VWQAAgBEjzAJJWNG4Qne/cLduOPMGnTntTKfLGZGYtbo9scL5TIpmo47UUGN5BnNjXZ0mejz6zxStzqZ6ZXZRebk8xoxpq/HuUEg1BQXyJRnyAQAA8C+EWWAYkVhEH/3bR1VbVquvXfA1p8sZsSUtLdocCGhmYaGe7ehQPAWzUUeqr4vwSJR7PPrc9OlaeuiQlqcghKc6zBa73Tq9tHRMYXYXY3kAAABGjTALDOO/l/+3Xtn/in586Y9VXljudDkj0rcqO7+kRF+eNUuHolFt9PszXsdoVmYl6YZp01RdUKAvp2B1tikUUqnbrXJP6raIn1dRoVWdnQrF46P6/t2hkGayxRgAAGBUCLPAELYc3KKvPP0VXX3S1brqxKucLmfEfr9/v7YEAvrPWbP0+spKSdIz7e0ZrSEaj2t/ODyqMFvq8ejWGTP0RFub/m+MdY9mdXg451VUKGStXuzqGvH3Wmu1m5VZAACAUSPMAoOI27g+/MiH5Svw6ceX/tjpckYsGo/ra7t2aUFJid42aZIaioo01esd8ziZkWoOhxXX6Lf3fry2VlO8Xn15xw7ZMWyRHu3q8FDOTTSBem4Uv6cHIxH543HG8gAAAIwSYRYYxM9W/0zP7H5G33vz9zSldIrT5YzYkpaWw6uyLmNkjNF5FRUZbwLVN5anbpShrdjt1hdmzNA/Ozr01BhWZ9MRZmu8Xs32+Ub1DwSHZ8yyMgsAADAqhFlgAHs69ujWJ27VmxrepOtOvc7pckYsGo/r9sSq7FWTJh2+fn5FhXaHQodHwmRCKkbifGTqVNUVFupLo1ydjVurfaPc6jyc8yoq9NwoGmv1/RnMJMwCAACMCmEWOIq1Vh9/9OOK2ZjuufweGWOcLmnEft/Soq2BgL6SWJXtc35iW2wmV2dT0UW4yO3WF2fM0POdnXrs0KERf/+BSEQRa1Wb4jOzUm+YPRiNavMIG2vt6luZZZsxAADAqBBmgaP8ft3v9ejWR/X1C76u+gn1TpczYn2rsqeUlOjKfquykjS/tFTlbndGm0A1hULyGqNJBQVjep4PTZ2qCR6P/njgwKhqkFI3lqe/8xL/QDDSrca7g0H5XK4x/74AAACMV4RZoJ/WnlZ9etmndda0s/SpRZ9yupxR+V1Li7YNsCorSW5jdG6Gz802hUKqLSwc8wq31+XSHJ9POwKBUdUgpSfMzvb5VF1QMOImULtDIc1Iwe8LAADAeEWYBfq56bGb1Bnq1C+u+IXcLrfT5YxYXwfjU0tLj1mV7XN+RYU2+P06GIlkpKZUjsRp8Pm0fRTnfVNxbncwJvEPBCNdmd3FWB4AAIAxIcwCCX/b8jf97tXf6Yvnf1HzauY5Xc6o/LbfquxgK37njWGczGg0hUKj7mR8tPqiIu0OBhWNx0dcg0vSlDSEWan39/S1YFD7EivAydgdDHJeFgAAYAwIs4CkzlCnPv7ox3Vyzcn6/Pmfd7qcUYnG4/razp06rbRUV1RVDXrfmWVl8hqTka3G1lo1pnAkToPPp5ikPSMIjVJvmJ3s9crjSs9H3kj/gSAYi2l/JEInYwAAgDEgzAKSbnviNu3t2qtfXPELed3pWb1Lt9/s36/XgsEhV2Wl3s7Ai8rLM9IEqj0aVSAeT1mYrU+Ev5FuNU7HjNn+Tistlc/l0nOdnUndv4cZswAAAGNGmMW499SOp/ST1T/RTWfdpEXTFjldzqhEEmdlTy8t1VuHWJXtc35FhV7s7lZPLJbWulLdeKkhEf5G2gQqled2B+J1ubSorCzpc7O7GcsDAAAwZhkLs8aYi40xm40x24wxtw3w+PeNMWsTP7YYY9ozVRvGr00HNukdf3iH5lTN0e1vvN3pckbtnn37tD0Y1H8Osyrb5/yKCkWt1cokVxJHK9WNl+oKC+UxJutWZqXercYvdXWpOxod9t7difrZZgwAADB6GQmzxhi3pLskXSJprqRrjTFz+99jrf2MtfZUa+2pkn4k6eFM1Ibxa2/XXr3lN2+Rx+XRsvcsU4m3xOmSRqU5FNIXtm/XhZWVSa3KStI5FRUyUtrPzaZ6ZdbjcmlGYaF2jCDMBmIxtUWjGQmzMUkru7qGvXdXMCij9IwKAgAAGC8ytTK7SNI2a+12a21Y0hJJVw5x/7WSfp+RyjAudQQ7dMlvL9GhwCEte88yNUxocLqkUfvsa68pGI/r7jlzkp5ZWuHxaEFJyYjHyYxUX5itTWFoa/D5tH0E24zTOWO2v7MT/0CQzO/p7lBIU7xeFaapIRUAAMB4kKm/SU2TtKff142Ja8cwxsyUVC/pH4M8fr0xZrUxZnVra2vKC0X+C0VDuuqBq7ShdYMe/reHdfrU050uadT+99Ah/b6lRZ+fMUNziotH9L3nV1ZqeUfHiMfcjERjKKTqgoKUhrb6oqIRrcymc8ZsfxUej+aXlCTV0Xh3MMgWYwAAgDHKxmWBayQ9ZK0dsDONtfYea+1Ca+3C6urqDJeGXBe3cb3/z+/X0zuf1n1X3qeLjrvI6ZJGLRiL6RNbt+p4n0+3zZgx4u8/v6JCPfG4XuruTkN1vdJxVrWhqEitkUhSZ1P7apAys6X3vIoKLe/sHPYfCHaFQjR/AgAAGKNMhdkmSdP7fV2XuDaQa8QWY6SBtVaffeyzenD9g/rORd/Rexa8x+mSxuSO3bu1LRDQ3bNnq8jtHvH3n5+YjZrsudnnOzqSnqPaJx1dhOt9PklKenU202G2OxbTKz09g94Tt1Z7gkHG8gAAAIxRpsLsC5JmG2PqjTFe9QbWR46+yRhzoqQJkpZnqC6MI999/ru6c+Wduumsm/TvZ/+70+WMyRa/X9/cvVvX1tToookTR/UcUwsLdVxRUVJhtikU0qWvvKKPbt48otdI18qslPys2aZQSKVut8o9npTWMZDzEv9A8MfWVllrB7ynNRJRyFrNZGUWAABgTDISZq21UUk3SHpM0kZJD1pr1xtjbjfGXNHv1mskLbGD/S0QGKVfv/xr3fLELXrXvHfpv9/y30k3SspG1lp9YssW+Vwufe+448b0XOdXVurZjo5Bg1ff631syxZ1xGLa5PcrkORs2lA8rtZIJPVhtm9lNskmUE3hsGrTfF62z/SiIr1pwgR9Y/duveWVV7TF7z/mnl2JEM7KLAAAwNhk7MystXaptXaOtfY4a+3XE9e+bK19pN89X7HWHjODFhiLJ7Y/oQ898iG9cdYbdf9V98tlsvGoePJ+39KiJ9vb9c2GBk0ZY1A8r6JCByIRbR4gdPX5XUuL/nbwoN5YWamYpPVDbKHtb1+atvdO9HhU5nYnvTK7NwMzZvtbNn++fnj88VrZ2an5L7ygL+/YccQ/APTNmOXMLAAAwNjk9t/qgWFE41F95K8f0ZyqOfrTu/6kQk9uB4i2SESf2bZNi8rKdH1t7Zifb7hzs/vDYX1661adXV6un86ZI0lam2TDqL4uwnUpDm3GGDUUFSU9nicdW52H4nG59Km6Om1etEjvrK7W13bt0rwXXtCjBw9K6h3LI4luxgAAAGNEmEVee3D9g9rZvlPfvPCbqiiqcLqcMfvijh06EInop3PmyJ2CrdKzfT7VFBQMGmZv2LpVPbGYfnnCCTre51OZ2510mG3sW5lNwxbfep8vqQZQcWu1Nw1NqJIxpbBQv5k7V0+dcoqKXC5d/uqruurVV7W8s1OlbrcqM3CGFwAAIJ8RZpG3rLW649k7NK96ni6fc7nT5YzZys5O/XTvXn26rk6nlZWl5DmNMTq/omLAMPtQS4seam3VV2bN0oklJXIZowUlJXo5yW3G6ewi3JCYNTvc8foDkYgi1mZ0ZfZob5gwQWsXLtS3Ghr0v21teqi1VTMKC3P63DYAAEA2IMwiby3dulSvtryqW8+9NefPyUbjcX1syxbVer26fdaslD73+ZWV2hkMqrHfSufBSESf3LpVZ5SW6ubp/5qqdWppqV7u7lY8iR5tTaGQfC5XWlYg64uKFIjHtT+xlXmoGqTMjOUZitfl0i0zZmjjokV67+TJ+sCUKY7WAwAAkA9y+2/4wBDueO4OzayYqWtOvsbpUsbsF83NWtvdrTtnz1ZZisPhQOdmb9q2TYeiUf3ixBPlcf3rY+LU0lJ1xWJJbfHtO6uajhXIvo7GwzWBypYw22dGUZF+fdJJumXGDKdLAQAAyHmEWeSlZ3c/q2d3P6ubz7lZBe4Cp8sZs4dbW3VScbHePmlSyp97QUmJSt1uPZsIs387cEC/2b9fX5gxQ6eUlh5x76mJr5M5N9uUxrOq9YnmScOF6r4mVE6cmQUAAEB6EWaRl+549g5NKp6kD532IadLGbNQPK5nOjr05gkT0rLK6XG5dE55uZ7p6FB7JKKPbtmik0tK9MWZM4+5d15JidxKMsymsYvwrESYHa6jcVMoJJekKYRZAACAvEOYRd55Zf8renTro7rxrBtVXFDsdDljtryjQ4F4XBdOmJC21zi/okLrenr0kS1b1BwO65cnnCCv69iPB5/brROLi4cNs9ZaNYVCKR/L07+OWq93+JXZUEiTvd4jtkoDAAAgP/A3POSdbz/3bZV6S/XJMz/pdCkp8URbm9ySXl9ZmbbXOL+yUlbSQ62tunn6dJ1ZXj7ovaeWlg4bZg9EIgqnuYtwfRKzZjM9YxYAAACZQ5hFXtnRtkNL1i3Rx874mCb40reSmUlPtrfrrPJyladxLumisjJ5jdEcn09fGaZb8imlpWoMhXQwEhn0nkw0Xmrw+YZvAOXQjFkAAACkH2EWeeW7z39Xbpdbnzn7M06XkhId0ahWdXamdYux1Ltt96F58/TX+fPlc7uHvLevCdTLQ6zOZqLxUn1RkRpDIYXj8cHrYGUWAAAgbxFmkTf2d+/XL9f+Uu9f8H7VltU6XU5KPN3errikN6U5zErSWydN0pzi4c8Yn5JER+NMrcxaSbsGWZ0NxGJqi0YJswAAAHmKMIu8cefKOxWKhnTLubc4XUrKPNHWpmKXS4uHOMOaaTVer2q93mHDrFF6uwgPN54n22bMAgAAILUIs8gLHcEO3fXCXXrH3HdodtVsp8tJmSfb2vS6ysoBOws7abgmUE2hkKZ4vSpIY90Nw4zn6dvqXMuZWQAAgLyUXX9DBkbpZy/+TJ2hTt167q1Ol5IyTaGQNvr9GdliPFKnlpZqo9+vYCw24ONN4XDaV0RrCwvlNYaVWQAAgHGKMIucF4wG9f0V39dFDRfpjNoznC4nZZ5sa5OUmfOyI3Vqaami1mqD3z/g442hUNq7CLuM0ayiokE7GhNmAQAA8hthFjnv/rX3q7m7WZ8/7/NOl5JST7a1aVJBgeaXlDhdyjGGawKVqS7CDT6fdgyyzXhvOKwSl0vlw3RnBgAAQG4izCKnRWIRffv5b2vRtEV6w6w3OF1Oylhr9URbmy6srJTLGKfLOcZxPp9KXK4Bw2wmuwjXD7MyO62wUCYLf/8AAAAwdoRZ5LSfr/m5trdt15df9+W8Ci2b/H7tDYezcouxJLmN0YLS0gFnzWZye29DUZHaolG1RyID1sEWYwAAgPxFmEXO6gn36Pb/u13nzzhfl86+1OlyUqrvvOyFWRpmpX91NLbWHnG9r4twus/MSlK9zydp4PE8hFkAAID8RphFzrpz5Z1q7m7WHW+6I69WZaXe+bINRUWHw1o2OrW0VJ2xmHYeFST7VmbrMrQyK+mYrcZxa7U3HM5IoAYAAIAzCLPISQf9B/Wt576lK064QudMP8fpclIqGo/rqfb2rN1i3OfUQZpAZXSbcd/K7FFNoA5EIopYy8osAABAHiPMIifd8ewd6gp16RsXfMPpUlJudVeXOmOxrN5iLEknl5TIpWPDbGMopDK3W2UeT9prqPB4NMHjOWZllrE8AAAA+Y8wi5yzp2OPfrTqR3r/Ke/XvJp5TpeTck+2t0uSLqisdLSO4RS73ZpTXDzgymwmQ2RDUdExZ2YJswAAAPmPMIuc89V/flVWVl99w1edLiUtnmhr02mlpZqUA+c9+5pA9deU4bOq9T6fth+1zTiTTagAAADgDMIscsrG1o26d+29+sTCT2hm5Uyny0k5fyym5zs6sn6LcZ9TS0u1OxTSoX6jcZxYmd0ZDCrer6tyUygkl6QphFkAAIC8RZhFTvmPp/5DJQUl+sL5X3C6lLR4tqNDYWuzvvlTn74mUK8kVmfj1mpfOJzRMFtfVKSwtdqb2Fos9YbZyV6vPC4+4gAAAPIVf9NDzljZuFIPb3xYN59zs6pLqp0uJy2eaGuT1xidV1HhdClJObqjcUs4rKi1GRnL06dhgFmzzJgFAADIf4RZ5ARrrW578jZVF1frM4s/43Q5afNEW5vOLi9XidvtdClJmez1aorXezjMHj6rmuFtxtKRs2YzfW4XAAAAmUeYRU54/LXH9fTOp/Wl131JZYVlTpeTFgfCYb3U3Z0zW4z79G8C1djXRTiDQXJGUZGMjpw12xQKqZaVWQAAgLxGmEXWi9u4bnvyNs2qnKXrz7je6XLS5qnESJ5cDLMb/H6F43FHRuJ4XS5NLyw8vDIbiMXUFo2yzRgAACDPeZwuABjOg+sf1Nrmtfr1236tQk/+BpQn2tpU7nZrYVlurTyfUlKiiLXa0NOjplBIbkk1Gd7iW19UdHg8T5MDq8MAAADIPFZmkdXCsbD+4x//ofk183Xtydc6XU5aPdHWpjdUVuZcB97+TaCaQiFNLSyU25iM1tDg8x1uALXXgXO7AAAAyDxWZpHVvvnMN/Va22ta9p5lcrtyoynSaOwIBLQ9GNRNdXVOlzJis4uL5XO5esNsOJzRTsZ96ouKtDccViAWc2SrMwAAADIvt5aAMK6sb1mvrz/zdV1z8jW6+PiLnS4nrZ5sa5MkXZhj52UlyW2MFpSU6OXENmMntvf2jefZFQwSZgEAAMYJwiyyUiwe04f/+mGVFZbpzovvdLqctHu8rU1TvV6dVFzsdCmj0tfR2Kn5rvX9xvM0hcMqcblUniPjjQAAADA6hFlkpbteuEsrGlfozovvVE1JjdPlpFV7JKK/HjyoqyZNksnwWdNUObW0VO3RqDpjMUfCbN+s2R2JldlphYU5+3sJAACA5BBmkXV2te/SF578gi45/hK9Z/57nC4n7R5obVUwHtcHp0xxupRR62sCJTmzvXey1yufy6XtgYBjq8MAAADILMIssoq1Vh/920clST+57CfjYnXt3n37NK+4OOdG8vQ3v7RUfX9STpyZNcaovqjoiJVZAAAA5DfCLLLKb175jR577TF988JvamblTKfLSbsNPT1a2dWlD06dmtPBvcTt1uxEEyangmSDz6dtgYD2hsPMmAUAABgHCLPIGi09LbrpsZt0dt3Z+sSZn3C6nIy4t7lZHmP03smTnS5lzPq2GjsVZuuLirShp0cRa1mZBQAAGAcIs8gan172aXWHu/XzK36eUzNle2IxXbB2rZ7r6BjR90Xicf26uVmXTZyoyXmwkvi+yZP1/smTVexQF+GGoiLFEj8nzAIAAOQ/wiyywl83/1UPrH9AXzz/i5pbPdfpckZkVWennmpv16e3blXc2qS/7++HDml/JKIPTp2axuoy5/JJk3T/SSc59vr1iW3OEmEWAABgPCDMwnEdwQ59/NGP6+Sak3Xbebc5Xc6IrenuPvzfP7a2Jv199zY3q6agQJdOnJiu0saVvvE8kjNNqAAAAJBZhFk47rYnbtO+7n36xRW/kNedeyHkpa4u1Xq9mltcrC/t2KFoPD7s97SEw/rrwYN63+TJKnDxP8NUqE+EWSPlxbZtAAAADI2/RcNRq5pW6acv/lQ3nnWjFk1b5HQ5o7Kmu1sLy8r0X/X12hwI6P79+4f9nt/u36+otXmzxTgblHo8qi4o0GSvl38gAAAAGAf4Gx8c9YMVP1B5Ybluf+PtTpcyKj2xmDb5/TqttFRXTZqkRWVl+srOnQrGYoN+j7VW9zY368yyMs0rKclgtfnvOJ9PdZyXBQAAGBcIs3DM/u79emjDQ7rulOtU6i11upxReaW7W1bS6WVlMsboGw0NagyF9NO9ewf9njXd3Xq1p0cfmjIlc4WOE98/7jjdefzxTpcBAACADCDMwjG/eOkXisQjOT1Ttq/50+mJGasXTpigCysr9fXdu9UVjQ74Pb/ct09FLpeuqanJWJ3jxeKKCp1TUeF0GQAAAMgAwiwcEYvH9NPVP9WF9RfqhEknOF3OqK3p6tKkgoIjRsF8o6FBByIRfb+x8Zj7g7GYftfSordNmqTKgoJMlgoAAADkFcIsHPG3LX/Tns49+uSZn3S6lDF5qbtbp5eWyhhz+Nqi8nK9bdIkfXfPHh0Ih4+4/y8HD6o9GtUH2WIMAAAAjAlhFo64e/XdmlY2TW894a1OlzJq4Xhc63p6dFrpsed9/6u+Xj2xmO7YvfuI6/fu26cZhYW6YMKETJUJAAAA5CXCLDJu68Gtevy1x/XRMz4qj8vjdDmjtr6nRxFrdXpZ2TGPzS0p0fsmT9aPm5rUGAxKkvYEg3q8rU0fmDJF7n4ruQAAAABGjjCLjPvJ6p/I4/LoI2d8xOlSxuTo5k9H+8qsWYpLun3XLknSr/bvl5V0HVuMAQAAgDFLKswaY05JdyEYH/wRv+5de6+uPulqTSnN7VC3pqtLZW63Gny+AR+f5fPpY7W1+uW+fdri9+u+5ma9obJy0PsBAAAAJC/ZldknjDEvG2NuNsZMTWtFyGtL1i1Re7A9p8fx9Hmpu1unlZbKNcSW4S/OnKkil0tvX7dO2wIBGj8BAAAAKZJsmJ0q6cuSzpK01RjzuDHmvcaY4vSVhnxjrdVdL9ylk2tO1vkzzne6nDGJWau13d0Dnpftb7LXq5vq6rTe71eZ262rq6szVCEAAACQ35IKs9baqLX2L9bad0qaJulBSbdI2m+M+ZUx5tx0Fon8sKppldbsW6NPLPzEEaNsctFmv1+BeHzATsZH+9yMGaouKNB7J09WidudgeoAAACA/DeiVrLGmFJJV0m6RlKdpCWSdkv6rTHmUWttbg8NRVrdvfpulXnL9N4F73W6lDF7aZjmT/1VeDzatGgRQRYAAABIoaTCrDHmMknvk3SJpOck/VzSn621wcTjd6k31BJmMaAD/gN6YN0D+vDpH1ZZ4dBbc3PBmq4uFblcOrE4uZ32EwsK0lwRAAAAML4kuzJ7h6RfSfqMtXbf0Q9aaw8ZY25KZWHIL7986ZcKxUL6+MKPO11KSrzU3a0FJSXyuJhuBQAAADghqTBrrZ2fxD0/H3s5yEexeEw/Xf1TvX7m6zWvZp7T5YyZtVZrurp07eTJTpcCAAAAjFvJzpl92Bhz/lHXzjfGPJSespBPHnvtMe1o36FPnpkfu9B3BIPqiMWSav4EAAAAID2S3SP5eknPH3VtuaQ3prYc5KO7XrhLU0qn6KoTr3K6lJQYSfMnAAAAAOmRbJgNSio56lqppEhqy0G+2d62Xcu2LtP1p1+vAnd+NEFa09Ult6STS47+nwQAAACATEk2zD4m6WfGmHJJSvz3x5L+nq7CkB/uWnWXXMal68+43ulSUmZNd7fmlZSoiFE7AAAAgGOSDbP/Lqlc0iFjTIukQ5IqJN2UprqQB9oCbbpnzT265uRrNK18mtPlpERf86fTy3J/vBAAAACQy5LtZtwm6TJjzFRJdZL2WGub01oZct7dL9yt7nC3bjn3FqdLSZl94bBaIhGaPwEAAAAOS3bOrCTJWrvPGNMsyRhjXIlr8bRUhpwWiAR058o7dcnxl2jB5AVOlzMka62i1qogiZmxa7q6JNH8CQAAAHBasqN5ao0xfzLGHJQUVW/jp74fwDHuW3ufWv2tuvXcW50uZVjf3rNHM1as0MHI8G/nl7q7ZSSdQpgFAAAAHJXsmdmfSQpLulBSt6TTJT0i6WNpqgs5LBqP6rvLv6uzpp2l1818ndPlDClure5ualJzOKzbd+4c9v413d2a7fOpzDOiTQ0AAAAAUizZMHuOpA9Za9dKstbalyX9P/U2hgKO8McNf9T2tu269dxbZYxxupwh/bO9XbtDIc32+XT33r3a7PcPef9LNH8CAAAAskKyYTam3u3FktRujKmW1CMpP1rUImWstfrWc9/SCVUn6MoTr3S6nGHd19yscrdb/3vKKSp2uXTza68Neu/BSES7QiGaPwEAAABZINkwu1LSpYmfPybpAUkPS1qdjqKQu57Y/oRean5Jnzvnc3KZZN9ezuiKRvVQa6veVVOjmUVF+uLMmfrbwYN64tChAe9/ieZPAAAAQNZINm28T9I/Ez+/SdI/JK2T9O401IQc9q3nvqXaslq9d8F7nS5lWA+1tsofj+u6KVMkSTfW1am+qEiffe01xaw95v6XurslSaexzRgAAABw3LBh1hjjlnSnercVy1obsNb+l7X2VmvtvnQXiNyxeu9qPbnjSd101k0q9BQ6Xc6w7m9u1myfT2eXl0uSCl0ufbuhQa/29OiX+459a6/p7taMwkJVFRRkulQAAAAARxk2zFprY5LeLIl5shjSt577lioKK/TRhR91upRhbQ8E9M+ODn1gypQjmlRdXV2t8yoq9B87dqgzGj3ie9bQ/AkAAADIGsluM/6+pK8aY1iSwoC2HtyqP274oz6+8OMqLyx3upxh/aq5WUbS+yZPPuK6MUbfO+44tUQi+ubu3Yevd0Wj2hoI0PwJAAAAyBLJhtlPSfqcpC5jzB5jzO6+H8m+kDHmYmPMZmPMNmPMbYPc82/GmA3GmPXGmN8l+9xw3nef/668bq9uXHyj06UMK26tfrV/vy6cMEEzioqOefzM8nK9b/JkfX/PHu0MBCRJL3d3y4rmTwAAAEC28CR535i6+STO3d4l6SJJjZJeMMY8Yq3d0O+e2ZI+L+lca22bMaZmLK+JzGnubtb9L9+vD5zyAU0pneJ0OcN6pqNDO4JBfa2+ftB7vlFfr4daW3Xb9u1aMm/e4eZPbDMGAAAAskNSYdZa+8/h7xrSIknbrLXbJckYs0TSlZI29LvnI5Lusta2JV6zZYyviQy5c8WdCsfCuvmcm50uJSn3NTerzO3W2yZNGvSeuqIifW76dN2+a5c+3dGhNd3dqiko0FSvN4OVAgAAABhMUmHWGHP7YI9Za7+cxFNMk7Sn39eNks466p45idd6TpJb0lestX9Ppj44pzPUqZ+s/oneMfcdml012+lyhtUdjeoPLS26pqZGxW73kPfeMmOGfr5vnz6zbZsC8bhOLys7olkUAAAAAOcku814+lFfT5H0ekl/SnEtsyW9QVKdpP8zxsy31rb3v8kYc72k6yVpxowZKXx5jMbPVv9MHaEO3XrurU6XkpSHDxxQT7/ZskMpcbv1jYYGXbdpkyTprVVV6S4PAAAAQJKS3Wb8waOvGWMulnRtkq/TpCMDcV3iWn+NklZaayOSdhhjtqg33L5wVC33SLpHkhYuXGiTfH2kQSga0g9W/kAX1F+gM2rPcLqcpNzX3Kzjiop0bkVFUve/b/Jk/bCxUWu6u+lkDAAAAGSRZLsZD+RxSVclee8LkmYbY+qNMV5J10h65Kh7/qzeVVkZYyapd9vx9jHUhzT73au/096uvbrlnFucLiUpOwMBPdXefsxs2aG4jNFds2fr1NJSva6yMr0FAgAAAEhasmdmG466VCzp3TryHOygrLVRY8wNkh5T73nYX1pr1yfO4q621j6SeOzNxpgNkmKSPmetPZjkrwMZFrdxfXf5d7Vg8gK9+bg3O11OUn69f78k6f1JbDHub3FFhV5auDAdJQEAAAAYpWTPzG6TZCX1LWf5Jb0k6QPJvpC1dqmkpUdd+3K/n1tJn038QJZbtnWZNrRu0K/f9uucaIpkrdV9zc26oLJSMweYLQsAAAAgtyR7ZnYs25GRh779/Lc1vXy63jXvXU6XkpRnOzq0PRjUV2bNcroUAAAAACmQVEg1xpxqjJl+1LXpxphT0lMWstmqplX6v13/p88s/owK3AVOl6NHDhzQb5qb1RoOD3rP/c3NKnW79fbq6gxWBgAAACBdkt1m/BtJVxx1zSvp15IWpLQiZL3vPP8dVRRW6MOnf9jpUhS3Vtdu2CB/PC4j6cyyMl0ycaIurarSwrIyuYxRTyymB1tb9c7qapUMM1sWAAAAQG5INszOsNYe0VnYWvuaMWZW6ktCNtt2aJv+uOGPuu2821RWWOZ0OWoMheSPx/XvdXWq8Hi09NAh3b5rl766a5eqCwr0lokTVenxqCsWS2q2LAAAAIDckGyYbTTGnG6tXdN3wRhzuqS96SkL2ep7y7+nAneBPrXoU06XIkna5PdLkt46aZJeX1mpL82apQPhsB5va9OyQ4f090OHdCAS0XFFRTovydmyAAAAALJfsmH2+5L+Yoz5tqTXJB0n6WZJX09XYcg+rT2tunftvXrfgvdpatlUp8uR9K8we2Jx8eFrk7xevXvyZL178mTFrNWLXV2aVFAgVw50XQYAAACQnGS7Gf+PMaZd0v+TNF2982X/3Vr7UBprQ5b58aofKxgN6uZzbna6lMM2+/2q9HhUUzBwIyq3MVpUXp7hqgAAAACkW7Irs7LW/kHSH9JYC7JYT7hHd71wl6444QqdOOlEp8s5bJPfrxN8vpyYdQsAAAAgdZIdzfNDY8w5R107xxjzg7RUhaxz79p7dTBwUJ8753NOl3KETX7/EVuMAQAAAIwPSYVZSddKWn3UtRclvTu15SAbReNRfW/593R23dk6d/q5TpdzWFc0qr3hMGEWAAAAGIeSDbN2gHvdI/h+5LCHNz6sHe079LlzPpdV23k3J5o/nUCYBQAAAMadZMPoM5L+yxjjkqTEf7+auI48Zq3Vt5/7tuZUzdEVJ1zhdDlHGKiTMQAAAIDxIdkGUDdK+pukfcaYXZJmqnfG7FvTVRiyw9M7n9aL+17Uzy7/mdwut9PlHGFzICC3pON8PqdLAQAAAJBhyY7maTTGnC5pkXpH8+yXdJWkVZJq01YdHPed57+jmpIavf+U9ztdyjE2+f1q8PnkdbHbHQAAABhvRpICqiSdJekLkp6SdLp6V2yRp/Z27dXft/1dHz3joyryFDldzjHoZAwAAACMX0OuzBpjCiRdIek6SW+RtE3S7yXNkPRv1tqWdBcI5/xh/R9kZfXu+dnXtDpmrbb6/bp44kSnSwEAAADggOFWZvdL+pmkzZIWW2vnWmu/Jimc9srguCXrl+jUKafqxEknOl3KMXYFgwpZy8osAAAAME4NF2ZfkVSp3u3FZxpjJqS9ImSFne07taJxhd41711OlzIgOhkDAAAA49uQYdZa+wZJx0l6XNLNkpqNMX+VVCKpIO3VwTEPrn9QkrI2zB6eMUsnYwAAAGBcGrYBlLV2l7X2a9ba2ZIulLRPUlzSy8aYb6e7QDhjybolOmvaWaqfUO90KQPa5PeryuPRJK/X6VIAAAAAOGBEM02stc9aa6+XNEXSpyTNT0tVcNSWg1v0UvNLuubka5wuZVCb6WQMAAAAjGujGtBprQ1aa39vrb0k1QXBeQ+se0BGRu+c+84xP1dXNKoXOjtlrU1BZf+yye/XCYRZAAAAYNwaVZhF/rLW6vfrfq/zZ56vaeXTxvx839mzR4vWrNGlr76qLYlzrmPVHolofyTCyiwAAAAwjhFmcYR1Leu08cBGXTMvNVuM1/X0qNLj0fMdHZr/wgv6wvbt6onFxvScmwMBSXQyBgAAAMYzwiyOsGTdErmNW1fPvTolz7c1END5FRXavGiRrqmp0Td379aJq1bpDy0to9563DeWh23GAAAAwPhFmMVh1lo9sP4BXVB/gWpKasb8fHFrtS0Q0ByfT1MKC3X/SSfp2dNOU5XHo3/bsEEXvfyyNvb0jPh5N/n9KjBG9UVFY64RAAAAQG4izOKwF/e9qNfaXktZF+PGUEjBeFyz+62gnltRodVnnKEfz56tF7u7tWD1at322muKj2CVdrPfr+N8PhW4ePsCAAAA4xVpAIctWbdEBa4Cve3Et6Xk+foaPs3x+Y647nG59Mlp0w5vPf7Wnj16/NChpJ93E2N5AAAAgHGPMAtJUtzG9cD6B3Tx8Rdrgm9CSp5za6JR0+yjwmyfGq9X98yZI5/LpUeTDLPReFzbAgHCLAAAADDOEWYhSVq+Z7kaOxtTtsVYkrYEAip2uVRbWDjoPT63W2+aMEGPHjyYVEOoHcGgItbqhEECMgAAAIDxgTALSb1bjIs8RXrrnLem7Dm3+P063ueTy5gh77usqko7gkFtTGIObV8nY1ZmAQAAgPGNMAtF41E9uOFBXT7ncpUVlqXsebcGApqTROi8dOJESdKjBw8Oey9jeQAAAABIhFlI+ufOf6qlp0XXzEvdFuNIPK7tgcCg52X7m15UpFNKSpIKs5v9ftUUFGhCQUEqygQAAACQowiz0APrH1Cpt1SXzr40Zc+5MxhUTMd2Mh7MZVVVerajQ22RyJD30ckYAAAAgESYHffCsbD+uPGPuvKEK+UrSF1TpS19nYyTDJ6XVVUpJunxtrYh79tMJ2MAAAAAIsyOe09sf0KHAodS2sVYkrYOMmN2MGeVl6vK49HfhthqfCAc1oFIhPOyAAAAAAiz492SdUtUWVSpNx/35pQ+75ZAQBVutyYlebbVbYwuqarSsoMHFRtkRM/mxGovK7MAAAAACLPjWDAa1J83/VlXn3S1vG5vSp+7r5OxGWYsT3+XTZyog9GoVnV2Dvj4ZjoZAwAAAEggzI5j/9z5T3WFu/T2k96e8ufe4vcnvcW4z1smTpRbGnSr8Sa/X15jNKuoKAUVAgAAAMhlhNlxbNm2ZSryFOmNs96Y0ucNxGLaEwol3fypz4SCAp1bUTHoiJ5Nfr/mFBfLPYLVXgAAAAD5iTA7ji3dulQX1F+Q0i7GkvRaICCr5Js/9Xd5VZVe7ulRYzB4zGOb/X6dMIrnBAAAAJB/CLPj1LZD27T10FZdcvwlKX/uw2N5RhE8L6uqkiQ9eujQEdfD8bheYywPAAAAgATC7Di1bOsySdKlsy9N+XNvHeGM2f5OKi7WrKKiY7YavxYIKCY6GQMAAADoRZgdp5ZuW6o5VXPUMKEh5c+9xe9XTUGBKjyeEX+vMUaXV1XpybY2BWKxw9fpZAwAAACgP8LsOOSP+PX0zqd16fGpX5WV/jWWZ7QumzhR/nhcT7e3H762iTALAAAAoB/C7Dj09M6nFYwGdcns1J+XlXpXZkdzXrbPGyorVexyHbHVeJPfr1qvV+WjWO0FAAAAkH8Is+PQ0q1LVVxQrNfNfF3Kn7szGtX+SGRUnYz7FLndetOECXr00CFZayVJmwMBVmUBAAAAHEaYHWestVq2bZkurL9QRZ6ilD//WJo/9XdZVZV2BoPa4PfLWqtNfj/NnwAAAAAcRpgdZ7Yc3KLtbdvTMpJHkrYmzraOZWVWki6dOFGS9OjBg2qNRNQejRJmAQAAABxGmB1nlm3rHcmTtvOyiZXZ48cYZuuKinRqaakePXiQ5k8AAAAAjkGYHWeWbl2qkyadpFmVs9Ly/FsDAU0vLJTP7R7zc102caKe6+jQ8s5OScyYBQAAAPAvhNlxpDvcrX/u+qcunZ2ekTxSbyfjsW4x7nNZVZViku5uapLP5dL0wsKUPC8AAACA3EeYHUee2vGUwrFw2s7LWmu1JRAYc/OnPovKyzWpoEC7QyHN8fnkMiYlzwsAAAAg9xFmx5GlW5eq1Fuq82acl5bnP5ho1JSqlVm3Mbok0QiKLcYAAAAA+iPMjhN9I3ne1PAmFXrSs123r/nT7BSFWal3q7FE8ycAAAAARyLMjhMbD2zUro5dadtiLP1rxuycFAbPSyZO1OLycl2cWKEFAAAAAEnyOF0AMmPp1qWSlNYwu8Xvl1tSfVFRyp6z3OPR8tNPT9nzAQAAAMgPrMyOE8u2LdPJNSdresX0tL3G1kBA9T6fCly8rQAAAACkF6ljHOgKdemZXc/o0uPTN5JH6l2ZTeV5WQAAAAAYDGF2HHhyx5OKxCO6ZHb6thhba7U1EEhZJ2MAAAAAGAphdhxYunWpyrxlOnf6uWl7jb3hsPzxeMpmzAIAAADAUAizec5aq6Vbl+qi4y5Sgbsgba+z1e+XJFZmAQAAAGQEYTbPrWtZp6aupvSfl03DWB4AAAAAGAxhNs8dHsmTxvOyUm8n40JjNL2wMK2vAwAAAAASYTbvLdu2TKdMPkW1ZbVpfZ0tfr+O9/nkMiatrwMAAAAAEmE2r3UEO/Ts7md16ez0bjGWercZ0/wJAAAAQKYQZvPY0zufVszGdPHxF6f1dWLW6jXG8gAAAADIIMJsHlvRuEIel0eLpi1K6+vsCgYVsVazCbMAAAAAMoQwm8dWNq3UKZNPUZGnKK2vs5VOxgAAAAAyjDCbp2LxmFbvXa2zpp2V9tfakpgxy8osAAAAgEwhzOapTQc2qSvclfYtxlLvymyp260pXm/aXwsAAAAAJMJs3lrVtEqSdFZdZlZmZ/t8MozlAQAAAJAhhNk8tbJppSoKKzSnak7aX2srnYwBAAAAZBhhNk+talqlM6edKZdJ7x9xOB7XzmCQGbMAAAAAMoowm4f8Eb9e2f9KRpo/bQ8EFJdYmQUAAACQUYTZPPTSvpcUs7GMNH/awlgeAAAAAA4gzOahlU0rJSljnYwlxvIAAAAAyCzCbB5a2bRSMypmaErplLS/1ha/X1UejyYWFKT9tQAAAACgD2E2D61qWpWR87KheFx/P3RIp5SWpv21AAAAAKC/jIVZY8zFxpjNxphtxpjbBnj8OmNMqzFmbeLHhzNVWz5p6WnRzvadGdlifM/evdodCunWGTPS/loAAAAA0J8nEy9ijHFLukvSRZIaJb1gjHnEWrvhqFsfsNbekIma8tWqplWSlPaV2Z5YTF/ftUuvr6jQRRMmpPW1AAAAAOBoGQmzkhZJ2mat3S5Jxpglkq6UdHSYxRitbFwpt3Hr9Kmnp/V1ftTYqP2RiP7Y0CBjTFpfCwAAAACOlqltxtMk7en3dWPi2tGuNsa8Yox5yBgzfaAnMsZcb4xZbYxZ3dramo5ac9qqvat0cs3JKvGWpO012iMRfXvPHl06caLOrahI2+sAAAAAwGCyqQHUXyXNstYukPS/ku4f6CZr7T3W2oXW2oXV1dUZLTDbxW08I82f/ruxUW3RqP6rvj6trwMAAAAAg8lUmG2S1H+ltS5x7TBr7UFrbSjx5c8lnZGh2vLGtkPb1B5sT7r5U2MwqLevW6cn29qSfo2WcFjf37NH76yu1mllZaMtFQAAAADGJFNh9gVJs40x9cYYr6RrJD3S/wZjzNR+X14haWOGassbKxtXSpLOqht+ZbYxGNQbX35ZfzpwQFe++qpe6OxM6jXu2L1bgXhct8+aNZZSAQAAAGBMMhJmrbVRSTdIeky9IfVBa+16Y8ztxpgrErd92hiz3hjzsqRPS7ouE7Xlk1VNq1TqLdVJk04a8r6+ILs/HNaf5s1TtderS199VVv9/mG/7+6mJr1/yhSdWJK+M7kAAAAAMJxMdTOWtXappKVHXftyv59/XtLnM1VPPlrZtFILaxfK7XIPek9TKHQ4yD6+YIEWV1RobkmJzn3pJb3llVf0/GmnaUph4YDf+7VduxSX9J8zZ6bpVwAAAAAAycmmBlAYg2A0qLXNa7WodvDzsk2hkN6wdu0RQVaS5hQX69H587U/HNYlr76qzmj0mO/d5vfrl83Nun7qVM3y+dL26wAAAACAZBBm88TLzS8rEo8Mel62f5B9rF+Q7bOovFx/nDdP63p69LZ16xSKx494/Cs7d6rAGH2RVVkAAAAAWYAwmydWNiWaPw0wlqcpFNIb+wXZsweZDXtxVZV+ecIJ+kd7u96/caPi1kqS1nV363ctLfrUtGmaOsgWZAAAAADIpIydmUV6rWpapdqyWk0rn3bE9b4g2zxMkO3zvilT1BwO65bt2zV52zbdefzx+vLOnSpzu3XLjBnp/CUAAAAAQNIIs3liZdPKY1ZlD0Uih4Ps35MIsn1unj5d+8Jhfb+xUZ3RqP504IC+OmuWqgoK0lE6AAAAAIwY24zzwKHAIW07tE2Lph3Z/Onvhw5payCgP8ybp3OSDLKSZIzRd487Tu+uqdH9+/eryuPRTXV1qS4bAAAAAEaNldk8sKpplaRjz8tuDwQkSa8bQZDt4zJG9554oio8Hl1QWalyD28VAAAAANmDhJIHVjWtkpHRGbVnHHF9RzCoKV6vfO7B584Oxety6e45c1JRIgAAAACkFNuM88DKppWaWz1X5YXlR1zfEQyqvqjIoaoAAAAAIH0IsznOWqtVTauOOS8r9YbZBsIsAAAAgDxEmM1xO9p36ID/wDHnZSPxuPYEg6r3+RyqDAAAAADShzCb41Y2rpQknVV3ZJjdEwopJrHNGAAAAEBeIszmuFVNq+Tz+HRyzclHXN8RDEoizAIAAADIT4TZHLeyaaXOqD1DHteRjal3JMbyNLDNGAAAAEAeIszmsEgsojX71mhR7cDNnzzGqK6w0IHKAAAAACC9CLM57JX9rygUCx1zXlaStgeDmlFYKLcxDlQGAAAAAOlFmM1hq5pWSdLAY3kCAc7LAgAAAMhbhNkctqJphWpKajSzYuYxj+1gLA8AAACAPEaYzWHL9yzX2XVnyxy1lbgnFlNLJKIGVmYBAAAA5CnCbI464D+grYe26uy6s495rK+TMduMAQAAAOQrwmyOWtm4UpJ09vQBwmzfjFm2GQMAAADIU4TZHLW8cbncxq0zpp5xzGOHwywrswAAAADyFGE2Ry1vXK5TppyiEm/JMY/tCAZV4nKpuqDAgcoAAAAAIP0IszkoFo9pVdOqAc/LStL2QED1Pt8xjaEAAAAAIF8QZnPQ+tb16g53a3Hd4gEf3xEMssUYAAAAQF4jzOag5XuWS9KAK7PWWsIsAAAAgLxHmM1BK5pWqLq4Wg0TGo557GAkou5YjDALAAAAIK8RZnPQ8j3Ltbhu8YBnYvs6GTcwlgcAAABAHiPM5phDgUPafHDz4M2fGMsDAAAAYBwgzOaYlY0rJUlnTx84zO4IBCQRZgEAAADkN8JsjlneuFwu49LC2oUDPr4jGNSkggKVejwZrgwAAAAAMocwm2OWNy7XgskLVOotHfDxHcGgGliVBQAAAJDnCLM5JBaPaWXjykHPy0rS9kCALcYAAAAA8h5hNodsPLBRXeEuLa5bPODjMWu1OxRSPZ2MAQAAAOQ5wmwOWb5nuSQNujLbFAopYi0rswAAAADyHmE2h6xoXKEqX5WOn3j8gI8fnjFLmAUAAACQ5wizOWR543ItrlssY8yAj2/vG8vDNmMAAAAAeY4wmyPaAm3aeGDjkM2fdgSDckmaUViYucIAAAAAwAGE2RyxsmmlJOns6UOH2brCQhW4+GMFAAAAkN9IPTliReMKuYxLZ9aeOeg9OxjLAwAAAGCcIMzmiOWNy3VyzckqKywb9J7twaAaOC8LAAAAYBwgzOaAuI1rZePKIc/LBmIx7QuHWZkFAAAAMC4QZnPApgOb1BHq0OK6xYPesysxlocwCwAAAGA8IMzmgOV7lkvSsJ2MJcbyAAAAABgfCLM5YHnjck0omqA5VXMGvacvzDawMgsAAABgHCDM5oAVjSu0uG6xjDGD3rM9EFCRy6UpXm8GKwMAAAAAZxBms1xHsEMbWjcMucVY6l2ZnVVUNGTgBQAAAIB8QZjNciubVsrK6uzpw4dZmj8BAAAAGC8Is1luReMKGRktmrZoyPsIswAAAADGE8JsllveuFzzauapvLB80HvaIhG1R6NqoJMxAAAAgHGCMJvF4jauFY0rkjovKzFjFgAAAMD4QZjNYlsOblF7sJ0wCwAAAABHIcxmseV7lkuSFtctHvK+HYGAJMIsAAAAgPGDMJvFljcuV2VRpU6YdMKQ920PBjXB41FlQUGGKgMAAAAAZxFms9ja5rU6Y+oZcpmh/5joZAwAAABgvCHMZilrrTa0btC86nnD3rsjECDMAgAAABhXCLNZanfHbvVEejS3eu6Q98Wt1c5gUPWM5QEAAAAwjhBms9T61vWSpHk1Q6/M7guHFbKWlVkAAAAA4wphNkttaN0gScOuzPZ1Mm4gzAIAAAAYRwizWWp963pNKZ2iib6JQ953eMYs24wBAAAAjCOE2Sy1oXXDsKuy0r/C7MzCwnSXBAAAAABZgzCbhUbUyTgYVK3XqyK3OwOVAQAAAEB2IMxmoT2de9Qd7k4qzG4PBNTAFmMAAAAA4wxhNgutb+ntZJzsNmM6GQMAAAAYbwizWahvLM9wYTYcj6sxFCLMAgAAABh3CLNZaEPrBk0umayq4qoh79sdDMpKhFkAAAAA4w5hNgutb12veTVJnJdNdDLmzCwAAACA8YYwm2X6OhnPnZT8WB5WZgEAAACMN4TZLHO4k3ESK7PLOzpU5narlhmzAAAAAMYZwmyW6etkPNxYnu5oVA+1tupdNTVyG5OJ0gAAAAAgaxBms8yG1g2Shu9k/FBrq3ricV03ZUomygIAAACArEKYzTLrW9cn1cn43uZmzfb5dE55eYYqAwAAAIDsQZjNMhtaNwy7KvtaIKD/6+jQdVOmyLDFGAAAAMA4RJjNIn2djIc7L3t/c7OMpPdPnpyZwgAAAAAgyxBms0hjZ6O6wl1DrszGrdX9zc26aMIE1TGSBwAAAMA4RZjNIutbE52MhxjL81R7u3aHQvogjZ8AAAAAjGOE2SySzFie+5qbVeF268pJkzJVFgAAAABkHcJsFtnQukE1JTWDdjLuiEb1x9ZWXTt5snxud4arAwAAAIDskbEwa4y52Biz2RizzRhz2xD3XW2MscaYhZmqLVusb10/5KrsH1paFGC2LAAAAABkJswaY9yS7pJ0iaS5kq41xhzT5cgYUybpRkkrM1FXNunrZDxU86d7m5t1UnGxFpWVZbAyAAAAAMg+mVqZXSRpm7V2u7U2LGmJpCsHuO9rkr4lKZihurJGXyfjwVZmt/j9er6zk9myAAAAAKDMhdlpkvb0+7oxce0wY8zpkqZbax8d6omMMdcbY1YbY1a3tramvlKH9HUyHmxl9r7mZrkkvY/ZsgAAAACQHQ2gjDEuSd+T9O/D3Wutvcdau9Bau7C6ujr9xWXIhtYNkgYeyxOzVr9qbtbFEydqamFhpksDAAAAgKyTqTDbJGl6v6/rEtf6lEk6WdLTxpidkhZLemQ8NYFa37JeNSU1mlR87MidJ9ra1BQOM1sWAAAAABIyFWZfkDTbGFNvjPFKukbSI30PWms7rLWTrLWzrLWzJK2QdIW1dnWG6nPchgODN3+6r7lZEz0evZXZsgAAAAAgKUNh1loblXSDpMckbZT0oLV2vTHmdmPMFZmoIZv1dTIeqPlTWySiP7W26t2TJ6vQlRW7wgEAAADAcZ5MvZC1dqmkpUdd+/Ig974hEzVli6auJnWGOgdcmX2gpUUha5ktCwAAAAD9sNSXBda39HYyHmhl9t7mZs0vKdHppaWZLgsAAAAAshZhNgsMNpZnQ0+PVnV1MVsWAAAAAI5CmM0CG1o3qLq4WtUlR44aur+5WR5j9F5mywIAAADAEQizWWB96/oBz8v+o71d51dUqMbrdaAqAAAAAMhehFmHDdbJOBqPa11Pj07jrCwAAAAAHIMw67C+Tsbzao4Ms1sDAQXjcZ1CmAUAAACAYxBmHdbXyfjobcYvd3dLkk4lzAIAAADAMQizDtvQukHSsWN51nZ3q8AYnVhc7ERZAAAAAJDVCLMOW9+6XpOKJx3Tyfjlnh7NLS6W18UfEQAAAAAcjaTksIGaP0m924w5LwsAAAAAAyPMOshaO+BYnpZwWPvCYcIsAAAAAAyCMOugw52Mj1qZ7Wv+RJgFAAAAgIERZh10uPlTzSBhtqQk4zUBAAAAQC4gzDpo0LE8PT2a5vVqktfrRFkAAAAAkPUIsw7a0LpBk4onqaak5ojrNH8CAAAAgKERZh00UPOnUDyujX4/YRYAAAAAhkCYddC2Q9t0QtUJR1zb0NOjqLWEWQAAAAAYAmHWIbF4TAf8BzSldMoR1/uaP51KmAUAAACAQRFmHXIwcFBW9tjzsj098rlcOt7nc6gyAAAAAMh+hFmHtPS0SJKqi6uPuP5yd7fml5TIbYwTZQEAAABATiDMOqS1p1WSjliZtdbSyRgAAAAAkkCYdUjfymz/MNsYCulQNEqYBQAAAIBhEGYdcnibccm/thnT/AkAAAAAkkOYdUirv1VGRlW+qsPXXu7pkSQtKClxqiwAAAAAyAmEWYe09LRoUvEkuV3uw9de7u5WQ1GRyjweBysDAAAAgOxHmHVIS0/LEVuMJdH8CQAAAACSRJh1SKu/9YjmTz2xmLYGAoRZAAAAAEgCYdYhLT0tR4TZV7u7ZSWdwnlZAAAAABgWYdYhLT0tqi7u18k40fyJTsYAAAAAMDzCrAPCsbDag+1HrMy+3N2tCrdbM4uKHKwMAAAAAHIDYdYBB/wHJOmIMLu2u1sLSktljHGqLAAAAADIGYRZB7T0tEjS4W3GcWv1Cp2MAQAAACBphFkHtPa0SvrXyuz2QEA98TjNnwAAAAAgSYRZB/StzPaFWZo/AQAAAMDIEGYdcHibcUnvNuOXu7vlkjSPlVkAAAAASAph1gGt/lZ5XB5VFlVK6m3+dEJxsXxut7OFAQAAAECOIMw6oG/GrMv0/va/TPMnAAAAABgRwqwDWnpaDp+XbYtEtDsUovkTAAAAAIwAYdYBrf7Ww+dlX6H5EwAAAACMGGHWAf1XZl/u7pYkthkDAAAAwAgQZh3Q0tOimuLeMLu2u1vVBQWa4vU6XBUAAAAA5A7CbIYFIgF1h7uPGMtzSmmpjDEOVwYAAAAAuYMwm2Gt/lZJUk1JjaLxuNb39ND8CQAAAABGiDCbYS09LZJ6w+zmQEAha2n+BAAAAAAjRJjNsNae3pXZ6uJqraX5EwAAAACMCmE2w/qvzL7c3S2vMTqxuNjhqgAAAAAgtxBmM+zoMDu3pEQFLv4YAAAAAGAkSFEZ1upvVaG7UKXeUr3a06MFNH8CAAAAgBEjzGZYS0+LakpqFIjHtS8c1myfz+mSAAAAACDnEGYzrC/M7gwGJUn1hFkAAAAAGDHCbIa1+ltVXVKtHYkw21BU5HBFAAAAAJB7CLMZ1rcyuyMQkCTVE2YBAAAAYMQIsxlkre0Ns8U12h4MyudyabLX63RZAAAAAJBzCLMZ1BPpUTAaPLzNuL6oSMYYp8sCAAAAgJxDmM2g/jNmtwcCbDEGAAAAgFEizGZQX5itLq7RjmBQDXQyBgAAAIBRIcxmUGtPqyTJWzRJXbEYK7MAAAAAMEqE2QzqW5kNeColiZVZAAAAABglwmwG9YXZDtMbYlmZBQAAAIDRIcxmUKu/VaXeUjWF45IIswAAAAAwWoTZDGrpaVF1ce9YnkkFBSrzeJwuCQAAAAByEmE2g1p6WnrH8iRmzAIAAAAARocwm0Gt/lbVlNRoRyCgBsIsAAAAAIwaYTaDWnpaVFVco12hkOrpZAwAAAAAo0aYzRBrrVp7WuUrma6otWwzBgAAAIAxIMxmSEeoQ5F4RMZXK0lsMwYAAACAMSDMZkjfjNmwt0qS2GYMAAAAAGNAmM2QvjDrd1fIJWlGYaGzBQEAAABADmPQaYa09rRKktpVpOmFLhW4+HcEAAAAABgtwmyG9K3M7o+51eDjvCwAAAAAjAXLgxnSF2abwjE6GQMAAADAGBFmM6TV36qK4ho1RyKEWQAAAAAYI8JshrT0tKii4kRJUgOdjAEAAABgTAizGdLS06KS8uMliZVZAAAAABgjwmyGtPpbVVA8XRIrswAAAAAwVoTZDGnpaZEtmqJil0s1BQVOlwMAAAAAOY0wmwFxG9cB/wGFCqpUX1QkY4zTJQEAAABATiPMZsChwCHFbVzdrlLVs8UYAAAAAMYsY2HWGHOxMWazMWabMea2AR7/mDHmVWPMWmPMs8aYuZmqLd36ZsweUiHNnwAAAAAgBTISZo0xbkl3SbpE0lxJ1w4QVn9nrZ1vrT1V0rclfS8TtWVCS0+L5ClX0LrUQJgFAAAAgDHL1MrsIknbrLXbrbVhSUskXdn/BmttZ78vSyTZDNWWdq09rZJvqiSxzRgAAAAAUsCTodeZJmlPv68bJZ119E3GmE9K+qwkr6QLMlNa+rX0tEhFtZLEyiwAAAAApEBWNYCy1t5lrT1O0q2S/mOge4wx1xtjVhtjVre2tma2wFHqDbOJlVnCLAAAAACMWabCbJOk6f2+rktcG8wSSVcN9IC19h5r7UJr7cLq6urUVZhGrf5WFZbWa1JBgUo9mVoMBwAAAID8lakw+4Kk2caYemOMV9I1kh7pf4MxZna/Ly+TtDVDtaVdS0+LPMXT2GIMAAAAACmSkWVCa23UGHODpMckuSX90lq73hhzu6TV1tpHJN1gjHmTpIikNkkfyERtmdDS06LYhMlsMQYAAACAFMnYnldr7VJJS4+69uV+P78xU7VkWov/gEKeCjXQyRgAAAAAUiKrGkDlq+ZIXNa4WZkFAAAAgBQhzKZZJBZRh+ldkWVlFgAAAABSgzCbZgcDBxnLAwAAAAApRphNs74Zsy5ZTS8sdLocAAAAAMgLhNk06wuzNR6jAhe/3QAAAACQCqSrNGvtaZWKpmhmodfpUgAAAAAgbxBm06ylp0Xy1Wp2cYnTpQAAAABA3iDMpllTzwHJO1EnlFQ4XQoAAAAA5A3CbJptDwYlMZYHAAAAAFKJMJtmjeGoJKmBsTwAAAAAkDKE2TTbH+39La5nZRYAAAAAUoYwm2ZtpkhuG1FNQYHTpQAAAABA3iDMplmPq0yVNiBjjNOlAAAAAEDeIMymUSgaUtRbrWpX1OlSAAAAACCvEGbTqKWnRSqaqtoCVmUBAAAAIJU8TheQz7Z07pc8xZpVRJgFAAAAgFRiZTaN1nUdlCSdUFLmcCUAAAAAkF8Is2m0padLkjSvrMrhSgAAAAAgvxBm02hHMCRJOm3CFIcrAQAAAID8wpnZNGqKxKRou6b6Kp0uBQAAAADyCiuzadQaL5A3coAZswAAAACQYoTZNOqQTyWxLqfLAAAAAIC8Q5hNk2g8roC7TBNM0OlSAAAAACDvEGbTpCkcljVu1bhiTpcCAAAAAHmHMJsmMwoL5Vv5Lp1ZwDZjAAAAAEg1wmya+CN+BYItqithxiwAAAAApBphNk06Qh2qK69TbVmt06UAAAAAQN5hzmya1JbVas9n9jhdBgAAAADkJVZmAQAAAAA5hzALAAAAAMg5hFkAAAAAQM4hzAIAAAAAcg5hFgAAAACQcwizAAAAAICcQ5gFAAAAAOQcwiwAAAAAIOcQZgEAAAAAOYcwCwAAAADIOYRZAAAAAEDOIcwCAAAAAHIOYRYAAAAAkHMIswAAAACAnEOYBQAAAADkHMIsAAAAACDnEGYBAAAAADmHMAsAAAAAyDmEWQAAAABAziHMAgAAAAByDmEWAAAAAJBzCLMAAAAAgJxDmAUAAAAA5BzCLAAAAAAg5xBmAQAAAAA5hzALAAAAAMg5hFkAAAAAQM4hzAIAAAAAco6x1jpdw6gZY1ol7XK6jmFMknTA6SKABN6PyCa8H5FNeD8im/B+RLbIhvfiTGtt9UAP5HSYzQXGmNXW2oVO1wFIvB+RXXg/IpvwfkQ24f2IbJHt70W2GQMAAAAAcg5hFgAAAACQcwiz6XeP0wUA/fB+RDbh/YhswvsR2YT3I7JFVr8XOTMLAAAAAMg5rMwCAAAAAHIOYRYAAAAAkHMIs2lijLnYGLPZGLPNGHOb0/VgfDHGTDfGPGWM2WCMWW+MuTFxfaIx5n+NMVsT/53gdK0YP4wxbmPMS8aYvyW+rjfGrEx8Tj5gjPE6XSPGB2NMpTHmIWPMJmPMRmPM2Xw+winGmM8k/r96nTHm98aYIj4fkSnGmF8aY1qMMev6XRvw89D0+mHiffmKMeZ05yrvRZhNA2OMW9Jdki6RNFfStcaYuc5WhXEmKunfrbVzJS2W9MnEe/A2SU9aa2dLejLxNZApN0ra2O/rb0n6vrX2eEltkv6fI1VhPLpT0t+ttSdKOkW970s+H5Fxxphpkj4taaG19mRJbknXiM9HZM59ki4+6tpgn4eXSJqd+HG9pJ9kqMZBEWbTY5Gkbdba7dbasKQlkq50uCaMI9bafdbaNYmfd6n3L2rT1Ps+vD9x2/2SrnKkQIw7xpg6SZdJ+nniayPpAkkPJW7h/YiMMMZUSHqdpF9IkrU2bK1tF5+PcI5Hks8Y45FULGmf+HxEhlhr/0/SoaMuD/Z5eKWkX9leKyRVGmOmZqTQQRBm02OapD39vm5MXAMyzhgzS9JpklZKmmyt3Zd4qFnSZKfqwrjzA0m3SIonvq6S1G6tjSa+5nMSmVIvqVXSvYlt7z83xpSIz0c4wFrbJOm7knarN8R2SHpRfD7CWYN9HmZdxiHMAnnMGFMq6Y+SbrLWdvZ/zPbO5WI2F9LOGHO5pBZr7YtO1wKodxXsdEk/sdaeJqlHR20p5vMRmZI4i3ilev+RpVZSiY7d8gk4Jts/Dwmz6dEkaXq/r+sS14CMMcYUqDfI/tZa+3Di8v6+7SCJ/7Y4VR/GlXMlXWGM2aneYxcXqPfMYmViW53E5yQyp1FSo7V2ZeLrh9Qbbvl8hBPeJGmHtbbVWhuR9LB6PzP5fISTBvs8zLqMQ5hNjxckzU50ovOq9yD/Iw7XhHEkcR7xF5I2Wmu/1++hRyR9IPHzD0j6S6Zrw/hjrf28tbbOWjtLvZ+H/7DWvkfSU5LekbiN9yMywlrbLGmPMeaExKULJW0Qn49wxm5Ji40xxYn/7+57P/L5CCcN9nn4iKT3J7oaL5bU0W87siNM78oxUs0Yc6l6z4i5Jf3SWvt1ZyvCeGKMOU/SM5Je1b/OKH5BvedmH5Q0Q9IuSf9mrT360D+QNsaYN0i62Vp7uTGmQb0rtRMlvSTpvdbakIPlYZwwxpyq3mZkXknbJX1Qvf/Az+cjMs4Y81VJ71LvJIKXJH1YvecQ+XxE2hljfi/pDZImSdov6T8l/VkDfB4m/sHlx+rdCu+X9EFr7WoHyj6MMAsAAAAAyDlsMwYAAAAA5BzCLAAAAAAg5xBmAQAAAAA5hzALAAAAAMg5hFkAAAAAQM4hzAIAkIeMMdYYc7zTdQAAkC6EWQAAMsAYs9MYEzDGdPf78WOn6wIAIFd5nC4AAIBx5K3W2iecLgIAgHzAyiwAAA4yxlxnjHnOGPNjY0yHMWaTMebCfo/XGmMeMcYcMsZsM8Z8pN9jbmPMF4wxrxljuowxLxpjpvd7+jcZY7YaY9qNMXcZY0xGf3EAAKQRK7MAADjvLEkPSZok6e2SHjbG1FtrD0laImmdpFpJJ0r6X2PMa9baf0j6rKRrJV0qaYukBZL8/Z73cklnSiqX9KKkv0r6e0Z+RQAApJmx1jpdAwAAec8Ys1O9YTXa7/LnJEUkfUPSNJv4P2VjzCpJP5L0tKSdkiqttV2Jx74paaq19jpjzGZJt1hr/zLA61lJ51trn018/aCkNdbaO9LyCwQAIMPYZgwAQOZcZa2t7PfjfxLXm+yR/7q8S70rsbWSDvUF2X6PTUv8fLqk14Z4veZ+P/dLKh1b+QAAZA/CLAAAzpt21HnWGZL2Jn5MNMaUHfVYU+LneyQdl5kSAQDILoRZAACcVyPp08aYAmPMOyWdJGmptXaPpOclfdMYU2SMWSDp/0n6TeL7fi7pa8aY2abXAmNMlSO/AgAAMowGUAAAZM5fjTGxfl//r6S/SFopabakA5L2S3qHtfZg4p5rJf1Uvau0bZL+s994n+9JKpT0uHrP426S9LZ0/yIAAMgGNIACAMBBxpjrJH3YWnue07UAAJBL2GYMAAAAAMg5hFkAAAAAQM5hmzEAAAAAIOewMgsAAAAAyDmEWQAAAABAziHMAgAAAAByDmEWAAAAAJBzCLMAAAAAgJzz/wHV1PufFsFozQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1152x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "plt.title(\"Attention 92, v2: Training Accuracy vs Validation Accuracy\", fontsize=18)\n",
    "plt.plot(ran92_v2_history.history['accuracy'], label='training accuracy', color='g')\n",
    "plt.plot(ran92_v2_history.history['val_accuracy'], label = 'validation accuracy', color='c')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.savefig(plot_acc_filename)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92731241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/ran92_v2_arl/history/ran92_v2_history_Tue_Dec_21_22_36_50_2021\n"
     ]
    }
   ],
   "source": [
    "history_filename = history_path + '/ran92_v2_history_' + time.ctime().replace(' ','_').replace(':','_')\n",
    "print(history_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6275ad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('{}.npy'.format(history_filename),ran92_v2_history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f98e98c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Model_Input with unsupported characters which will be renamed to model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models/ran92_v2_ARL\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/ran92_v2_arl/saved_models/ran92_v2_ARL\\assets\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\suman\\anaconda3\\envs\\p38\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    }
   ],
   "source": [
    "model.save(saved_model_path + '/ran92_v2_ARL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e144c47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
